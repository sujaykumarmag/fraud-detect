{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/DMEPOS/imputed_dmepos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\",\"Rfrg_NPI\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rfrg_Prvdr_Crdntls</th>\n",
       "      <th>Rfrg_Prvdr_Gndr</th>\n",
       "      <th>Rfrg_Prvdr_Type</th>\n",
       "      <th>Rfrg_Prvdr_Type_Flag</th>\n",
       "      <th>Tot_Suplrs</th>\n",
       "      <th>Tot_Suplr_HCPCS_Cds</th>\n",
       "      <th>Tot_Suplr_Benes</th>\n",
       "      <th>Tot_Suplr_Clms</th>\n",
       "      <th>Tot_Suplr_Srvcs</th>\n",
       "      <th>Suplr_Sbmtd_Chrgs</th>\n",
       "      <th>...</th>\n",
       "      <th>Bene_CC_Hyplpdma_Pct</th>\n",
       "      <th>Bene_CC_Hyprtnsn_Pct</th>\n",
       "      <th>Bene_CC_IHD_Pct</th>\n",
       "      <th>Bene_CC_Opo_Pct</th>\n",
       "      <th>Bene_CC_RAOA_Pct</th>\n",
       "      <th>Bene_CC_Sz_Pct</th>\n",
       "      <th>Bene_CC_Strok_Pct</th>\n",
       "      <th>Bene_Avg_Risk_Scre</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>FraudType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>132</td>\n",
       "      <td>159</td>\n",
       "      <td>29869.97</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.729650</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28</td>\n",
       "      <td>47</td>\n",
       "      <td>33.0</td>\n",
       "      <td>97</td>\n",
       "      <td>1136</td>\n",
       "      <td>44435.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.654308</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1629</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>19.0</td>\n",
       "      <td>65</td>\n",
       "      <td>1117</td>\n",
       "      <td>18711.69</td>\n",
       "      <td>...</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.894526</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29</td>\n",
       "      <td>4778</td>\n",
       "      <td>26951.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.173167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4511</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>2080.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.819692</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383452</th>\n",
       "      <td>3017</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35</td>\n",
       "      <td>67</td>\n",
       "      <td>46.0</td>\n",
       "      <td>180</td>\n",
       "      <td>4981</td>\n",
       "      <td>107216.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.350335</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383453</th>\n",
       "      <td>2362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>11.0</td>\n",
       "      <td>35</td>\n",
       "      <td>384</td>\n",
       "      <td>11429.84</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.382273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383454</th>\n",
       "      <td>1186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47</td>\n",
       "      <td>56</td>\n",
       "      <td>86.0</td>\n",
       "      <td>502</td>\n",
       "      <td>11743</td>\n",
       "      <td>173452.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2.096019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383455</th>\n",
       "      <td>2362</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>14.0</td>\n",
       "      <td>55</td>\n",
       "      <td>322</td>\n",
       "      <td>19471.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.451024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383456</th>\n",
       "      <td>5465</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>38</td>\n",
       "      <td>55</td>\n",
       "      <td>6707.76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.572100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>383457 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rfrg_Prvdr_Crdntls  Rfrg_Prvdr_Gndr  Rfrg_Prvdr_Type  \\\n",
       "0                     2362              0.0               44   \n",
       "1                     3017              0.0               26   \n",
       "2                     1629              1.0               44   \n",
       "3                     2684              0.0              117   \n",
       "4                     4511              1.0               87   \n",
       "...                    ...              ...              ...   \n",
       "383452                3017              1.0               44   \n",
       "383453                2362              0.0               26   \n",
       "383454                1186              0.0               44   \n",
       "383455                2362              1.0               44   \n",
       "383456                5465              1.0               44   \n",
       "\n",
       "        Rfrg_Prvdr_Type_Flag  Tot_Suplrs  Tot_Suplr_HCPCS_Cds  \\\n",
       "0                        1.0           8                    7   \n",
       "1                        1.0          28                   47   \n",
       "2                        1.0          11                   44   \n",
       "3                        1.0           5                   12   \n",
       "4                        1.0           1                    1   \n",
       "...                      ...         ...                  ...   \n",
       "383452                   1.0          35                   67   \n",
       "383453                   1.0          12                   17   \n",
       "383454                   1.0          47                   56   \n",
       "383455                   1.0          11                   27   \n",
       "383456                   1.0           6                    8   \n",
       "\n",
       "        Tot_Suplr_Benes  Tot_Suplr_Clms  Tot_Suplr_Srvcs  Suplr_Sbmtd_Chrgs  \\\n",
       "0                  11.0             132              159           29869.97   \n",
       "1                  33.0              97             1136           44435.62   \n",
       "2                  19.0              65             1117           18711.69   \n",
       "3                  23.0              29             4778           26951.30   \n",
       "4                  13.0              13               13            2080.00   \n",
       "...                 ...             ...              ...                ...   \n",
       "383452             46.0             180             4981          107216.47   \n",
       "383453             11.0              35              384           11429.84   \n",
       "383454             86.0             502            11743          173452.58   \n",
       "383455             14.0              55              322           19471.42   \n",
       "383456             13.0              38               55            6707.76   \n",
       "\n",
       "        ...  Bene_CC_Hyplpdma_Pct  Bene_CC_Hyprtnsn_Pct  Bene_CC_IHD_Pct  \\\n",
       "0       ...                  0.75                  0.75             0.32   \n",
       "1       ...                  0.73                  0.75             0.39   \n",
       "2       ...                  0.74                  0.75             0.53   \n",
       "3       ...                  0.54                  0.69             0.48   \n",
       "4       ...                  0.75                  0.75             0.00   \n",
       "...     ...                   ...                   ...              ...   \n",
       "383452  ...                  0.75                  0.75             0.50   \n",
       "383453  ...                  0.75                  0.75             0.00   \n",
       "383454  ...                  0.60                  0.73             0.66   \n",
       "383455  ...                  0.75                  0.75             0.35   \n",
       "383456  ...                  0.75                  0.75             0.00   \n",
       "\n",
       "        Bene_CC_Opo_Pct  Bene_CC_RAOA_Pct  Bene_CC_Sz_Pct  Bene_CC_Strok_Pct  \\\n",
       "0                  0.00              0.64             0.0               0.00   \n",
       "1                  0.00              0.58             0.0               0.00   \n",
       "2                  0.00              0.68             0.0               0.00   \n",
       "3                  0.00              0.75             0.0               0.00   \n",
       "4                  0.00              0.75             0.0               0.00   \n",
       "...                 ...               ...             ...                ...   \n",
       "383452             0.40              0.57             0.0               0.00   \n",
       "383453             0.00              0.52             0.0               0.00   \n",
       "383454             0.14              0.47             0.0               0.07   \n",
       "383455             0.00              0.57             0.0               0.00   \n",
       "383456             0.00              0.75             0.0               0.00   \n",
       "\n",
       "        Bene_Avg_Risk_Scre  Fraud  FraudType  \n",
       "0                 3.729650      0          0  \n",
       "1                 1.654308      0          0  \n",
       "2                 1.894526      0          0  \n",
       "3                 2.173167      0          0  \n",
       "4                 0.819692      0          0  \n",
       "...                    ...    ...        ...  \n",
       "383452            2.350335      0          0  \n",
       "383453            1.382273      0          0  \n",
       "383454            2.096019      0          0  \n",
       "383455            1.451024      0          0  \n",
       "383456            1.572100      0          0  \n",
       "\n",
       "[383457 rows x 77 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6446535\ttotal: 544ms\tremaining: 4m 31s\n",
      "1:\tlearn: 0.6006962\ttotal: 865ms\tremaining: 3m 35s\n",
      "2:\tlearn: 0.5606318\ttotal: 1.34s\tremaining: 3m 42s\n",
      "3:\tlearn: 0.5242046\ttotal: 1.72s\tremaining: 3m 32s\n",
      "4:\tlearn: 0.4907765\ttotal: 2.12s\tremaining: 3m 29s\n",
      "5:\tlearn: 0.4599780\ttotal: 2.59s\tremaining: 3m 33s\n",
      "6:\tlearn: 0.4316295\ttotal: 2.93s\tremaining: 3m 26s\n",
      "7:\tlearn: 0.4053825\ttotal: 3.36s\tremaining: 3m 26s\n",
      "8:\tlearn: 0.3811245\ttotal: 3.72s\tremaining: 3m 22s\n",
      "9:\tlearn: 0.3585939\ttotal: 4.12s\tremaining: 3m 21s\n",
      "10:\tlearn: 0.3377230\ttotal: 4.51s\tremaining: 3m 20s\n",
      "11:\tlearn: 0.3182776\ttotal: 4.87s\tremaining: 3m 17s\n",
      "12:\tlearn: 0.3000892\ttotal: 5.25s\tremaining: 3m 16s\n",
      "13:\tlearn: 0.2831257\ttotal: 5.58s\tremaining: 3m 13s\n",
      "14:\tlearn: 0.2672604\ttotal: 6s\tremaining: 3m 14s\n",
      "15:\tlearn: 0.2523944\ttotal: 6.34s\tremaining: 3m 11s\n",
      "16:\tlearn: 0.2384763\ttotal: 6.8s\tremaining: 3m 13s\n",
      "17:\tlearn: 0.2254432\ttotal: 7.11s\tremaining: 3m 10s\n",
      "18:\tlearn: 0.2131850\ttotal: 7.46s\tremaining: 3m 8s\n",
      "19:\tlearn: 0.2016893\ttotal: 7.88s\tremaining: 3m 9s\n",
      "20:\tlearn: 0.1908792\ttotal: 8.33s\tremaining: 3m 10s\n",
      "21:\tlearn: 0.1807047\ttotal: 8.75s\tremaining: 3m 10s\n",
      "22:\tlearn: 0.1711191\ttotal: 9.12s\tremaining: 3m 9s\n",
      "23:\tlearn: 0.1621015\ttotal: 9.48s\tremaining: 3m 8s\n",
      "24:\tlearn: 0.1535929\ttotal: 9.86s\tremaining: 3m 7s\n",
      "25:\tlearn: 0.1455852\ttotal: 10.3s\tremaining: 3m 8s\n",
      "26:\tlearn: 0.1380177\ttotal: 10.7s\tremaining: 3m 8s\n",
      "27:\tlearn: 0.1308688\ttotal: 11.1s\tremaining: 3m 7s\n",
      "28:\tlearn: 0.1241384\ttotal: 11.6s\tremaining: 3m 7s\n",
      "29:\tlearn: 0.1177659\ttotal: 11.9s\tremaining: 3m 6s\n",
      "30:\tlearn: 0.1117494\ttotal: 12.3s\tremaining: 3m 5s\n",
      "31:\tlearn: 0.1060677\ttotal: 12.6s\tremaining: 3m 3s\n",
      "32:\tlearn: 0.1006879\ttotal: 13s\tremaining: 3m 4s\n",
      "33:\tlearn: 0.0956043\ttotal: 13.5s\tremaining: 3m 4s\n",
      "34:\tlearn: 0.0908007\ttotal: 13.8s\tremaining: 3m 3s\n",
      "35:\tlearn: 0.0862379\ttotal: 14.3s\tremaining: 3m 4s\n",
      "36:\tlearn: 0.0819278\ttotal: 14.6s\tremaining: 3m 3s\n",
      "37:\tlearn: 0.0778449\ttotal: 15.1s\tremaining: 3m 2s\n",
      "38:\tlearn: 0.0739773\ttotal: 15.4s\tremaining: 3m 1s\n",
      "39:\tlearn: 0.0703065\ttotal: 15.8s\tremaining: 3m 1s\n",
      "40:\tlearn: 0.0668469\ttotal: 16.2s\tremaining: 3m 1s\n",
      "41:\tlearn: 0.0635775\ttotal: 16.5s\tremaining: 2m 59s\n",
      "42:\tlearn: 0.0604590\ttotal: 17s\tremaining: 3m\n",
      "43:\tlearn: 0.0575157\ttotal: 17.3s\tremaining: 2m 59s\n",
      "44:\tlearn: 0.0547051\ttotal: 17.7s\tremaining: 2m 59s\n",
      "45:\tlearn: 0.0520690\ttotal: 18.1s\tremaining: 2m 58s\n",
      "46:\tlearn: 0.0495459\ttotal: 18.5s\tremaining: 2m 57s\n",
      "47:\tlearn: 0.0471620\ttotal: 18.9s\tremaining: 2m 57s\n",
      "48:\tlearn: 0.0448999\ttotal: 19.3s\tremaining: 2m 57s\n",
      "49:\tlearn: 0.0427402\ttotal: 19.7s\tremaining: 2m 57s\n",
      "50:\tlearn: 0.0407020\ttotal: 20.1s\tremaining: 2m 56s\n",
      "51:\tlearn: 0.0387587\ttotal: 20.6s\tremaining: 2m 57s\n",
      "52:\tlearn: 0.0369260\ttotal: 20.9s\tremaining: 2m 56s\n",
      "53:\tlearn: 0.0351904\ttotal: 21.4s\tremaining: 2m 56s\n",
      "54:\tlearn: 0.0335206\ttotal: 21.7s\tremaining: 2m 55s\n",
      "55:\tlearn: 0.0319418\ttotal: 22.1s\tremaining: 2m 55s\n",
      "56:\tlearn: 0.0304546\ttotal: 22.5s\tremaining: 2m 55s\n",
      "57:\tlearn: 0.0290350\ttotal: 22.9s\tremaining: 2m 54s\n",
      "58:\tlearn: 0.0276810\ttotal: 23.3s\tremaining: 2m 54s\n",
      "59:\tlearn: 0.0263963\ttotal: 23.6s\tremaining: 2m 53s\n",
      "60:\tlearn: 0.0251798\ttotal: 24.1s\tremaining: 2m 53s\n",
      "61:\tlearn: 0.0240290\ttotal: 24.4s\tremaining: 2m 52s\n",
      "62:\tlearn: 0.0229312\ttotal: 24.8s\tremaining: 2m 52s\n",
      "63:\tlearn: 0.0219153\ttotal: 25.3s\tremaining: 2m 52s\n",
      "64:\tlearn: 0.0209221\ttotal: 25.7s\tremaining: 2m 51s\n",
      "65:\tlearn: 0.0199755\ttotal: 26.2s\tremaining: 2m 52s\n",
      "66:\tlearn: 0.0190771\ttotal: 26.7s\tremaining: 2m 52s\n",
      "67:\tlearn: 0.0182263\ttotal: 27.2s\tremaining: 2m 52s\n",
      "68:\tlearn: 0.0174153\ttotal: 27.6s\tremaining: 2m 52s\n",
      "69:\tlearn: 0.0166445\ttotal: 28s\tremaining: 2m 52s\n",
      "70:\tlearn: 0.0159174\ttotal: 28.5s\tremaining: 2m 52s\n",
      "71:\tlearn: 0.0152254\ttotal: 29s\tremaining: 2m 52s\n",
      "72:\tlearn: 0.0145644\ttotal: 29.5s\tremaining: 2m 52s\n",
      "73:\tlearn: 0.0139377\ttotal: 29.8s\tremaining: 2m 51s\n",
      "74:\tlearn: 0.0133379\ttotal: 30.4s\tremaining: 2m 52s\n",
      "75:\tlearn: 0.0127801\ttotal: 30.7s\tremaining: 2m 51s\n",
      "76:\tlearn: 0.0122390\ttotal: 31.3s\tremaining: 2m 51s\n",
      "77:\tlearn: 0.0117283\ttotal: 31.7s\tremaining: 2m 51s\n",
      "78:\tlearn: 0.0112510\ttotal: 32.1s\tremaining: 2m 51s\n",
      "79:\tlearn: 0.0107899\ttotal: 32.6s\tremaining: 2m 51s\n",
      "80:\tlearn: 0.0103524\ttotal: 33s\tremaining: 2m 50s\n",
      "81:\tlearn: 0.0099375\ttotal: 33.5s\tremaining: 2m 50s\n",
      "82:\tlearn: 0.0095453\ttotal: 33.8s\tremaining: 2m 50s\n",
      "83:\tlearn: 0.0091696\ttotal: 34.4s\tremaining: 2m 50s\n",
      "84:\tlearn: 0.0088126\ttotal: 34.8s\tremaining: 2m 49s\n",
      "85:\tlearn: 0.0084770\ttotal: 35.4s\tremaining: 2m 50s\n",
      "86:\tlearn: 0.0081596\ttotal: 35.8s\tremaining: 2m 49s\n",
      "87:\tlearn: 0.0078524\ttotal: 36.2s\tremaining: 2m 49s\n",
      "88:\tlearn: 0.0075634\ttotal: 36.7s\tremaining: 2m 49s\n",
      "89:\tlearn: 0.0072868\ttotal: 37.1s\tremaining: 2m 48s\n",
      "90:\tlearn: 0.0070266\ttotal: 37.5s\tremaining: 2m 48s\n",
      "91:\tlearn: 0.0067758\ttotal: 37.9s\tremaining: 2m 48s\n",
      "92:\tlearn: 0.0065421\ttotal: 38.4s\tremaining: 2m 47s\n",
      "93:\tlearn: 0.0063269\ttotal: 38.9s\tremaining: 2m 47s\n",
      "94:\tlearn: 0.0061162\ttotal: 39.3s\tremaining: 2m 47s\n",
      "95:\tlearn: 0.0059153\ttotal: 39.8s\tremaining: 2m 47s\n",
      "96:\tlearn: 0.0057225\ttotal: 40.3s\tremaining: 2m 47s\n",
      "97:\tlearn: 0.0055385\ttotal: 40.7s\tremaining: 2m 47s\n",
      "98:\tlearn: 0.0053635\ttotal: 41.1s\tremaining: 2m 46s\n",
      "99:\tlearn: 0.0051983\ttotal: 41.6s\tremaining: 2m 46s\n",
      "100:\tlearn: 0.0050436\ttotal: 42.1s\tremaining: 2m 46s\n",
      "101:\tlearn: 0.0048947\ttotal: 42.6s\tremaining: 2m 46s\n",
      "102:\tlearn: 0.0047536\ttotal: 43.1s\tremaining: 2m 46s\n",
      "103:\tlearn: 0.0046253\ttotal: 43.5s\tremaining: 2m 45s\n",
      "104:\tlearn: 0.0044985\ttotal: 44.1s\tremaining: 2m 45s\n",
      "105:\tlearn: 0.0043803\ttotal: 44.5s\tremaining: 2m 45s\n",
      "106:\tlearn: 0.0042653\ttotal: 45s\tremaining: 2m 45s\n",
      "107:\tlearn: 0.0041596\ttotal: 45.5s\tremaining: 2m 45s\n",
      "108:\tlearn: 0.0040627\ttotal: 45.9s\tremaining: 2m 44s\n",
      "109:\tlearn: 0.0039649\ttotal: 46.5s\tremaining: 2m 44s\n",
      "110:\tlearn: 0.0038737\ttotal: 47.1s\tremaining: 2m 45s\n",
      "111:\tlearn: 0.0037899\ttotal: 47.7s\tremaining: 2m 45s\n",
      "112:\tlearn: 0.0037063\ttotal: 48.3s\tremaining: 2m 45s\n",
      "113:\tlearn: 0.0036310\ttotal: 48.8s\tremaining: 2m 45s\n",
      "114:\tlearn: 0.0035567\ttotal: 49.5s\tremaining: 2m 45s\n",
      "115:\tlearn: 0.0034885\ttotal: 50s\tremaining: 2m 45s\n",
      "116:\tlearn: 0.0034252\ttotal: 50.6s\tremaining: 2m 45s\n",
      "117:\tlearn: 0.0033620\ttotal: 51.2s\tremaining: 2m 45s\n",
      "118:\tlearn: 0.0033047\ttotal: 51.9s\tremaining: 2m 46s\n",
      "119:\tlearn: 0.0032504\ttotal: 52.4s\tremaining: 2m 46s\n",
      "120:\tlearn: 0.0031960\ttotal: 53.1s\tremaining: 2m 46s\n",
      "121:\tlearn: 0.0031453\ttotal: 53.7s\tremaining: 2m 46s\n",
      "122:\tlearn: 0.0030962\ttotal: 54.2s\tremaining: 2m 46s\n",
      "123:\tlearn: 0.0030503\ttotal: 54.7s\tremaining: 2m 45s\n",
      "124:\tlearn: 0.0030072\ttotal: 55.3s\tremaining: 2m 45s\n",
      "125:\tlearn: 0.0029659\ttotal: 55.9s\tremaining: 2m 45s\n",
      "126:\tlearn: 0.0029269\ttotal: 56.5s\tremaining: 2m 45s\n",
      "127:\tlearn: 0.0028910\ttotal: 57.1s\tremaining: 2m 46s\n",
      "128:\tlearn: 0.0028573\ttotal: 57.7s\tremaining: 2m 45s\n",
      "129:\tlearn: 0.0028247\ttotal: 58.4s\tremaining: 2m 46s\n",
      "130:\tlearn: 0.0027947\ttotal: 58.9s\tremaining: 2m 46s\n",
      "131:\tlearn: 0.0027648\ttotal: 59.6s\tremaining: 2m 46s\n",
      "132:\tlearn: 0.0027372\ttotal: 1m\tremaining: 2m 46s\n",
      "133:\tlearn: 0.0027113\ttotal: 1m\tremaining: 2m 45s\n",
      "134:\tlearn: 0.0026885\ttotal: 1m 1s\tremaining: 2m 45s\n",
      "135:\tlearn: 0.0026657\ttotal: 1m 1s\tremaining: 2m 45s\n",
      "136:\tlearn: 0.0026445\ttotal: 1m 2s\tremaining: 2m 45s\n",
      "137:\tlearn: 0.0026235\ttotal: 1m 3s\tremaining: 2m 45s\n",
      "138:\tlearn: 0.0026059\ttotal: 1m 3s\tremaining: 2m 45s\n",
      "139:\tlearn: 0.0025869\ttotal: 1m 4s\tremaining: 2m 45s\n",
      "140:\tlearn: 0.0025692\ttotal: 1m 4s\tremaining: 2m 45s\n",
      "141:\tlearn: 0.0025531\ttotal: 1m 5s\tremaining: 2m 45s\n",
      "142:\tlearn: 0.0025380\ttotal: 1m 6s\tremaining: 2m 45s\n",
      "143:\tlearn: 0.0025230\ttotal: 1m 6s\tremaining: 2m 45s\n",
      "144:\tlearn: 0.0025088\ttotal: 1m 7s\tremaining: 2m 44s\n",
      "145:\tlearn: 0.0024965\ttotal: 1m 8s\tremaining: 2m 45s\n",
      "146:\tlearn: 0.0024842\ttotal: 1m 8s\tremaining: 2m 44s\n",
      "147:\tlearn: 0.0024719\ttotal: 1m 9s\tremaining: 2m 44s\n",
      "148:\tlearn: 0.0024586\ttotal: 1m 9s\tremaining: 2m 44s\n",
      "149:\tlearn: 0.0024485\ttotal: 1m 10s\tremaining: 2m 43s\n",
      "150:\tlearn: 0.0024385\ttotal: 1m 10s\tremaining: 2m 43s\n",
      "151:\tlearn: 0.0024297\ttotal: 1m 11s\tremaining: 2m 43s\n",
      "152:\tlearn: 0.0024208\ttotal: 1m 12s\tremaining: 2m 43s\n",
      "153:\tlearn: 0.0024121\ttotal: 1m 12s\tremaining: 2m 43s\n",
      "154:\tlearn: 0.0024045\ttotal: 1m 13s\tremaining: 2m 43s\n",
      "155:\tlearn: 0.0023968\ttotal: 1m 13s\tremaining: 2m 43s\n",
      "156:\tlearn: 0.0023891\ttotal: 1m 14s\tremaining: 2m 42s\n",
      "157:\tlearn: 0.0023817\ttotal: 1m 15s\tremaining: 2m 42s\n",
      "158:\tlearn: 0.0023756\ttotal: 1m 15s\tremaining: 2m 42s\n",
      "159:\tlearn: 0.0023701\ttotal: 1m 16s\tremaining: 2m 42s\n",
      "160:\tlearn: 0.0023654\ttotal: 1m 17s\tremaining: 2m 42s\n",
      "161:\tlearn: 0.0023599\ttotal: 1m 17s\tremaining: 2m 41s\n",
      "162:\tlearn: 0.0023547\ttotal: 1m 18s\tremaining: 2m 41s\n",
      "163:\tlearn: 0.0023503\ttotal: 1m 18s\tremaining: 2m 41s\n",
      "164:\tlearn: 0.0023457\ttotal: 1m 19s\tremaining: 2m 40s\n",
      "165:\tlearn: 0.0023409\ttotal: 1m 19s\tremaining: 2m 40s\n",
      "166:\tlearn: 0.0023370\ttotal: 1m 20s\tremaining: 2m 40s\n",
      "167:\tlearn: 0.0023328\ttotal: 1m 21s\tremaining: 2m 40s\n",
      "168:\tlearn: 0.0023284\ttotal: 1m 21s\tremaining: 2m 39s\n",
      "169:\tlearn: 0.0023244\ttotal: 1m 22s\tremaining: 2m 39s\n",
      "170:\tlearn: 0.0023199\ttotal: 1m 22s\tremaining: 2m 39s\n",
      "171:\tlearn: 0.0023168\ttotal: 1m 23s\tremaining: 2m 39s\n",
      "172:\tlearn: 0.0023139\ttotal: 1m 24s\tremaining: 2m 39s\n",
      "173:\tlearn: 0.0023101\ttotal: 1m 24s\tremaining: 2m 38s\n",
      "174:\tlearn: 0.0023070\ttotal: 1m 25s\tremaining: 2m 38s\n",
      "175:\tlearn: 0.0023018\ttotal: 1m 25s\tremaining: 2m 38s\n",
      "176:\tlearn: 0.0022986\ttotal: 1m 26s\tremaining: 2m 37s\n",
      "177:\tlearn: 0.0022950\ttotal: 1m 27s\tremaining: 2m 37s\n",
      "178:\tlearn: 0.0022928\ttotal: 1m 27s\tremaining: 2m 37s\n",
      "179:\tlearn: 0.0022905\ttotal: 1m 28s\tremaining: 2m 37s\n",
      "180:\tlearn: 0.0022876\ttotal: 1m 29s\tremaining: 2m 37s\n",
      "181:\tlearn: 0.0022857\ttotal: 1m 29s\tremaining: 2m 36s\n",
      "182:\tlearn: 0.0022826\ttotal: 1m 30s\tremaining: 2m 36s\n",
      "183:\tlearn: 0.0022796\ttotal: 1m 30s\tremaining: 2m 36s\n",
      "184:\tlearn: 0.0022763\ttotal: 1m 31s\tremaining: 2m 35s\n",
      "185:\tlearn: 0.0022743\ttotal: 1m 32s\tremaining: 2m 35s\n",
      "186:\tlearn: 0.0022723\ttotal: 1m 32s\tremaining: 2m 35s\n",
      "187:\tlearn: 0.0022700\ttotal: 1m 33s\tremaining: 2m 34s\n",
      "188:\tlearn: 0.0022690\ttotal: 1m 33s\tremaining: 2m 34s\n",
      "189:\tlearn: 0.0022664\ttotal: 1m 34s\tremaining: 2m 34s\n",
      "190:\tlearn: 0.0022639\ttotal: 1m 35s\tremaining: 2m 34s\n",
      "191:\tlearn: 0.0022626\ttotal: 1m 35s\tremaining: 2m 33s\n",
      "192:\tlearn: 0.0022601\ttotal: 1m 36s\tremaining: 2m 33s\n",
      "193:\tlearn: 0.0022582\ttotal: 1m 37s\tremaining: 2m 33s\n",
      "194:\tlearn: 0.0022563\ttotal: 1m 37s\tremaining: 2m 32s\n",
      "195:\tlearn: 0.0022541\ttotal: 1m 38s\tremaining: 2m 32s\n",
      "196:\tlearn: 0.0022528\ttotal: 1m 38s\tremaining: 2m 32s\n",
      "197:\tlearn: 0.0022515\ttotal: 1m 39s\tremaining: 2m 31s\n",
      "198:\tlearn: 0.0022503\ttotal: 1m 40s\tremaining: 2m 31s\n",
      "199:\tlearn: 0.0022457\ttotal: 1m 40s\tremaining: 2m 31s\n",
      "200:\tlearn: 0.0022441\ttotal: 1m 41s\tremaining: 2m 30s\n",
      "201:\tlearn: 0.0022420\ttotal: 1m 42s\tremaining: 2m 30s\n",
      "202:\tlearn: 0.0022408\ttotal: 1m 42s\tremaining: 2m 30s\n",
      "203:\tlearn: 0.0022379\ttotal: 1m 43s\tremaining: 2m 29s\n",
      "204:\tlearn: 0.0022358\ttotal: 1m 43s\tremaining: 2m 29s\n",
      "205:\tlearn: 0.0022347\ttotal: 1m 44s\tremaining: 2m 29s\n",
      "206:\tlearn: 0.0022332\ttotal: 1m 45s\tremaining: 2m 28s\n",
      "207:\tlearn: 0.0022320\ttotal: 1m 45s\tremaining: 2m 28s\n",
      "208:\tlearn: 0.0022307\ttotal: 1m 46s\tremaining: 2m 28s\n",
      "209:\tlearn: 0.0022293\ttotal: 1m 47s\tremaining: 2m 27s\n",
      "210:\tlearn: 0.0022268\ttotal: 1m 47s\tremaining: 2m 27s\n",
      "211:\tlearn: 0.0022251\ttotal: 1m 48s\tremaining: 2m 27s\n",
      "212:\tlearn: 0.0022242\ttotal: 1m 48s\tremaining: 2m 26s\n",
      "213:\tlearn: 0.0022221\ttotal: 1m 49s\tremaining: 2m 25s\n",
      "214:\tlearn: 0.0022171\ttotal: 1m 49s\tremaining: 2m 25s\n",
      "215:\tlearn: 0.0022153\ttotal: 1m 50s\tremaining: 2m 25s\n",
      "216:\tlearn: 0.0022132\ttotal: 1m 51s\tremaining: 2m 24s\n",
      "217:\tlearn: 0.0022123\ttotal: 1m 51s\tremaining: 2m 24s\n",
      "218:\tlearn: 0.0022111\ttotal: 1m 52s\tremaining: 2m 24s\n",
      "219:\tlearn: 0.0022096\ttotal: 1m 52s\tremaining: 2m 23s\n",
      "220:\tlearn: 0.0022083\ttotal: 1m 53s\tremaining: 2m 23s\n",
      "221:\tlearn: 0.0022073\ttotal: 1m 53s\tremaining: 2m 22s\n",
      "222:\tlearn: 0.0022047\ttotal: 1m 54s\tremaining: 2m 22s\n",
      "223:\tlearn: 0.0022035\ttotal: 1m 55s\tremaining: 2m 22s\n",
      "224:\tlearn: 0.0021988\ttotal: 1m 55s\tremaining: 2m 21s\n",
      "225:\tlearn: 0.0021981\ttotal: 1m 56s\tremaining: 2m 21s\n",
      "226:\tlearn: 0.0021969\ttotal: 1m 57s\tremaining: 2m 20s\n",
      "227:\tlearn: 0.0021953\ttotal: 1m 57s\tremaining: 2m 20s\n",
      "228:\tlearn: 0.0021922\ttotal: 1m 58s\tremaining: 2m 20s\n",
      "229:\tlearn: 0.0021905\ttotal: 1m 59s\tremaining: 2m 19s\n",
      "230:\tlearn: 0.0021891\ttotal: 1m 59s\tremaining: 2m 19s\n",
      "231:\tlearn: 0.0021874\ttotal: 2m\tremaining: 2m 18s\n",
      "232:\tlearn: 0.0021848\ttotal: 2m\tremaining: 2m 18s\n",
      "233:\tlearn: 0.0021843\ttotal: 2m 1s\tremaining: 2m 17s\n",
      "234:\tlearn: 0.0021820\ttotal: 2m 2s\tremaining: 2m 17s\n",
      "235:\tlearn: 0.0021814\ttotal: 2m 2s\tremaining: 2m 17s\n",
      "236:\tlearn: 0.0021791\ttotal: 2m 3s\tremaining: 2m 16s\n",
      "237:\tlearn: 0.0021768\ttotal: 2m 3s\tremaining: 2m 16s\n",
      "238:\tlearn: 0.0021745\ttotal: 2m 4s\tremaining: 2m 15s\n",
      "239:\tlearn: 0.0021739\ttotal: 2m 5s\tremaining: 2m 15s\n",
      "240:\tlearn: 0.0021732\ttotal: 2m 5s\tremaining: 2m 15s\n",
      "241:\tlearn: 0.0021707\ttotal: 2m 6s\tremaining: 2m 14s\n",
      "242:\tlearn: 0.0021686\ttotal: 2m 6s\tremaining: 2m 14s\n",
      "243:\tlearn: 0.0021684\ttotal: 2m 7s\tremaining: 2m 13s\n",
      "244:\tlearn: 0.0021655\ttotal: 2m 8s\tremaining: 2m 13s\n",
      "245:\tlearn: 0.0021648\ttotal: 2m 8s\tremaining: 2m 13s\n",
      "246:\tlearn: 0.0021639\ttotal: 2m 9s\tremaining: 2m 12s\n",
      "247:\tlearn: 0.0021624\ttotal: 2m 10s\tremaining: 2m 12s\n",
      "248:\tlearn: 0.0021614\ttotal: 2m 10s\tremaining: 2m 11s\n",
      "249:\tlearn: 0.0021566\ttotal: 2m 11s\tremaining: 2m 11s\n",
      "250:\tlearn: 0.0021509\ttotal: 2m 11s\tremaining: 2m 10s\n",
      "251:\tlearn: 0.0021494\ttotal: 2m 12s\tremaining: 2m 10s\n",
      "252:\tlearn: 0.0021466\ttotal: 2m 13s\tremaining: 2m 10s\n",
      "253:\tlearn: 0.0021406\ttotal: 2m 13s\tremaining: 2m 9s\n",
      "254:\tlearn: 0.0021400\ttotal: 2m 14s\tremaining: 2m 9s\n",
      "255:\tlearn: 0.0021393\ttotal: 2m 15s\tremaining: 2m 8s\n",
      "256:\tlearn: 0.0021385\ttotal: 2m 15s\tremaining: 2m 8s\n",
      "257:\tlearn: 0.0021363\ttotal: 2m 16s\tremaining: 2m 7s\n",
      "258:\tlearn: 0.0021354\ttotal: 2m 16s\tremaining: 2m 7s\n",
      "259:\tlearn: 0.0021340\ttotal: 2m 17s\tremaining: 2m 6s\n",
      "260:\tlearn: 0.0021334\ttotal: 2m 18s\tremaining: 2m 6s\n",
      "261:\tlearn: 0.0021321\ttotal: 2m 18s\tremaining: 2m 6s\n",
      "262:\tlearn: 0.0021304\ttotal: 2m 19s\tremaining: 2m 5s\n",
      "263:\tlearn: 0.0021297\ttotal: 2m 20s\tremaining: 2m 5s\n",
      "264:\tlearn: 0.0021289\ttotal: 2m 20s\tremaining: 2m 4s\n",
      "265:\tlearn: 0.0021278\ttotal: 2m 21s\tremaining: 2m 4s\n",
      "266:\tlearn: 0.0021266\ttotal: 2m 22s\tremaining: 2m 3s\n",
      "267:\tlearn: 0.0021262\ttotal: 2m 22s\tremaining: 2m 3s\n",
      "268:\tlearn: 0.0021247\ttotal: 2m 23s\tremaining: 2m 3s\n",
      "269:\tlearn: 0.0021240\ttotal: 2m 24s\tremaining: 2m 2s\n",
      "270:\tlearn: 0.0021232\ttotal: 2m 24s\tremaining: 2m 2s\n",
      "271:\tlearn: 0.0021200\ttotal: 2m 25s\tremaining: 2m 1s\n",
      "272:\tlearn: 0.0021181\ttotal: 2m 25s\tremaining: 2m 1s\n",
      "273:\tlearn: 0.0021158\ttotal: 2m 26s\tremaining: 2m\n",
      "274:\tlearn: 0.0021148\ttotal: 2m 27s\tremaining: 2m\n",
      "275:\tlearn: 0.0021127\ttotal: 2m 27s\tremaining: 1m 59s\n",
      "276:\tlearn: 0.0021114\ttotal: 2m 28s\tremaining: 1m 59s\n",
      "277:\tlearn: 0.0021108\ttotal: 2m 28s\tremaining: 1m 58s\n",
      "278:\tlearn: 0.0021106\ttotal: 2m 29s\tremaining: 1m 58s\n",
      "279:\tlearn: 0.0021095\ttotal: 2m 30s\tremaining: 1m 57s\n",
      "280:\tlearn: 0.0021067\ttotal: 2m 30s\tremaining: 1m 57s\n",
      "281:\tlearn: 0.0021049\ttotal: 2m 31s\tremaining: 1m 56s\n",
      "282:\tlearn: 0.0021037\ttotal: 2m 31s\tremaining: 1m 56s\n",
      "283:\tlearn: 0.0020994\ttotal: 2m 32s\tremaining: 1m 55s\n",
      "284:\tlearn: 0.0020961\ttotal: 2m 32s\tremaining: 1m 55s\n",
      "285:\tlearn: 0.0020948\ttotal: 2m 33s\tremaining: 1m 54s\n",
      "286:\tlearn: 0.0020932\ttotal: 2m 34s\tremaining: 1m 54s\n",
      "287:\tlearn: 0.0020921\ttotal: 2m 35s\tremaining: 1m 54s\n",
      "288:\tlearn: 0.0020912\ttotal: 2m 35s\tremaining: 1m 53s\n",
      "289:\tlearn: 0.0020905\ttotal: 2m 36s\tremaining: 1m 53s\n",
      "290:\tlearn: 0.0020891\ttotal: 2m 37s\tremaining: 1m 52s\n",
      "291:\tlearn: 0.0020878\ttotal: 2m 37s\tremaining: 1m 52s\n",
      "292:\tlearn: 0.0020860\ttotal: 2m 38s\tremaining: 1m 51s\n",
      "293:\tlearn: 0.0020856\ttotal: 2m 38s\tremaining: 1m 51s\n",
      "294:\tlearn: 0.0020845\ttotal: 2m 39s\tremaining: 1m 50s\n",
      "295:\tlearn: 0.0020825\ttotal: 2m 39s\tremaining: 1m 50s\n",
      "296:\tlearn: 0.0020796\ttotal: 2m 40s\tremaining: 1m 49s\n",
      "297:\tlearn: 0.0020774\ttotal: 2m 41s\tremaining: 1m 49s\n",
      "298:\tlearn: 0.0020747\ttotal: 2m 41s\tremaining: 1m 48s\n",
      "299:\tlearn: 0.0020735\ttotal: 2m 42s\tremaining: 1m 48s\n",
      "300:\tlearn: 0.0020729\ttotal: 2m 43s\tremaining: 1m 47s\n",
      "301:\tlearn: 0.0020674\ttotal: 2m 43s\tremaining: 1m 47s\n",
      "302:\tlearn: 0.0020667\ttotal: 2m 44s\tremaining: 1m 46s\n",
      "303:\tlearn: 0.0020658\ttotal: 2m 44s\tremaining: 1m 46s\n",
      "304:\tlearn: 0.0020650\ttotal: 2m 45s\tremaining: 1m 45s\n",
      "305:\tlearn: 0.0020647\ttotal: 2m 46s\tremaining: 1m 45s\n",
      "306:\tlearn: 0.0020637\ttotal: 2m 46s\tremaining: 1m 44s\n",
      "307:\tlearn: 0.0020613\ttotal: 2m 47s\tremaining: 1m 44s\n",
      "308:\tlearn: 0.0020602\ttotal: 2m 48s\tremaining: 1m 43s\n",
      "309:\tlearn: 0.0020593\ttotal: 2m 48s\tremaining: 1m 43s\n",
      "310:\tlearn: 0.0020552\ttotal: 2m 49s\tremaining: 1m 42s\n",
      "311:\tlearn: 0.0020540\ttotal: 2m 49s\tremaining: 1m 42s\n",
      "312:\tlearn: 0.0020520\ttotal: 2m 50s\tremaining: 1m 41s\n",
      "313:\tlearn: 0.0020514\ttotal: 2m 51s\tremaining: 1m 41s\n",
      "314:\tlearn: 0.0020511\ttotal: 2m 51s\tremaining: 1m 40s\n",
      "315:\tlearn: 0.0020491\ttotal: 2m 52s\tremaining: 1m 40s\n",
      "316:\tlearn: 0.0020483\ttotal: 2m 53s\tremaining: 1m 39s\n",
      "317:\tlearn: 0.0020469\ttotal: 2m 53s\tremaining: 1m 39s\n",
      "318:\tlearn: 0.0020420\ttotal: 2m 54s\tremaining: 1m 38s\n",
      "319:\tlearn: 0.0020415\ttotal: 2m 54s\tremaining: 1m 38s\n",
      "320:\tlearn: 0.0020405\ttotal: 2m 55s\tremaining: 1m 37s\n",
      "321:\tlearn: 0.0020389\ttotal: 2m 56s\tremaining: 1m 37s\n",
      "322:\tlearn: 0.0020381\ttotal: 2m 56s\tremaining: 1m 36s\n",
      "323:\tlearn: 0.0020372\ttotal: 2m 57s\tremaining: 1m 36s\n",
      "324:\tlearn: 0.0020359\ttotal: 2m 58s\tremaining: 1m 35s\n",
      "325:\tlearn: 0.0020357\ttotal: 2m 58s\tremaining: 1m 35s\n",
      "326:\tlearn: 0.0020340\ttotal: 2m 59s\tremaining: 1m 34s\n",
      "327:\tlearn: 0.0020333\ttotal: 3m\tremaining: 1m 34s\n",
      "328:\tlearn: 0.0020328\ttotal: 3m\tremaining: 1m 33s\n",
      "329:\tlearn: 0.0020311\ttotal: 3m 1s\tremaining: 1m 33s\n",
      "330:\tlearn: 0.0020302\ttotal: 3m 1s\tremaining: 1m 32s\n",
      "331:\tlearn: 0.0020297\ttotal: 3m 2s\tremaining: 1m 32s\n",
      "332:\tlearn: 0.0020275\ttotal: 3m 3s\tremaining: 1m 31s\n",
      "333:\tlearn: 0.0020271\ttotal: 3m 3s\tremaining: 1m 31s\n",
      "334:\tlearn: 0.0020236\ttotal: 3m 4s\tremaining: 1m 30s\n",
      "335:\tlearn: 0.0020224\ttotal: 3m 5s\tremaining: 1m 30s\n",
      "336:\tlearn: 0.0020216\ttotal: 3m 5s\tremaining: 1m 29s\n",
      "337:\tlearn: 0.0020196\ttotal: 3m 6s\tremaining: 1m 29s\n",
      "338:\tlearn: 0.0020187\ttotal: 3m 6s\tremaining: 1m 28s\n",
      "339:\tlearn: 0.0020180\ttotal: 3m 7s\tremaining: 1m 28s\n",
      "340:\tlearn: 0.0020175\ttotal: 3m 8s\tremaining: 1m 27s\n",
      "341:\tlearn: 0.0020163\ttotal: 3m 8s\tremaining: 1m 27s\n",
      "342:\tlearn: 0.0020142\ttotal: 3m 9s\tremaining: 1m 26s\n",
      "343:\tlearn: 0.0020134\ttotal: 3m 10s\tremaining: 1m 26s\n",
      "344:\tlearn: 0.0020113\ttotal: 3m 10s\tremaining: 1m 25s\n",
      "345:\tlearn: 0.0020104\ttotal: 3m 11s\tremaining: 1m 25s\n",
      "346:\tlearn: 0.0020100\ttotal: 3m 12s\tremaining: 1m 24s\n",
      "347:\tlearn: 0.0020089\ttotal: 3m 12s\tremaining: 1m 24s\n",
      "348:\tlearn: 0.0020086\ttotal: 3m 13s\tremaining: 1m 23s\n",
      "349:\tlearn: 0.0020076\ttotal: 3m 13s\tremaining: 1m 23s\n",
      "350:\tlearn: 0.0020068\ttotal: 3m 14s\tremaining: 1m 22s\n",
      "351:\tlearn: 0.0020062\ttotal: 3m 15s\tremaining: 1m 22s\n",
      "352:\tlearn: 0.0020033\ttotal: 3m 15s\tremaining: 1m 21s\n",
      "353:\tlearn: 0.0020031\ttotal: 3m 16s\tremaining: 1m 20s\n",
      "354:\tlearn: 0.0020025\ttotal: 3m 16s\tremaining: 1m 20s\n",
      "355:\tlearn: 0.0020014\ttotal: 3m 17s\tremaining: 1m 19s\n",
      "356:\tlearn: 0.0020001\ttotal: 3m 18s\tremaining: 1m 19s\n",
      "357:\tlearn: 0.0019980\ttotal: 3m 18s\tremaining: 1m 18s\n",
      "358:\tlearn: 0.0019976\ttotal: 3m 19s\tremaining: 1m 18s\n",
      "359:\tlearn: 0.0019955\ttotal: 3m 20s\tremaining: 1m 17s\n",
      "360:\tlearn: 0.0019927\ttotal: 3m 20s\tremaining: 1m 17s\n",
      "361:\tlearn: 0.0019912\ttotal: 3m 21s\tremaining: 1m 16s\n",
      "362:\tlearn: 0.0019901\ttotal: 3m 22s\tremaining: 1m 16s\n",
      "363:\tlearn: 0.0019856\ttotal: 3m 22s\tremaining: 1m 15s\n",
      "364:\tlearn: 0.0019854\ttotal: 3m 23s\tremaining: 1m 15s\n",
      "365:\tlearn: 0.0019835\ttotal: 3m 24s\tremaining: 1m 14s\n",
      "366:\tlearn: 0.0019825\ttotal: 3m 24s\tremaining: 1m 14s\n",
      "367:\tlearn: 0.0019810\ttotal: 3m 25s\tremaining: 1m 13s\n",
      "368:\tlearn: 0.0019792\ttotal: 3m 25s\tremaining: 1m 13s\n",
      "369:\tlearn: 0.0019789\ttotal: 3m 26s\tremaining: 1m 12s\n",
      "370:\tlearn: 0.0019744\ttotal: 3m 27s\tremaining: 1m 12s\n",
      "371:\tlearn: 0.0019737\ttotal: 3m 27s\tremaining: 1m 11s\n",
      "372:\tlearn: 0.0019730\ttotal: 3m 28s\tremaining: 1m 11s\n",
      "373:\tlearn: 0.0019720\ttotal: 3m 29s\tremaining: 1m 10s\n",
      "374:\tlearn: 0.0019715\ttotal: 3m 29s\tremaining: 1m 9s\n",
      "375:\tlearn: 0.0019701\ttotal: 3m 30s\tremaining: 1m 9s\n",
      "376:\tlearn: 0.0019687\ttotal: 3m 31s\tremaining: 1m 8s\n",
      "377:\tlearn: 0.0019643\ttotal: 3m 31s\tremaining: 1m 8s\n",
      "378:\tlearn: 0.0019611\ttotal: 3m 32s\tremaining: 1m 7s\n",
      "379:\tlearn: 0.0019610\ttotal: 3m 32s\tremaining: 1m 7s\n",
      "380:\tlearn: 0.0019601\ttotal: 3m 33s\tremaining: 1m 6s\n",
      "381:\tlearn: 0.0019592\ttotal: 3m 33s\tremaining: 1m 6s\n",
      "382:\tlearn: 0.0019588\ttotal: 3m 34s\tremaining: 1m 5s\n",
      "383:\tlearn: 0.0019586\ttotal: 3m 35s\tremaining: 1m 5s\n",
      "384:\tlearn: 0.0019567\ttotal: 3m 35s\tremaining: 1m 4s\n",
      "385:\tlearn: 0.0019566\ttotal: 3m 36s\tremaining: 1m 3s\n",
      "386:\tlearn: 0.0019550\ttotal: 3m 36s\tremaining: 1m 3s\n",
      "387:\tlearn: 0.0019544\ttotal: 3m 37s\tremaining: 1m 2s\n",
      "388:\tlearn: 0.0019542\ttotal: 3m 38s\tremaining: 1m 2s\n",
      "389:\tlearn: 0.0019538\ttotal: 3m 38s\tremaining: 1m 1s\n",
      "390:\tlearn: 0.0019517\ttotal: 3m 39s\tremaining: 1m 1s\n",
      "391:\tlearn: 0.0019493\ttotal: 3m 40s\tremaining: 1m\n",
      "392:\tlearn: 0.0019466\ttotal: 3m 40s\tremaining: 1m\n",
      "393:\tlearn: 0.0019455\ttotal: 3m 41s\tremaining: 59.5s\n",
      "394:\tlearn: 0.0019425\ttotal: 3m 41s\tremaining: 59s\n",
      "395:\tlearn: 0.0019387\ttotal: 3m 42s\tremaining: 58.4s\n",
      "396:\tlearn: 0.0019365\ttotal: 3m 43s\tremaining: 57.9s\n",
      "397:\tlearn: 0.0019358\ttotal: 3m 43s\tremaining: 57.4s\n",
      "398:\tlearn: 0.0019354\ttotal: 3m 44s\tremaining: 56.8s\n",
      "399:\tlearn: 0.0019334\ttotal: 3m 45s\tremaining: 56.3s\n",
      "400:\tlearn: 0.0019314\ttotal: 3m 45s\tremaining: 55.7s\n",
      "401:\tlearn: 0.0019310\ttotal: 3m 46s\tremaining: 55.1s\n",
      "402:\tlearn: 0.0019304\ttotal: 3m 46s\tremaining: 54.6s\n",
      "403:\tlearn: 0.0019301\ttotal: 3m 47s\tremaining: 54s\n",
      "404:\tlearn: 0.0019292\ttotal: 3m 48s\tremaining: 53.5s\n",
      "405:\tlearn: 0.0019267\ttotal: 3m 48s\tremaining: 52.9s\n",
      "406:\tlearn: 0.0019263\ttotal: 3m 49s\tremaining: 52.4s\n",
      "407:\tlearn: 0.0019257\ttotal: 3m 49s\tremaining: 51.8s\n",
      "408:\tlearn: 0.0019241\ttotal: 3m 50s\tremaining: 51.3s\n",
      "409:\tlearn: 0.0019233\ttotal: 3m 51s\tremaining: 50.7s\n",
      "410:\tlearn: 0.0019231\ttotal: 3m 51s\tremaining: 50.2s\n",
      "411:\tlearn: 0.0019225\ttotal: 3m 52s\tremaining: 49.6s\n",
      "412:\tlearn: 0.0019212\ttotal: 3m 53s\tremaining: 49.1s\n",
      "413:\tlearn: 0.0019195\ttotal: 3m 53s\tremaining: 48.5s\n",
      "414:\tlearn: 0.0019175\ttotal: 3m 54s\tremaining: 48s\n",
      "415:\tlearn: 0.0019174\ttotal: 3m 54s\tremaining: 47.4s\n",
      "416:\tlearn: 0.0019171\ttotal: 3m 55s\tremaining: 46.9s\n",
      "417:\tlearn: 0.0019170\ttotal: 3m 56s\tremaining: 46.4s\n",
      "418:\tlearn: 0.0019167\ttotal: 3m 56s\tremaining: 45.8s\n",
      "419:\tlearn: 0.0019155\ttotal: 3m 57s\tremaining: 45.3s\n",
      "420:\tlearn: 0.0019154\ttotal: 3m 58s\tremaining: 44.7s\n",
      "421:\tlearn: 0.0019147\ttotal: 3m 58s\tremaining: 44.2s\n",
      "422:\tlearn: 0.0019141\ttotal: 3m 59s\tremaining: 43.6s\n",
      "423:\tlearn: 0.0019137\ttotal: 4m\tremaining: 43s\n",
      "424:\tlearn: 0.0019135\ttotal: 4m\tremaining: 42.5s\n",
      "425:\tlearn: 0.0019110\ttotal: 4m 1s\tremaining: 41.9s\n",
      "426:\tlearn: 0.0019071\ttotal: 4m 1s\tremaining: 41.4s\n",
      "427:\tlearn: 0.0019058\ttotal: 4m 2s\tremaining: 40.8s\n",
      "428:\tlearn: 0.0019053\ttotal: 4m 3s\tremaining: 40.3s\n",
      "429:\tlearn: 0.0019043\ttotal: 4m 3s\tremaining: 39.7s\n",
      "430:\tlearn: 0.0019036\ttotal: 4m 4s\tremaining: 39.1s\n",
      "431:\tlearn: 0.0019022\ttotal: 4m 5s\tremaining: 38.6s\n",
      "432:\tlearn: 0.0019011\ttotal: 4m 5s\tremaining: 38s\n",
      "433:\tlearn: 0.0019008\ttotal: 4m 6s\tremaining: 37.5s\n",
      "434:\tlearn: 0.0019000\ttotal: 4m 6s\tremaining: 36.9s\n",
      "435:\tlearn: 0.0018998\ttotal: 4m 7s\tremaining: 36.4s\n",
      "436:\tlearn: 0.0018976\ttotal: 4m 8s\tremaining: 35.8s\n",
      "437:\tlearn: 0.0018930\ttotal: 4m 8s\tremaining: 35.2s\n",
      "438:\tlearn: 0.0018912\ttotal: 4m 9s\tremaining: 34.7s\n",
      "439:\tlearn: 0.0018910\ttotal: 4m 10s\tremaining: 34.1s\n",
      "440:\tlearn: 0.0018880\ttotal: 4m 10s\tremaining: 33.5s\n",
      "441:\tlearn: 0.0018878\ttotal: 4m 11s\tremaining: 33s\n",
      "442:\tlearn: 0.0018877\ttotal: 4m 12s\tremaining: 32.4s\n",
      "443:\tlearn: 0.0018862\ttotal: 4m 12s\tremaining: 31.9s\n",
      "444:\tlearn: 0.0018860\ttotal: 4m 13s\tremaining: 31.3s\n",
      "445:\tlearn: 0.0018859\ttotal: 4m 13s\tremaining: 30.7s\n",
      "446:\tlearn: 0.0018839\ttotal: 4m 14s\tremaining: 30.2s\n",
      "447:\tlearn: 0.0018811\ttotal: 4m 15s\tremaining: 29.6s\n",
      "448:\tlearn: 0.0018795\ttotal: 4m 15s\tremaining: 29.1s\n",
      "449:\tlearn: 0.0018779\ttotal: 4m 16s\tremaining: 28.5s\n",
      "450:\tlearn: 0.0018756\ttotal: 4m 17s\tremaining: 27.9s\n",
      "451:\tlearn: 0.0018748\ttotal: 4m 17s\tremaining: 27.4s\n",
      "452:\tlearn: 0.0018741\ttotal: 4m 18s\tremaining: 26.8s\n",
      "453:\tlearn: 0.0018731\ttotal: 4m 18s\tremaining: 26.2s\n",
      "454:\tlearn: 0.0018725\ttotal: 4m 19s\tremaining: 25.7s\n",
      "455:\tlearn: 0.0018721\ttotal: 4m 20s\tremaining: 25.1s\n",
      "456:\tlearn: 0.0018707\ttotal: 4m 20s\tremaining: 24.5s\n",
      "457:\tlearn: 0.0018706\ttotal: 4m 21s\tremaining: 24s\n",
      "458:\tlearn: 0.0018694\ttotal: 4m 22s\tremaining: 23.4s\n",
      "459:\tlearn: 0.0018661\ttotal: 4m 22s\tremaining: 22.9s\n",
      "460:\tlearn: 0.0018647\ttotal: 4m 23s\tremaining: 22.3s\n",
      "461:\tlearn: 0.0018646\ttotal: 4m 24s\tremaining: 21.7s\n",
      "462:\tlearn: 0.0018622\ttotal: 4m 24s\tremaining: 21.2s\n",
      "463:\tlearn: 0.0018594\ttotal: 4m 25s\tremaining: 20.6s\n",
      "464:\tlearn: 0.0018593\ttotal: 4m 25s\tremaining: 20s\n",
      "465:\tlearn: 0.0018586\ttotal: 4m 26s\tremaining: 19.4s\n",
      "466:\tlearn: 0.0018546\ttotal: 4m 27s\tremaining: 18.9s\n",
      "467:\tlearn: 0.0018525\ttotal: 4m 27s\tremaining: 18.3s\n",
      "468:\tlearn: 0.0018523\ttotal: 4m 28s\tremaining: 17.7s\n",
      "469:\tlearn: 0.0018517\ttotal: 4m 29s\tremaining: 17.2s\n",
      "470:\tlearn: 0.0018514\ttotal: 4m 29s\tremaining: 16.6s\n",
      "471:\tlearn: 0.0018489\ttotal: 4m 30s\tremaining: 16s\n",
      "472:\tlearn: 0.0018488\ttotal: 4m 31s\tremaining: 15.5s\n",
      "473:\tlearn: 0.0018479\ttotal: 4m 31s\tremaining: 14.9s\n",
      "474:\tlearn: 0.0018460\ttotal: 4m 32s\tremaining: 14.3s\n",
      "475:\tlearn: 0.0018456\ttotal: 4m 32s\tremaining: 13.8s\n",
      "476:\tlearn: 0.0018452\ttotal: 4m 33s\tremaining: 13.2s\n",
      "477:\tlearn: 0.0018436\ttotal: 4m 34s\tremaining: 12.6s\n",
      "478:\tlearn: 0.0018434\ttotal: 4m 34s\tremaining: 12s\n",
      "479:\tlearn: 0.0018432\ttotal: 4m 35s\tremaining: 11.5s\n",
      "480:\tlearn: 0.0018431\ttotal: 4m 36s\tremaining: 10.9s\n",
      "481:\tlearn: 0.0018427\ttotal: 4m 36s\tremaining: 10.3s\n",
      "482:\tlearn: 0.0018426\ttotal: 4m 37s\tremaining: 9.76s\n",
      "483:\tlearn: 0.0018413\ttotal: 4m 37s\tremaining: 9.18s\n",
      "484:\tlearn: 0.0018412\ttotal: 4m 38s\tremaining: 8.62s\n",
      "485:\tlearn: 0.0018409\ttotal: 4m 39s\tremaining: 8.04s\n",
      "486:\tlearn: 0.0018384\ttotal: 4m 39s\tremaining: 7.47s\n",
      "487:\tlearn: 0.0018383\ttotal: 4m 40s\tremaining: 6.9s\n",
      "488:\tlearn: 0.0018377\ttotal: 4m 41s\tremaining: 6.33s\n",
      "489:\tlearn: 0.0018376\ttotal: 4m 41s\tremaining: 5.75s\n",
      "490:\tlearn: 0.0018354\ttotal: 4m 42s\tremaining: 5.18s\n",
      "491:\tlearn: 0.0018343\ttotal: 4m 43s\tremaining: 4.61s\n",
      "492:\tlearn: 0.0018327\ttotal: 4m 43s\tremaining: 4.03s\n",
      "493:\tlearn: 0.0018303\ttotal: 4m 44s\tremaining: 3.46s\n",
      "494:\tlearn: 0.0018282\ttotal: 4m 45s\tremaining: 2.88s\n",
      "495:\tlearn: 0.0018280\ttotal: 4m 45s\tremaining: 2.31s\n",
      "496:\tlearn: 0.0018277\ttotal: 4m 46s\tremaining: 1.73s\n",
      "497:\tlearn: 0.0018275\ttotal: 4m 47s\tremaining: 1.15s\n",
      "498:\tlearn: 0.0018274\ttotal: 4m 47s\tremaining: 577ms\n",
      "499:\tlearn: 0.0018269\ttotal: 4m 48s\tremaining: 0us\n",
      "Accuracy: 0.9997131382673551\n",
      "\n",
      "Confusion Matrix:\n",
      " [[76670     0]\n",
      " [   22     0]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     76670\n",
      "           1       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           1.00     76692\n",
      "   macro avg       0.50      0.50      0.50     76692\n",
      "weighted avg       1.00      1.00      1.00     76692\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Fraud','FraudType'], axis=1)\n",
    "y = df['Fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a CatBoost Classifier\n",
    "model = CatBoostClassifier(iterations=500, depth=10, learning_rate=0.05, loss_function='MultiClass', random_seed=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, cat_features=None)  # You can specify categorical features if needed\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/DMEPOS/dmepos_rus_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0.1\",\"Unnamed: 0\",\"Rfrg_NPI\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rfrg_Prvdr_Crdntls</th>\n",
       "      <th>Rfrg_Prvdr_Gndr</th>\n",
       "      <th>Rfrg_Prvdr_Type</th>\n",
       "      <th>Rfrg_Prvdr_Type_Flag</th>\n",
       "      <th>Tot_Suplrs</th>\n",
       "      <th>Tot_Suplr_HCPCS_Cds</th>\n",
       "      <th>Tot_Suplr_Benes</th>\n",
       "      <th>Tot_Suplr_Clms</th>\n",
       "      <th>Tot_Suplr_Srvcs</th>\n",
       "      <th>Suplr_Sbmtd_Chrgs</th>\n",
       "      <th>...</th>\n",
       "      <th>Bene_CC_Dbts_Pct</th>\n",
       "      <th>Bene_CC_Hyplpdma_Pct</th>\n",
       "      <th>Bene_CC_Hyprtnsn_Pct</th>\n",
       "      <th>Bene_CC_IHD_Pct</th>\n",
       "      <th>Bene_CC_Opo_Pct</th>\n",
       "      <th>Bene_CC_RAOA_Pct</th>\n",
       "      <th>Bene_CC_Sz_Pct</th>\n",
       "      <th>Bene_CC_Strok_Pct</th>\n",
       "      <th>Bene_Avg_Risk_Scre</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4437</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "      <td>4202.72</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.806234</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>42.0</td>\n",
       "      <td>220</td>\n",
       "      <td>324</td>\n",
       "      <td>53997.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>3.433250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4587</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>34</td>\n",
       "      <td>172</td>\n",
       "      <td>6297.83</td>\n",
       "      <td>...</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.244400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>419</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>25.0</td>\n",
       "      <td>32</td>\n",
       "      <td>1503</td>\n",
       "      <td>8361.72</td>\n",
       "      <td>...</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.217893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>112.0</td>\n",
       "      <td>372</td>\n",
       "      <td>96088</td>\n",
       "      <td>437064.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.338480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>3017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>20.0</td>\n",
       "      <td>58</td>\n",
       "      <td>2584</td>\n",
       "      <td>21190.91</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.013313</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>13.0</td>\n",
       "      <td>44</td>\n",
       "      <td>468</td>\n",
       "      <td>5537.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.464125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>3017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>929.52</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.301000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>3017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>61.0</td>\n",
       "      <td>84</td>\n",
       "      <td>491</td>\n",
       "      <td>44971.91</td>\n",
       "      <td>...</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.282148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>3017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "      <td>1651.46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.225500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rfrg_Prvdr_Crdntls  Rfrg_Prvdr_Gndr  Rfrg_Prvdr_Type  \\\n",
       "0                  4437              1.0               65   \n",
       "1                  1997              1.0               65   \n",
       "2                  4587              0.0               87   \n",
       "3                   419              1.0               65   \n",
       "4                  2362              0.0               30   \n",
       "..                  ...              ...              ...   \n",
       "199                3017              0.0               26   \n",
       "200                2362              0.0               29   \n",
       "201                3017              0.0               26   \n",
       "202                3017              0.0               29   \n",
       "203                3017              0.0               44   \n",
       "\n",
       "     Rfrg_Prvdr_Type_Flag  Tot_Suplrs  Tot_Suplr_HCPCS_Cds  Tot_Suplr_Benes  \\\n",
       "0                     1.0           2                   10             16.0   \n",
       "1                     1.0           6                   22             42.0   \n",
       "2                     1.0           5                    9             18.0   \n",
       "3                     1.0           5                    7             25.0   \n",
       "4                     1.0          12                   18            112.0   \n",
       "..                    ...         ...                  ...              ...   \n",
       "199                   1.0          19                   22             20.0   \n",
       "200                   1.0           4                   16             13.0   \n",
       "201                   1.0           1                    1             17.0   \n",
       "202                   0.0          14                   18             61.0   \n",
       "203                   1.0           2                    3             20.0   \n",
       "\n",
       "     Tot_Suplr_Clms  Tot_Suplr_Srvcs  Suplr_Sbmtd_Chrgs  ...  \\\n",
       "0                18               41            4202.72  ...   \n",
       "1               220              324           53997.47  ...   \n",
       "2                34              172            6297.83  ...   \n",
       "3                32             1503            8361.72  ...   \n",
       "4               372            96088          437064.15  ...   \n",
       "..              ...              ...                ...  ...   \n",
       "199              58             2584           21190.91  ...   \n",
       "200              44              468            5537.80  ...   \n",
       "201              12               12             929.52  ...   \n",
       "202              84              491           44971.91  ...   \n",
       "203              15               26            1651.46  ...   \n",
       "\n",
       "     Bene_CC_Dbts_Pct  Bene_CC_Hyplpdma_Pct  Bene_CC_Hyprtnsn_Pct  \\\n",
       "0                0.75                  0.75                  0.75   \n",
       "1                0.60                  0.75                  0.75   \n",
       "2                0.70                  0.61                  0.73   \n",
       "3                0.56                  0.69                  0.59   \n",
       "4                0.70                  0.63                  0.75   \n",
       "..                ...                   ...                   ...   \n",
       "199              0.75                  0.70                  0.75   \n",
       "200              0.42                  0.65                  0.75   \n",
       "201              0.75                  0.69                  0.75   \n",
       "202              0.46                  0.57                  0.75   \n",
       "203              0.55                  0.69                  0.75   \n",
       "\n",
       "     Bene_CC_IHD_Pct  Bene_CC_Opo_Pct  Bene_CC_RAOA_Pct  Bene_CC_Sz_Pct  \\\n",
       "0               0.75             0.00              0.72             0.0   \n",
       "1               0.67             0.20              0.69             0.0   \n",
       "2               0.64             0.00              0.64             0.0   \n",
       "3               0.63             0.00              0.50             0.0   \n",
       "4               0.61             0.21              0.23             0.0   \n",
       "..               ...              ...               ...             ...   \n",
       "199             0.55             0.00              0.56             0.0   \n",
       "200             0.21             0.00              0.40             0.0   \n",
       "201             0.53             0.00              0.75             0.0   \n",
       "202             0.46             0.17              0.51             0.0   \n",
       "203             0.68             0.00              0.75             0.0   \n",
       "\n",
       "     Bene_CC_Strok_Pct  Bene_Avg_Risk_Scre  Fraud  \n",
       "0                 0.00            6.806234      0  \n",
       "1                 0.09            3.433250      0  \n",
       "2                 0.00            2.244400      0  \n",
       "3                 0.00            1.217893      0  \n",
       "4                 0.00            8.338480      0  \n",
       "..                 ...                 ...    ...  \n",
       "199               0.00            2.013313      1  \n",
       "200               0.00            2.464125      1  \n",
       "201               0.00            4.301000      1  \n",
       "202               0.00            1.282148      1  \n",
       "203               0.00            4.225500      1  \n",
       "\n",
       "[204 rows x 76 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6859936\ttotal: 86.9ms\tremaining: 43.4s\n",
      "1:\tlearn: 0.6767634\ttotal: 182ms\tremaining: 45.3s\n",
      "2:\tlearn: 0.6706037\ttotal: 284ms\tremaining: 47.1s\n",
      "3:\tlearn: 0.6605775\ttotal: 375ms\tremaining: 46.5s\n",
      "4:\tlearn: 0.6525874\ttotal: 468ms\tremaining: 46.3s\n",
      "5:\tlearn: 0.6454960\ttotal: 550ms\tremaining: 45.3s\n",
      "6:\tlearn: 0.6386224\ttotal: 621ms\tremaining: 43.7s\n",
      "7:\tlearn: 0.6319520\ttotal: 680ms\tremaining: 41.8s\n",
      "8:\tlearn: 0.6250081\ttotal: 768ms\tremaining: 41.9s\n",
      "9:\tlearn: 0.6210773\ttotal: 840ms\tremaining: 41.2s\n",
      "10:\tlearn: 0.6142555\ttotal: 909ms\tremaining: 40.4s\n",
      "11:\tlearn: 0.6082572\ttotal: 1.01s\tremaining: 41.2s\n",
      "12:\tlearn: 0.6032054\ttotal: 1.09s\tremaining: 40.9s\n",
      "13:\tlearn: 0.5977951\ttotal: 1.17s\tremaining: 40.7s\n",
      "14:\tlearn: 0.5922840\ttotal: 1.28s\tremaining: 41.3s\n",
      "15:\tlearn: 0.5863956\ttotal: 1.34s\tremaining: 40.4s\n",
      "16:\tlearn: 0.5812775\ttotal: 1.46s\tremaining: 41.5s\n",
      "17:\tlearn: 0.5757718\ttotal: 1.57s\tremaining: 42s\n",
      "18:\tlearn: 0.5698619\ttotal: 1.6s\tremaining: 40.6s\n",
      "19:\tlearn: 0.5646718\ttotal: 1.69s\tremaining: 40.5s\n",
      "20:\tlearn: 0.5598589\ttotal: 1.75s\tremaining: 40s\n",
      "21:\tlearn: 0.5549486\ttotal: 1.82s\tremaining: 39.6s\n",
      "22:\tlearn: 0.5507261\ttotal: 1.89s\tremaining: 39.3s\n",
      "23:\tlearn: 0.5452063\ttotal: 1.94s\tremaining: 38.4s\n",
      "24:\tlearn: 0.5400431\ttotal: 2.01s\tremaining: 38.2s\n",
      "25:\tlearn: 0.5349048\ttotal: 2.15s\tremaining: 39.3s\n",
      "26:\tlearn: 0.5307540\ttotal: 2.26s\tremaining: 39.6s\n",
      "27:\tlearn: 0.5251489\ttotal: 2.33s\tremaining: 39.3s\n",
      "28:\tlearn: 0.5206257\ttotal: 2.4s\tremaining: 39s\n",
      "29:\tlearn: 0.5166083\ttotal: 2.47s\tremaining: 38.7s\n",
      "30:\tlearn: 0.5122697\ttotal: 2.56s\tremaining: 38.7s\n",
      "31:\tlearn: 0.5072697\ttotal: 2.66s\tremaining: 38.9s\n",
      "32:\tlearn: 0.5035881\ttotal: 2.75s\tremaining: 38.9s\n",
      "33:\tlearn: 0.4996476\ttotal: 2.82s\tremaining: 38.7s\n",
      "34:\tlearn: 0.4958752\ttotal: 2.89s\tremaining: 38.4s\n",
      "35:\tlearn: 0.4916719\ttotal: 2.97s\tremaining: 38.2s\n",
      "36:\tlearn: 0.4887255\ttotal: 2.99s\tremaining: 37.5s\n",
      "37:\tlearn: 0.4842914\ttotal: 3.08s\tremaining: 37.5s\n",
      "38:\tlearn: 0.4798641\ttotal: 3.16s\tremaining: 37.3s\n",
      "39:\tlearn: 0.4767129\ttotal: 3.22s\tremaining: 37s\n",
      "40:\tlearn: 0.4728083\ttotal: 3.34s\tremaining: 37.4s\n",
      "41:\tlearn: 0.4684974\ttotal: 3.46s\tremaining: 37.8s\n",
      "42:\tlearn: 0.4654046\ttotal: 3.56s\tremaining: 37.8s\n",
      "43:\tlearn: 0.4614666\ttotal: 3.63s\tremaining: 37.6s\n",
      "44:\tlearn: 0.4570708\ttotal: 3.72s\tremaining: 37.6s\n",
      "45:\tlearn: 0.4532556\ttotal: 3.78s\tremaining: 37.4s\n",
      "46:\tlearn: 0.4489273\ttotal: 3.84s\tremaining: 37s\n",
      "47:\tlearn: 0.4451434\ttotal: 3.92s\tremaining: 36.9s\n",
      "48:\tlearn: 0.4425637\ttotal: 4s\tremaining: 36.8s\n",
      "49:\tlearn: 0.4399597\ttotal: 4.08s\tremaining: 36.7s\n",
      "50:\tlearn: 0.4362002\ttotal: 4.17s\tremaining: 36.7s\n",
      "51:\tlearn: 0.4334495\ttotal: 4.19s\tremaining: 36.1s\n",
      "52:\tlearn: 0.4296164\ttotal: 4.33s\tremaining: 36.5s\n",
      "53:\tlearn: 0.4265570\ttotal: 4.39s\tremaining: 36.3s\n",
      "54:\tlearn: 0.4234326\ttotal: 4.44s\tremaining: 35.9s\n",
      "55:\tlearn: 0.4194080\ttotal: 4.53s\tremaining: 35.9s\n",
      "56:\tlearn: 0.4165464\ttotal: 4.6s\tremaining: 35.7s\n",
      "57:\tlearn: 0.4136689\ttotal: 4.72s\tremaining: 36s\n",
      "58:\tlearn: 0.4108056\ttotal: 4.84s\tremaining: 36.2s\n",
      "59:\tlearn: 0.4080227\ttotal: 4.94s\tremaining: 36.2s\n",
      "60:\tlearn: 0.4055087\ttotal: 5.11s\tremaining: 36.8s\n",
      "61:\tlearn: 0.4023824\ttotal: 5.18s\tremaining: 36.6s\n",
      "62:\tlearn: 0.3996013\ttotal: 5.21s\tremaining: 36.1s\n",
      "63:\tlearn: 0.3969702\ttotal: 5.25s\tremaining: 35.8s\n",
      "64:\tlearn: 0.3937812\ttotal: 5.38s\tremaining: 36s\n",
      "65:\tlearn: 0.3903500\ttotal: 5.45s\tremaining: 35.8s\n",
      "66:\tlearn: 0.3872021\ttotal: 5.59s\tremaining: 36.1s\n",
      "67:\tlearn: 0.3839939\ttotal: 5.66s\tremaining: 36s\n",
      "68:\tlearn: 0.3807560\ttotal: 5.78s\tremaining: 36.1s\n",
      "69:\tlearn: 0.3781199\ttotal: 5.89s\tremaining: 36.2s\n",
      "70:\tlearn: 0.3752990\ttotal: 5.99s\tremaining: 36.2s\n",
      "71:\tlearn: 0.3723575\ttotal: 6.07s\tremaining: 36.1s\n",
      "72:\tlearn: 0.3695583\ttotal: 6.14s\tremaining: 35.9s\n",
      "73:\tlearn: 0.3662325\ttotal: 6.22s\tremaining: 35.8s\n",
      "74:\tlearn: 0.3642805\ttotal: 6.28s\tremaining: 35.6s\n",
      "75:\tlearn: 0.3613883\ttotal: 6.34s\tremaining: 35.4s\n",
      "76:\tlearn: 0.3587067\ttotal: 6.39s\tremaining: 35.1s\n",
      "77:\tlearn: 0.3561849\ttotal: 6.53s\tremaining: 35.3s\n",
      "78:\tlearn: 0.3535174\ttotal: 6.6s\tremaining: 35.2s\n",
      "79:\tlearn: 0.3514575\ttotal: 6.67s\tremaining: 35s\n",
      "80:\tlearn: 0.3486894\ttotal: 6.74s\tremaining: 34.9s\n",
      "81:\tlearn: 0.3464100\ttotal: 6.84s\tremaining: 34.9s\n",
      "82:\tlearn: 0.3437539\ttotal: 6.92s\tremaining: 34.8s\n",
      "83:\tlearn: 0.3414972\ttotal: 6.97s\tremaining: 34.5s\n",
      "84:\tlearn: 0.3386845\ttotal: 7.07s\tremaining: 34.5s\n",
      "85:\tlearn: 0.3360344\ttotal: 7.25s\tremaining: 34.9s\n",
      "86:\tlearn: 0.3342378\ttotal: 7.31s\tremaining: 34.7s\n",
      "87:\tlearn: 0.3318272\ttotal: 7.4s\tremaining: 34.6s\n",
      "88:\tlearn: 0.3301386\ttotal: 7.42s\tremaining: 34.3s\n",
      "89:\tlearn: 0.3280747\ttotal: 7.45s\tremaining: 33.9s\n",
      "90:\tlearn: 0.3256193\ttotal: 7.59s\tremaining: 34.1s\n",
      "91:\tlearn: 0.3233652\ttotal: 7.66s\tremaining: 34s\n",
      "92:\tlearn: 0.3209292\ttotal: 7.74s\tremaining: 33.9s\n",
      "93:\tlearn: 0.3188396\ttotal: 7.83s\tremaining: 33.8s\n",
      "94:\tlearn: 0.3167012\ttotal: 7.92s\tremaining: 33.8s\n",
      "95:\tlearn: 0.3148073\ttotal: 8.04s\tremaining: 33.9s\n",
      "96:\tlearn: 0.3120877\ttotal: 8.17s\tremaining: 33.9s\n",
      "97:\tlearn: 0.3099204\ttotal: 8.24s\tremaining: 33.8s\n",
      "98:\tlearn: 0.3083319\ttotal: 8.35s\tremaining: 33.8s\n",
      "99:\tlearn: 0.3064212\ttotal: 8.42s\tremaining: 33.7s\n",
      "100:\tlearn: 0.3045089\ttotal: 8.47s\tremaining: 33.5s\n",
      "101:\tlearn: 0.3027237\ttotal: 8.54s\tremaining: 33.3s\n",
      "102:\tlearn: 0.3012382\ttotal: 8.66s\tremaining: 33.4s\n",
      "103:\tlearn: 0.2993364\ttotal: 8.73s\tremaining: 33.2s\n",
      "104:\tlearn: 0.2975235\ttotal: 8.86s\tremaining: 33.3s\n",
      "105:\tlearn: 0.2957757\ttotal: 8.93s\tremaining: 33.2s\n",
      "106:\tlearn: 0.2933852\ttotal: 8.99s\tremaining: 33s\n",
      "107:\tlearn: 0.2916740\ttotal: 9.07s\tremaining: 32.9s\n",
      "108:\tlearn: 0.2894083\ttotal: 9.13s\tremaining: 32.7s\n",
      "109:\tlearn: 0.2870028\ttotal: 9.22s\tremaining: 32.7s\n",
      "110:\tlearn: 0.2845683\ttotal: 9.33s\tremaining: 32.7s\n",
      "111:\tlearn: 0.2827550\ttotal: 9.4s\tremaining: 32.6s\n",
      "112:\tlearn: 0.2812889\ttotal: 9.47s\tremaining: 32.4s\n",
      "113:\tlearn: 0.2792137\ttotal: 9.55s\tremaining: 32.3s\n",
      "114:\tlearn: 0.2772040\ttotal: 9.62s\tremaining: 32.2s\n",
      "115:\tlearn: 0.2752720\ttotal: 9.65s\tremaining: 31.9s\n",
      "116:\tlearn: 0.2737722\ttotal: 9.76s\tremaining: 31.9s\n",
      "117:\tlearn: 0.2718452\ttotal: 9.88s\tremaining: 32s\n",
      "118:\tlearn: 0.2699789\ttotal: 9.95s\tremaining: 31.9s\n",
      "119:\tlearn: 0.2678913\ttotal: 10s\tremaining: 31.8s\n",
      "120:\tlearn: 0.2658371\ttotal: 10.2s\tremaining: 31.9s\n",
      "121:\tlearn: 0.2641196\ttotal: 10.2s\tremaining: 31.7s\n",
      "122:\tlearn: 0.2621229\ttotal: 10.4s\tremaining: 31.8s\n",
      "123:\tlearn: 0.2603062\ttotal: 10.4s\tremaining: 31.7s\n",
      "124:\tlearn: 0.2580848\ttotal: 10.5s\tremaining: 31.6s\n",
      "125:\tlearn: 0.2560094\ttotal: 10.6s\tremaining: 31.5s\n",
      "126:\tlearn: 0.2541412\ttotal: 10.7s\tremaining: 31.3s\n",
      "127:\tlearn: 0.2522857\ttotal: 10.7s\tremaining: 31.2s\n",
      "128:\tlearn: 0.2504591\ttotal: 10.8s\tremaining: 31s\n",
      "129:\tlearn: 0.2488249\ttotal: 10.9s\tremaining: 31.1s\n",
      "130:\tlearn: 0.2470902\ttotal: 11s\tremaining: 31s\n",
      "131:\tlearn: 0.2451285\ttotal: 11.1s\tremaining: 31s\n",
      "132:\tlearn: 0.2435331\ttotal: 11.2s\tremaining: 30.8s\n",
      "133:\tlearn: 0.2417538\ttotal: 11.2s\tremaining: 30.7s\n",
      "134:\tlearn: 0.2402714\ttotal: 11.3s\tremaining: 30.6s\n",
      "135:\tlearn: 0.2384133\ttotal: 11.4s\tremaining: 30.6s\n",
      "136:\tlearn: 0.2365420\ttotal: 11.5s\tremaining: 30.5s\n",
      "137:\tlearn: 0.2343692\ttotal: 11.6s\tremaining: 30.4s\n",
      "138:\tlearn: 0.2327245\ttotal: 11.7s\tremaining: 30.3s\n",
      "139:\tlearn: 0.2308919\ttotal: 11.8s\tremaining: 30.2s\n",
      "140:\tlearn: 0.2294872\ttotal: 11.9s\tremaining: 30.2s\n",
      "141:\tlearn: 0.2281469\ttotal: 11.9s\tremaining: 30s\n",
      "142:\tlearn: 0.2266723\ttotal: 12s\tremaining: 29.9s\n",
      "143:\tlearn: 0.2251851\ttotal: 12s\tremaining: 29.7s\n",
      "144:\tlearn: 0.2235347\ttotal: 12.1s\tremaining: 29.7s\n",
      "145:\tlearn: 0.2218598\ttotal: 12.2s\tremaining: 29.7s\n",
      "146:\tlearn: 0.2201433\ttotal: 12.3s\tremaining: 29.5s\n",
      "147:\tlearn: 0.2185064\ttotal: 12.4s\tremaining: 29.4s\n",
      "148:\tlearn: 0.2171932\ttotal: 12.4s\tremaining: 29.3s\n",
      "149:\tlearn: 0.2155538\ttotal: 12.6s\tremaining: 29.3s\n",
      "150:\tlearn: 0.2140749\ttotal: 12.6s\tremaining: 29.2s\n",
      "151:\tlearn: 0.2125474\ttotal: 12.7s\tremaining: 29s\n",
      "152:\tlearn: 0.2111343\ttotal: 12.7s\tremaining: 28.9s\n",
      "153:\tlearn: 0.2097667\ttotal: 12.8s\tremaining: 28.8s\n",
      "154:\tlearn: 0.2085649\ttotal: 12.9s\tremaining: 28.8s\n",
      "155:\tlearn: 0.2071875\ttotal: 13.1s\tremaining: 28.8s\n",
      "156:\tlearn: 0.2058911\ttotal: 13.1s\tremaining: 28.7s\n",
      "157:\tlearn: 0.2046319\ttotal: 13.2s\tremaining: 28.5s\n",
      "158:\tlearn: 0.2032410\ttotal: 13.3s\tremaining: 28.4s\n",
      "159:\tlearn: 0.2020241\ttotal: 13.3s\tremaining: 28.3s\n",
      "160:\tlearn: 0.2006208\ttotal: 13.4s\tremaining: 28.3s\n",
      "161:\tlearn: 0.1991678\ttotal: 13.5s\tremaining: 28.2s\n",
      "162:\tlearn: 0.1978827\ttotal: 13.6s\tremaining: 28.1s\n",
      "163:\tlearn: 0.1965409\ttotal: 13.7s\tremaining: 28.1s\n",
      "164:\tlearn: 0.1951951\ttotal: 13.8s\tremaining: 28s\n",
      "165:\tlearn: 0.1938121\ttotal: 13.9s\tremaining: 27.9s\n",
      "166:\tlearn: 0.1925697\ttotal: 14s\tremaining: 27.8s\n",
      "167:\tlearn: 0.1912022\ttotal: 14.1s\tremaining: 27.8s\n",
      "168:\tlearn: 0.1899725\ttotal: 14.1s\tremaining: 27.7s\n",
      "169:\tlearn: 0.1886291\ttotal: 14.2s\tremaining: 27.6s\n",
      "170:\tlearn: 0.1874294\ttotal: 14.3s\tremaining: 27.5s\n",
      "171:\tlearn: 0.1861161\ttotal: 14.3s\tremaining: 27.3s\n",
      "172:\tlearn: 0.1847417\ttotal: 14.4s\tremaining: 27.2s\n",
      "173:\tlearn: 0.1836899\ttotal: 14.5s\tremaining: 27.1s\n",
      "174:\tlearn: 0.1818940\ttotal: 14.6s\tremaining: 27.1s\n",
      "175:\tlearn: 0.1804909\ttotal: 14.7s\tremaining: 27s\n",
      "176:\tlearn: 0.1792162\ttotal: 14.8s\tremaining: 26.9s\n",
      "177:\tlearn: 0.1782049\ttotal: 14.8s\tremaining: 26.9s\n",
      "178:\tlearn: 0.1771109\ttotal: 14.9s\tremaining: 26.8s\n",
      "179:\tlearn: 0.1759646\ttotal: 15s\tremaining: 26.7s\n",
      "180:\tlearn: 0.1748357\ttotal: 15.2s\tremaining: 26.7s\n",
      "181:\tlearn: 0.1732699\ttotal: 15.3s\tremaining: 26.7s\n",
      "182:\tlearn: 0.1720735\ttotal: 15.4s\tremaining: 26.6s\n",
      "183:\tlearn: 0.1708993\ttotal: 15.4s\tremaining: 26.5s\n",
      "184:\tlearn: 0.1696428\ttotal: 15.5s\tremaining: 26.3s\n",
      "185:\tlearn: 0.1685721\ttotal: 15.5s\tremaining: 26.2s\n",
      "186:\tlearn: 0.1676056\ttotal: 15.6s\tremaining: 26.1s\n",
      "187:\tlearn: 0.1664020\ttotal: 15.8s\tremaining: 26.2s\n",
      "188:\tlearn: 0.1653375\ttotal: 15.9s\tremaining: 26.1s\n",
      "189:\tlearn: 0.1644269\ttotal: 15.9s\tremaining: 25.9s\n",
      "190:\tlearn: 0.1633574\ttotal: 16s\tremaining: 25.9s\n",
      "191:\tlearn: 0.1620096\ttotal: 16.1s\tremaining: 25.8s\n",
      "192:\tlearn: 0.1610891\ttotal: 16.2s\tremaining: 25.7s\n",
      "193:\tlearn: 0.1602113\ttotal: 16.2s\tremaining: 25.5s\n",
      "194:\tlearn: 0.1593356\ttotal: 16.3s\tremaining: 25.5s\n",
      "195:\tlearn: 0.1583377\ttotal: 16.4s\tremaining: 25.4s\n",
      "196:\tlearn: 0.1575436\ttotal: 16.5s\tremaining: 25.3s\n",
      "197:\tlearn: 0.1567399\ttotal: 16.5s\tremaining: 25.2s\n",
      "198:\tlearn: 0.1557974\ttotal: 16.6s\tremaining: 25.2s\n",
      "199:\tlearn: 0.1548000\ttotal: 16.7s\tremaining: 25.1s\n",
      "200:\tlearn: 0.1539247\ttotal: 16.8s\tremaining: 24.9s\n",
      "201:\tlearn: 0.1530300\ttotal: 16.8s\tremaining: 24.8s\n",
      "202:\tlearn: 0.1522568\ttotal: 16.9s\tremaining: 24.8s\n",
      "203:\tlearn: 0.1512825\ttotal: 17s\tremaining: 24.7s\n",
      "204:\tlearn: 0.1504355\ttotal: 17.1s\tremaining: 24.6s\n",
      "205:\tlearn: 0.1493896\ttotal: 17.1s\tremaining: 24.5s\n",
      "206:\tlearn: 0.1482734\ttotal: 17.3s\tremaining: 24.5s\n",
      "207:\tlearn: 0.1473200\ttotal: 17.3s\tremaining: 24.3s\n",
      "208:\tlearn: 0.1464356\ttotal: 17.5s\tremaining: 24.4s\n",
      "209:\tlearn: 0.1455193\ttotal: 17.5s\tremaining: 24.2s\n",
      "210:\tlearn: 0.1447581\ttotal: 17.6s\tremaining: 24.1s\n",
      "211:\tlearn: 0.1440050\ttotal: 17.7s\tremaining: 24.1s\n",
      "212:\tlearn: 0.1432614\ttotal: 17.8s\tremaining: 24s\n",
      "213:\tlearn: 0.1423191\ttotal: 17.9s\tremaining: 23.9s\n",
      "214:\tlearn: 0.1415777\ttotal: 17.9s\tremaining: 23.8s\n",
      "215:\tlearn: 0.1407623\ttotal: 18.1s\tremaining: 23.8s\n",
      "216:\tlearn: 0.1399452\ttotal: 18.2s\tremaining: 23.8s\n",
      "217:\tlearn: 0.1390168\ttotal: 18.3s\tremaining: 23.7s\n",
      "218:\tlearn: 0.1382840\ttotal: 18.4s\tremaining: 23.6s\n",
      "219:\tlearn: 0.1370637\ttotal: 18.5s\tremaining: 23.6s\n",
      "220:\tlearn: 0.1363412\ttotal: 18.6s\tremaining: 23.5s\n",
      "221:\tlearn: 0.1354596\ttotal: 18.7s\tremaining: 23.5s\n",
      "222:\tlearn: 0.1346320\ttotal: 18.8s\tremaining: 23.3s\n",
      "223:\tlearn: 0.1339022\ttotal: 18.9s\tremaining: 23.3s\n",
      "224:\tlearn: 0.1332177\ttotal: 19s\tremaining: 23.2s\n",
      "225:\tlearn: 0.1324975\ttotal: 19s\tremaining: 23s\n",
      "226:\tlearn: 0.1316398\ttotal: 19.1s\tremaining: 22.9s\n",
      "227:\tlearn: 0.1310730\ttotal: 19.2s\tremaining: 22.9s\n",
      "228:\tlearn: 0.1303939\ttotal: 19.3s\tremaining: 22.8s\n",
      "229:\tlearn: 0.1296635\ttotal: 19.4s\tremaining: 22.7s\n",
      "230:\tlearn: 0.1290501\ttotal: 19.5s\tremaining: 22.7s\n",
      "231:\tlearn: 0.1283894\ttotal: 19.6s\tremaining: 22.6s\n",
      "232:\tlearn: 0.1277052\ttotal: 19.6s\tremaining: 22.5s\n",
      "233:\tlearn: 0.1271198\ttotal: 19.7s\tremaining: 22.4s\n",
      "234:\tlearn: 0.1265095\ttotal: 19.8s\tremaining: 22.4s\n",
      "235:\tlearn: 0.1257999\ttotal: 20s\tremaining: 22.3s\n",
      "236:\tlearn: 0.1251580\ttotal: 20s\tremaining: 22.2s\n",
      "237:\tlearn: 0.1241862\ttotal: 20.1s\tremaining: 22.2s\n",
      "238:\tlearn: 0.1236525\ttotal: 20.2s\tremaining: 22.1s\n",
      "239:\tlearn: 0.1230444\ttotal: 20.3s\tremaining: 22s\n",
      "240:\tlearn: 0.1225179\ttotal: 20.4s\tremaining: 21.9s\n",
      "241:\tlearn: 0.1219982\ttotal: 20.5s\tremaining: 21.8s\n",
      "242:\tlearn: 0.1213772\ttotal: 20.6s\tremaining: 21.7s\n",
      "243:\tlearn: 0.1207901\ttotal: 20.6s\tremaining: 21.7s\n",
      "244:\tlearn: 0.1202386\ttotal: 20.7s\tremaining: 21.6s\n",
      "245:\tlearn: 0.1197315\ttotal: 20.8s\tremaining: 21.5s\n",
      "246:\tlearn: 0.1191648\ttotal: 21s\tremaining: 21.5s\n",
      "247:\tlearn: 0.1186812\ttotal: 21.1s\tremaining: 21.4s\n",
      "248:\tlearn: 0.1181475\ttotal: 21.1s\tremaining: 21.3s\n",
      "249:\tlearn: 0.1175788\ttotal: 21.2s\tremaining: 21.2s\n",
      "250:\tlearn: 0.1169664\ttotal: 21.3s\tremaining: 21.2s\n",
      "251:\tlearn: 0.1163780\ttotal: 21.4s\tremaining: 21.1s\n",
      "252:\tlearn: 0.1157555\ttotal: 21.5s\tremaining: 20.9s\n",
      "253:\tlearn: 0.1151289\ttotal: 21.6s\tremaining: 20.9s\n",
      "254:\tlearn: 0.1145143\ttotal: 21.6s\tremaining: 20.8s\n",
      "255:\tlearn: 0.1140448\ttotal: 21.7s\tremaining: 20.7s\n",
      "256:\tlearn: 0.1134346\ttotal: 21.8s\tremaining: 20.6s\n",
      "257:\tlearn: 0.1129360\ttotal: 21.9s\tremaining: 20.5s\n",
      "258:\tlearn: 0.1124098\ttotal: 22s\tremaining: 20.4s\n",
      "259:\tlearn: 0.1118649\ttotal: 22.1s\tremaining: 20.4s\n",
      "260:\tlearn: 0.1112276\ttotal: 22.2s\tremaining: 20.3s\n",
      "261:\tlearn: 0.1107783\ttotal: 22.3s\tremaining: 20.3s\n",
      "262:\tlearn: 0.1102785\ttotal: 22.4s\tremaining: 20.2s\n",
      "263:\tlearn: 0.1097143\ttotal: 22.5s\tremaining: 20.1s\n",
      "264:\tlearn: 0.1092189\ttotal: 22.5s\tremaining: 20s\n",
      "265:\tlearn: 0.1085833\ttotal: 22.6s\tremaining: 19.9s\n",
      "266:\tlearn: 0.1080140\ttotal: 22.6s\tremaining: 19.7s\n",
      "267:\tlearn: 0.1074845\ttotal: 22.8s\tremaining: 19.7s\n",
      "268:\tlearn: 0.1069221\ttotal: 22.8s\tremaining: 19.6s\n",
      "269:\tlearn: 0.1063649\ttotal: 22.9s\tremaining: 19.5s\n",
      "270:\tlearn: 0.1057787\ttotal: 23s\tremaining: 19.5s\n",
      "271:\tlearn: 0.1053229\ttotal: 23.1s\tremaining: 19.4s\n",
      "272:\tlearn: 0.1048524\ttotal: 23.2s\tremaining: 19.3s\n",
      "273:\tlearn: 0.1043338\ttotal: 23.3s\tremaining: 19.2s\n",
      "274:\tlearn: 0.1038860\ttotal: 23.4s\tremaining: 19.1s\n",
      "275:\tlearn: 0.1033939\ttotal: 23.5s\tremaining: 19.1s\n",
      "276:\tlearn: 0.1028997\ttotal: 23.6s\tremaining: 19s\n",
      "277:\tlearn: 0.1024255\ttotal: 23.7s\tremaining: 18.9s\n",
      "278:\tlearn: 0.1019611\ttotal: 23.7s\tremaining: 18.8s\n",
      "279:\tlearn: 0.1014843\ttotal: 23.8s\tremaining: 18.7s\n",
      "280:\tlearn: 0.1010106\ttotal: 23.9s\tremaining: 18.6s\n",
      "281:\tlearn: 0.1005432\ttotal: 24s\tremaining: 18.5s\n",
      "282:\tlearn: 0.1000683\ttotal: 24.1s\tremaining: 18.5s\n",
      "283:\tlearn: 0.0996317\ttotal: 24.1s\tremaining: 18.4s\n",
      "284:\tlearn: 0.0992520\ttotal: 24.2s\tremaining: 18.2s\n",
      "285:\tlearn: 0.0987169\ttotal: 24.3s\tremaining: 18.2s\n",
      "286:\tlearn: 0.0982916\ttotal: 24.4s\tremaining: 18.1s\n",
      "287:\tlearn: 0.0978813\ttotal: 24.5s\tremaining: 18s\n",
      "288:\tlearn: 0.0973713\ttotal: 24.5s\tremaining: 17.9s\n",
      "289:\tlearn: 0.0969441\ttotal: 24.7s\tremaining: 17.9s\n",
      "290:\tlearn: 0.0965498\ttotal: 24.7s\tremaining: 17.8s\n",
      "291:\tlearn: 0.0957602\ttotal: 24.8s\tremaining: 17.6s\n",
      "292:\tlearn: 0.0952874\ttotal: 24.8s\tremaining: 17.5s\n",
      "293:\tlearn: 0.0948679\ttotal: 24.9s\tremaining: 17.5s\n",
      "294:\tlearn: 0.0943133\ttotal: 25s\tremaining: 17.4s\n",
      "295:\tlearn: 0.0938636\ttotal: 25.1s\tremaining: 17.3s\n",
      "296:\tlearn: 0.0934409\ttotal: 25.2s\tremaining: 17.2s\n",
      "297:\tlearn: 0.0930557\ttotal: 25.3s\tremaining: 17.1s\n",
      "298:\tlearn: 0.0926782\ttotal: 25.4s\tremaining: 17.1s\n",
      "299:\tlearn: 0.0922982\ttotal: 25.5s\tremaining: 17s\n",
      "300:\tlearn: 0.0919530\ttotal: 25.5s\tremaining: 16.9s\n",
      "301:\tlearn: 0.0916006\ttotal: 25.6s\tremaining: 16.8s\n",
      "302:\tlearn: 0.0911317\ttotal: 25.7s\tremaining: 16.7s\n",
      "303:\tlearn: 0.0907513\ttotal: 25.8s\tremaining: 16.6s\n",
      "304:\tlearn: 0.0903123\ttotal: 25.9s\tremaining: 16.5s\n",
      "305:\tlearn: 0.0899518\ttotal: 25.9s\tremaining: 16.4s\n",
      "306:\tlearn: 0.0893830\ttotal: 26s\tremaining: 16.4s\n",
      "307:\tlearn: 0.0887157\ttotal: 26.1s\tremaining: 16.3s\n",
      "308:\tlearn: 0.0883643\ttotal: 26.2s\tremaining: 16.2s\n",
      "309:\tlearn: 0.0880469\ttotal: 26.3s\tremaining: 16.1s\n",
      "310:\tlearn: 0.0877123\ttotal: 26.4s\tremaining: 16s\n",
      "311:\tlearn: 0.0873189\ttotal: 26.5s\tremaining: 16s\n",
      "312:\tlearn: 0.0869983\ttotal: 26.5s\tremaining: 15.9s\n",
      "313:\tlearn: 0.0867150\ttotal: 26.6s\tremaining: 15.8s\n",
      "314:\tlearn: 0.0862997\ttotal: 26.7s\tremaining: 15.7s\n",
      "315:\tlearn: 0.0859436\ttotal: 26.8s\tremaining: 15.6s\n",
      "316:\tlearn: 0.0856228\ttotal: 26.9s\tremaining: 15.5s\n",
      "317:\tlearn: 0.0852708\ttotal: 27s\tremaining: 15.4s\n",
      "318:\tlearn: 0.0849399\ttotal: 27s\tremaining: 15.3s\n",
      "319:\tlearn: 0.0845968\ttotal: 27.1s\tremaining: 15.2s\n",
      "320:\tlearn: 0.0842724\ttotal: 27.2s\tremaining: 15.2s\n",
      "321:\tlearn: 0.0838212\ttotal: 27.2s\tremaining: 15.1s\n",
      "322:\tlearn: 0.0835137\ttotal: 27.3s\tremaining: 15s\n",
      "323:\tlearn: 0.0832406\ttotal: 27.5s\tremaining: 14.9s\n",
      "324:\tlearn: 0.0829410\ttotal: 27.6s\tremaining: 14.9s\n",
      "325:\tlearn: 0.0826165\ttotal: 27.6s\tremaining: 14.8s\n",
      "326:\tlearn: 0.0822272\ttotal: 27.7s\tremaining: 14.7s\n",
      "327:\tlearn: 0.0818875\ttotal: 27.8s\tremaining: 14.6s\n",
      "328:\tlearn: 0.0814919\ttotal: 27.9s\tremaining: 14.5s\n",
      "329:\tlearn: 0.0810722\ttotal: 28s\tremaining: 14.4s\n",
      "330:\tlearn: 0.0806708\ttotal: 28.1s\tremaining: 14.3s\n",
      "331:\tlearn: 0.0803412\ttotal: 28.2s\tremaining: 14.3s\n",
      "332:\tlearn: 0.0800138\ttotal: 28.3s\tremaining: 14.2s\n",
      "333:\tlearn: 0.0796982\ttotal: 28.3s\tremaining: 14.1s\n",
      "334:\tlearn: 0.0794353\ttotal: 28.4s\tremaining: 14s\n",
      "335:\tlearn: 0.0790970\ttotal: 28.5s\tremaining: 13.9s\n",
      "336:\tlearn: 0.0788264\ttotal: 28.5s\tremaining: 13.8s\n",
      "337:\tlearn: 0.0785271\ttotal: 28.6s\tremaining: 13.7s\n",
      "338:\tlearn: 0.0782755\ttotal: 28.7s\tremaining: 13.6s\n",
      "339:\tlearn: 0.0779171\ttotal: 28.8s\tremaining: 13.6s\n",
      "340:\tlearn: 0.0775550\ttotal: 28.9s\tremaining: 13.5s\n",
      "341:\tlearn: 0.0772821\ttotal: 29s\tremaining: 13.4s\n",
      "342:\tlearn: 0.0770376\ttotal: 29.1s\tremaining: 13.3s\n",
      "343:\tlearn: 0.0768061\ttotal: 29.1s\tremaining: 13.2s\n",
      "344:\tlearn: 0.0765217\ttotal: 29.2s\tremaining: 13.1s\n",
      "345:\tlearn: 0.0762597\ttotal: 29.3s\tremaining: 13s\n",
      "346:\tlearn: 0.0759929\ttotal: 29.4s\tremaining: 12.9s\n",
      "347:\tlearn: 0.0757076\ttotal: 29.4s\tremaining: 12.9s\n",
      "348:\tlearn: 0.0754748\ttotal: 29.5s\tremaining: 12.8s\n",
      "349:\tlearn: 0.0751974\ttotal: 29.6s\tremaining: 12.7s\n",
      "350:\tlearn: 0.0749418\ttotal: 29.7s\tremaining: 12.6s\n",
      "351:\tlearn: 0.0746507\ttotal: 29.8s\tremaining: 12.5s\n",
      "352:\tlearn: 0.0743770\ttotal: 29.8s\tremaining: 12.4s\n",
      "353:\tlearn: 0.0740720\ttotal: 29.9s\tremaining: 12.3s\n",
      "354:\tlearn: 0.0738563\ttotal: 30s\tremaining: 12.3s\n",
      "355:\tlearn: 0.0735793\ttotal: 30.1s\tremaining: 12.2s\n",
      "356:\tlearn: 0.0733593\ttotal: 30.1s\tremaining: 12.1s\n",
      "357:\tlearn: 0.0730608\ttotal: 30.2s\tremaining: 12s\n",
      "358:\tlearn: 0.0727928\ttotal: 30.3s\tremaining: 11.9s\n",
      "359:\tlearn: 0.0725188\ttotal: 30.4s\tremaining: 11.8s\n",
      "360:\tlearn: 0.0722982\ttotal: 30.5s\tremaining: 11.7s\n",
      "361:\tlearn: 0.0720632\ttotal: 30.5s\tremaining: 11.6s\n",
      "362:\tlearn: 0.0718245\ttotal: 30.6s\tremaining: 11.5s\n",
      "363:\tlearn: 0.0715747\ttotal: 30.6s\tremaining: 11.4s\n",
      "364:\tlearn: 0.0713013\ttotal: 30.7s\tremaining: 11.4s\n",
      "365:\tlearn: 0.0711019\ttotal: 30.8s\tremaining: 11.3s\n",
      "366:\tlearn: 0.0708850\ttotal: 30.9s\tremaining: 11.2s\n",
      "367:\tlearn: 0.0706496\ttotal: 31s\tremaining: 11.1s\n",
      "368:\tlearn: 0.0704069\ttotal: 31.1s\tremaining: 11s\n",
      "369:\tlearn: 0.0701623\ttotal: 31.2s\tremaining: 10.9s\n",
      "370:\tlearn: 0.0699255\ttotal: 31.3s\tremaining: 10.9s\n",
      "371:\tlearn: 0.0696411\ttotal: 31.3s\tremaining: 10.8s\n",
      "372:\tlearn: 0.0693880\ttotal: 31.4s\tremaining: 10.7s\n",
      "373:\tlearn: 0.0691380\ttotal: 31.5s\tremaining: 10.6s\n",
      "374:\tlearn: 0.0689392\ttotal: 31.6s\tremaining: 10.5s\n",
      "375:\tlearn: 0.0687198\ttotal: 31.7s\tremaining: 10.4s\n",
      "376:\tlearn: 0.0685411\ttotal: 31.8s\tremaining: 10.4s\n",
      "377:\tlearn: 0.0683092\ttotal: 31.9s\tremaining: 10.3s\n",
      "378:\tlearn: 0.0680039\ttotal: 31.9s\tremaining: 10.2s\n",
      "379:\tlearn: 0.0676856\ttotal: 32s\tremaining: 10.1s\n",
      "380:\tlearn: 0.0674766\ttotal: 32.1s\tremaining: 10s\n",
      "381:\tlearn: 0.0672290\ttotal: 32.2s\tremaining: 9.94s\n",
      "382:\tlearn: 0.0669823\ttotal: 32.3s\tremaining: 9.86s\n",
      "383:\tlearn: 0.0667506\ttotal: 32.4s\tremaining: 9.78s\n",
      "384:\tlearn: 0.0665176\ttotal: 32.5s\tremaining: 9.7s\n",
      "385:\tlearn: 0.0662827\ttotal: 32.6s\tremaining: 9.62s\n",
      "386:\tlearn: 0.0660689\ttotal: 32.6s\tremaining: 9.53s\n",
      "387:\tlearn: 0.0658328\ttotal: 32.7s\tremaining: 9.45s\n",
      "388:\tlearn: 0.0655347\ttotal: 32.8s\tremaining: 9.35s\n",
      "389:\tlearn: 0.0653488\ttotal: 32.8s\tremaining: 9.25s\n",
      "390:\tlearn: 0.0651287\ttotal: 32.9s\tremaining: 9.18s\n",
      "391:\tlearn: 0.0649099\ttotal: 33s\tremaining: 9.09s\n",
      "392:\tlearn: 0.0646876\ttotal: 33.1s\tremaining: 9.01s\n",
      "393:\tlearn: 0.0645135\ttotal: 33.2s\tremaining: 8.93s\n",
      "394:\tlearn: 0.0643399\ttotal: 33.3s\tremaining: 8.85s\n",
      "395:\tlearn: 0.0641499\ttotal: 33.4s\tremaining: 8.77s\n",
      "396:\tlearn: 0.0639064\ttotal: 33.5s\tremaining: 8.69s\n",
      "397:\tlearn: 0.0637256\ttotal: 33.5s\tremaining: 8.59s\n",
      "398:\tlearn: 0.0635486\ttotal: 33.6s\tremaining: 8.51s\n",
      "399:\tlearn: 0.0633603\ttotal: 33.7s\tremaining: 8.43s\n",
      "400:\tlearn: 0.0631968\ttotal: 33.8s\tremaining: 8.34s\n",
      "401:\tlearn: 0.0629684\ttotal: 33.9s\tremaining: 8.25s\n",
      "402:\tlearn: 0.0627755\ttotal: 33.9s\tremaining: 8.16s\n",
      "403:\tlearn: 0.0626084\ttotal: 34s\tremaining: 8.07s\n",
      "404:\tlearn: 0.0623852\ttotal: 34.1s\tremaining: 7.99s\n",
      "405:\tlearn: 0.0622192\ttotal: 34.2s\tremaining: 7.91s\n",
      "406:\tlearn: 0.0620254\ttotal: 34.2s\tremaining: 7.82s\n",
      "407:\tlearn: 0.0618796\ttotal: 34.3s\tremaining: 7.75s\n",
      "408:\tlearn: 0.0616793\ttotal: 34.5s\tremaining: 7.67s\n",
      "409:\tlearn: 0.0615062\ttotal: 34.5s\tremaining: 7.58s\n",
      "410:\tlearn: 0.0612244\ttotal: 34.6s\tremaining: 7.5s\n",
      "411:\tlearn: 0.0610822\ttotal: 34.7s\tremaining: 7.42s\n",
      "412:\tlearn: 0.0608721\ttotal: 34.8s\tremaining: 7.33s\n",
      "413:\tlearn: 0.0606905\ttotal: 34.9s\tremaining: 7.25s\n",
      "414:\tlearn: 0.0604915\ttotal: 34.9s\tremaining: 7.16s\n",
      "415:\tlearn: 0.0603527\ttotal: 35s\tremaining: 7.06s\n",
      "416:\tlearn: 0.0601123\ttotal: 35s\tremaining: 6.97s\n",
      "417:\tlearn: 0.0599291\ttotal: 35.1s\tremaining: 6.88s\n",
      "418:\tlearn: 0.0597666\ttotal: 35.1s\tremaining: 6.79s\n",
      "419:\tlearn: 0.0595442\ttotal: 35.3s\tremaining: 6.72s\n",
      "420:\tlearn: 0.0593681\ttotal: 35.4s\tremaining: 6.64s\n",
      "421:\tlearn: 0.0592041\ttotal: 35.4s\tremaining: 6.55s\n",
      "422:\tlearn: 0.0590395\ttotal: 35.6s\tremaining: 6.47s\n",
      "423:\tlearn: 0.0588627\ttotal: 35.7s\tremaining: 6.39s\n",
      "424:\tlearn: 0.0587171\ttotal: 35.8s\tremaining: 6.31s\n",
      "425:\tlearn: 0.0584938\ttotal: 35.8s\tremaining: 6.23s\n",
      "426:\tlearn: 0.0582467\ttotal: 36s\tremaining: 6.15s\n",
      "427:\tlearn: 0.0580546\ttotal: 36s\tremaining: 6.06s\n",
      "428:\tlearn: 0.0578855\ttotal: 36.2s\tremaining: 5.98s\n",
      "429:\tlearn: 0.0577312\ttotal: 36.2s\tremaining: 5.89s\n",
      "430:\tlearn: 0.0575997\ttotal: 36.3s\tremaining: 5.81s\n",
      "431:\tlearn: 0.0574173\ttotal: 36.3s\tremaining: 5.72s\n",
      "432:\tlearn: 0.0572877\ttotal: 36.4s\tremaining: 5.63s\n",
      "433:\tlearn: 0.0570528\ttotal: 36.4s\tremaining: 5.54s\n",
      "434:\tlearn: 0.0569181\ttotal: 36.6s\tremaining: 5.47s\n",
      "435:\tlearn: 0.0567456\ttotal: 36.7s\tremaining: 5.38s\n",
      "436:\tlearn: 0.0566035\ttotal: 36.8s\tremaining: 5.3s\n",
      "437:\tlearn: 0.0564059\ttotal: 36.9s\tremaining: 5.22s\n",
      "438:\tlearn: 0.0562473\ttotal: 36.9s\tremaining: 5.13s\n",
      "439:\tlearn: 0.0560993\ttotal: 37.1s\tremaining: 5.05s\n",
      "440:\tlearn: 0.0559254\ttotal: 37.1s\tremaining: 4.97s\n",
      "441:\tlearn: 0.0557705\ttotal: 37.2s\tremaining: 4.88s\n",
      "442:\tlearn: 0.0556376\ttotal: 37.3s\tremaining: 4.8s\n",
      "443:\tlearn: 0.0554778\ttotal: 37.4s\tremaining: 4.71s\n",
      "444:\tlearn: 0.0552722\ttotal: 37.4s\tremaining: 4.63s\n",
      "445:\tlearn: 0.0551275\ttotal: 37.5s\tremaining: 4.54s\n",
      "446:\tlearn: 0.0549752\ttotal: 37.6s\tremaining: 4.45s\n",
      "447:\tlearn: 0.0548389\ttotal: 37.7s\tremaining: 4.38s\n",
      "448:\tlearn: 0.0547061\ttotal: 37.8s\tremaining: 4.29s\n",
      "449:\tlearn: 0.0545759\ttotal: 37.8s\tremaining: 4.2s\n",
      "450:\tlearn: 0.0544410\ttotal: 37.9s\tremaining: 4.12s\n",
      "451:\tlearn: 0.0542771\ttotal: 37.9s\tremaining: 4.03s\n",
      "452:\tlearn: 0.0541379\ttotal: 38s\tremaining: 3.94s\n",
      "453:\tlearn: 0.0539864\ttotal: 38.1s\tremaining: 3.86s\n",
      "454:\tlearn: 0.0538611\ttotal: 38.2s\tremaining: 3.78s\n",
      "455:\tlearn: 0.0537132\ttotal: 38.3s\tremaining: 3.69s\n",
      "456:\tlearn: 0.0535627\ttotal: 38.3s\tremaining: 3.61s\n",
      "457:\tlearn: 0.0534453\ttotal: 38.5s\tremaining: 3.53s\n",
      "458:\tlearn: 0.0533162\ttotal: 38.5s\tremaining: 3.44s\n",
      "459:\tlearn: 0.0531684\ttotal: 38.6s\tremaining: 3.35s\n",
      "460:\tlearn: 0.0530294\ttotal: 38.6s\tremaining: 3.27s\n",
      "461:\tlearn: 0.0528968\ttotal: 38.7s\tremaining: 3.19s\n",
      "462:\tlearn: 0.0527516\ttotal: 38.8s\tremaining: 3.1s\n",
      "463:\tlearn: 0.0526266\ttotal: 38.9s\tremaining: 3.02s\n",
      "464:\tlearn: 0.0524958\ttotal: 39s\tremaining: 2.94s\n",
      "465:\tlearn: 0.0523140\ttotal: 39.1s\tremaining: 2.85s\n",
      "466:\tlearn: 0.0521828\ttotal: 39.2s\tremaining: 2.77s\n",
      "467:\tlearn: 0.0520169\ttotal: 39.3s\tremaining: 2.69s\n",
      "468:\tlearn: 0.0518551\ttotal: 39.4s\tremaining: 2.6s\n",
      "469:\tlearn: 0.0517188\ttotal: 39.5s\tremaining: 2.52s\n",
      "470:\tlearn: 0.0515797\ttotal: 39.5s\tremaining: 2.44s\n",
      "471:\tlearn: 0.0514389\ttotal: 39.7s\tremaining: 2.35s\n",
      "472:\tlearn: 0.0512931\ttotal: 39.7s\tremaining: 2.27s\n",
      "473:\tlearn: 0.0511631\ttotal: 39.8s\tremaining: 2.18s\n",
      "474:\tlearn: 0.0510322\ttotal: 39.9s\tremaining: 2.1s\n",
      "475:\tlearn: 0.0509177\ttotal: 39.9s\tremaining: 2.01s\n",
      "476:\tlearn: 0.0507710\ttotal: 40s\tremaining: 1.93s\n",
      "477:\tlearn: 0.0506712\ttotal: 40.1s\tremaining: 1.85s\n",
      "478:\tlearn: 0.0505263\ttotal: 40.2s\tremaining: 1.76s\n",
      "479:\tlearn: 0.0504145\ttotal: 40.3s\tremaining: 1.68s\n",
      "480:\tlearn: 0.0502912\ttotal: 40.4s\tremaining: 1.6s\n",
      "481:\tlearn: 0.0501503\ttotal: 40.6s\tremaining: 1.51s\n",
      "482:\tlearn: 0.0500430\ttotal: 40.6s\tremaining: 1.43s\n",
      "483:\tlearn: 0.0499241\ttotal: 40.8s\tremaining: 1.35s\n",
      "484:\tlearn: 0.0498075\ttotal: 40.9s\tremaining: 1.26s\n",
      "485:\tlearn: 0.0496914\ttotal: 40.9s\tremaining: 1.18s\n",
      "486:\tlearn: 0.0495523\ttotal: 41s\tremaining: 1.09s\n",
      "487:\tlearn: 0.0494247\ttotal: 41.1s\tremaining: 1.01s\n",
      "488:\tlearn: 0.0493301\ttotal: 41.2s\tremaining: 927ms\n",
      "489:\tlearn: 0.0491940\ttotal: 41.3s\tremaining: 842ms\n",
      "490:\tlearn: 0.0490635\ttotal: 41.3s\tremaining: 758ms\n",
      "491:\tlearn: 0.0489317\ttotal: 41.4s\tremaining: 673ms\n",
      "492:\tlearn: 0.0488244\ttotal: 41.5s\tremaining: 589ms\n",
      "493:\tlearn: 0.0487152\ttotal: 41.6s\tremaining: 505ms\n",
      "494:\tlearn: 0.0485904\ttotal: 41.7s\tremaining: 421ms\n",
      "495:\tlearn: 0.0484539\ttotal: 41.8s\tremaining: 337ms\n",
      "496:\tlearn: 0.0483621\ttotal: 42s\tremaining: 253ms\n",
      "497:\tlearn: 0.0482322\ttotal: 42.1s\tremaining: 169ms\n",
      "498:\tlearn: 0.0481071\ttotal: 42.1s\tremaining: 84.4ms\n",
      "499:\tlearn: 0.0479832\ttotal: 42.1s\tremaining: 0us\n",
      "Accuracy: 0.6097560975609756\n",
      "\n",
      "Confusion Matrix:\n",
      " [[13  9]\n",
      " [ 7 12]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.59      0.62        22\n",
      "           1       0.57      0.63      0.60        19\n",
      "\n",
      "    accuracy                           0.61        41\n",
      "   macro avg       0.61      0.61      0.61        41\n",
      "weighted avg       0.61      0.61      0.61        41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Fraud'], axis=1)\n",
    "y = df['Fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a CatBoost Classifier\n",
    "model = CatBoostClassifier(iterations=500, depth=10, learning_rate=0.05, loss_function='MultiClass', random_seed=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, cat_features=None)  # You can specify categorical features if needed\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/DMEPOS/dmepos_ros_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0.1\",\"Unnamed: 0\",\"Rfrg_NPI\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rfrg_Prvdr_Crdntls</th>\n",
       "      <th>Rfrg_Prvdr_Gndr</th>\n",
       "      <th>Rfrg_Prvdr_Type</th>\n",
       "      <th>Rfrg_Prvdr_Type_Flag</th>\n",
       "      <th>Tot_Suplrs</th>\n",
       "      <th>Tot_Suplr_HCPCS_Cds</th>\n",
       "      <th>Tot_Suplr_Benes</th>\n",
       "      <th>Tot_Suplr_Clms</th>\n",
       "      <th>Tot_Suplr_Srvcs</th>\n",
       "      <th>Suplr_Sbmtd_Chrgs</th>\n",
       "      <th>...</th>\n",
       "      <th>Bene_CC_Dbts_Pct</th>\n",
       "      <th>Bene_CC_Hyplpdma_Pct</th>\n",
       "      <th>Bene_CC_Hyprtnsn_Pct</th>\n",
       "      <th>Bene_CC_IHD_Pct</th>\n",
       "      <th>Bene_CC_Opo_Pct</th>\n",
       "      <th>Bene_CC_RAOA_Pct</th>\n",
       "      <th>Bene_CC_Sz_Pct</th>\n",
       "      <th>Bene_CC_Strok_Pct</th>\n",
       "      <th>Bene_Avg_Risk_Scre</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>132</td>\n",
       "      <td>159</td>\n",
       "      <td>29869.97</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.729650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28</td>\n",
       "      <td>47</td>\n",
       "      <td>33.0</td>\n",
       "      <td>97</td>\n",
       "      <td>1136</td>\n",
       "      <td>44435.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.654308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1629</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>19.0</td>\n",
       "      <td>65</td>\n",
       "      <td>1117</td>\n",
       "      <td>18711.69</td>\n",
       "      <td>...</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.894526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29</td>\n",
       "      <td>4778</td>\n",
       "      <td>26951.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.173167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4511</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>2080.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.819692</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766705</th>\n",
       "      <td>3017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1499</td>\n",
       "      <td>10756.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766706</th>\n",
       "      <td>3017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>35</td>\n",
       "      <td>58</td>\n",
       "      <td>8610.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.946854</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766707</th>\n",
       "      <td>1186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>11.0</td>\n",
       "      <td>38</td>\n",
       "      <td>527</td>\n",
       "      <td>24189.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.920779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766708</th>\n",
       "      <td>3017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>20.0</td>\n",
       "      <td>197</td>\n",
       "      <td>256</td>\n",
       "      <td>24346.83</td>\n",
       "      <td>...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>4.135803</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766709</th>\n",
       "      <td>4277</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>32.0</td>\n",
       "      <td>57</td>\n",
       "      <td>10044</td>\n",
       "      <td>49465.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.485419</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>766710 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rfrg_Prvdr_Crdntls  Rfrg_Prvdr_Gndr  Rfrg_Prvdr_Type  \\\n",
       "0                     2362              0.0               44   \n",
       "1                     3017              0.0               26   \n",
       "2                     1629              1.0               44   \n",
       "3                     2684              0.0              117   \n",
       "4                     4511              1.0               87   \n",
       "...                    ...              ...              ...   \n",
       "766705                3017              0.0               26   \n",
       "766706                3017              0.0               44   \n",
       "766707                1186              1.0               26   \n",
       "766708                3017              0.0               85   \n",
       "766709                4277              1.0               65   \n",
       "\n",
       "        Rfrg_Prvdr_Type_Flag  Tot_Suplrs  Tot_Suplr_HCPCS_Cds  \\\n",
       "0                        1.0           8                    7   \n",
       "1                        1.0          28                   47   \n",
       "2                        1.0          11                   44   \n",
       "3                        1.0           5                   12   \n",
       "4                        1.0           1                    1   \n",
       "...                      ...         ...                  ...   \n",
       "766705                   1.0           4                   11   \n",
       "766706                   1.0           1                    5   \n",
       "766707                   1.0           9                   27   \n",
       "766708                   1.0           9                   18   \n",
       "766709                   1.0           7                    7   \n",
       "\n",
       "        Tot_Suplr_Benes  Tot_Suplr_Clms  Tot_Suplr_Srvcs  Suplr_Sbmtd_Chrgs  \\\n",
       "0                  11.0             132              159           29869.97   \n",
       "1                  33.0              97             1136           44435.62   \n",
       "2                  19.0              65             1117           18711.69   \n",
       "3                  23.0              29             4778           26951.30   \n",
       "4                  13.0              13               13            2080.00   \n",
       "...                 ...             ...              ...                ...   \n",
       "766705             20.0              20             1499           10756.06   \n",
       "766706             11.0              35               58            8610.00   \n",
       "766707             11.0              38              527           24189.32   \n",
       "766708             20.0             197              256           24346.83   \n",
       "766709             32.0              57            10044           49465.56   \n",
       "\n",
       "        ...  Bene_CC_Dbts_Pct  Bene_CC_Hyplpdma_Pct  Bene_CC_Hyprtnsn_Pct  \\\n",
       "0       ...              0.75                  0.75                  0.75   \n",
       "1       ...              0.75                  0.73                  0.75   \n",
       "2       ...              0.68                  0.74                  0.75   \n",
       "3       ...              0.64                  0.54                  0.69   \n",
       "4       ...              0.00                  0.75                  0.75   \n",
       "...     ...               ...                   ...                   ...   \n",
       "766705  ...              0.44                  0.63                  0.75   \n",
       "766706  ...              0.58                  0.75                  0.75   \n",
       "766707  ...              0.41                  0.50                  0.75   \n",
       "766708  ...              0.64                  0.65                  0.75   \n",
       "766709  ...              0.35                  0.48                  0.75   \n",
       "\n",
       "        Bene_CC_IHD_Pct  Bene_CC_Opo_Pct  Bene_CC_RAOA_Pct  Bene_CC_Sz_Pct  \\\n",
       "0                  0.32              0.0              0.64             0.0   \n",
       "1                  0.39              0.0              0.58             0.0   \n",
       "2                  0.53              0.0              0.68             0.0   \n",
       "3                  0.48              0.0              0.75             0.0   \n",
       "4                  0.00              0.0              0.75             0.0   \n",
       "...                 ...              ...               ...             ...   \n",
       "766705             0.54              0.0              0.55             0.0   \n",
       "766706             0.75              0.0              0.71             0.0   \n",
       "766707             0.00              0.0              0.00             0.0   \n",
       "766708             0.65              0.0              0.75             0.0   \n",
       "766709             0.37              0.0              0.62             0.0   \n",
       "\n",
       "        Bene_CC_Strok_Pct  Bene_Avg_Risk_Scre  Fraud  \n",
       "0                    0.00            3.729650      0  \n",
       "1                    0.00            1.654308      0  \n",
       "2                    0.00            1.894526      0  \n",
       "3                    0.00            2.173167      0  \n",
       "4                    0.00            0.819692      0  \n",
       "...                   ...                 ...    ...  \n",
       "766705               0.00            2.950000      1  \n",
       "766706               0.00            2.946854      1  \n",
       "766707               0.00            4.920779      1  \n",
       "766708               0.19            4.135803      1  \n",
       "766709               0.00            2.485419      1  \n",
       "\n",
       "[766710 rows x 76 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6616602\ttotal: 1.2s\tremaining: 9m 56s\n",
      "1:\tlearn: 0.6335599\ttotal: 2.23s\tremaining: 9m 15s\n",
      "2:\tlearn: 0.6082929\ttotal: 3.33s\tremaining: 9m 12s\n",
      "3:\tlearn: 0.5829178\ttotal: 4.37s\tremaining: 9m 1s\n",
      "4:\tlearn: 0.5649450\ttotal: 5.51s\tremaining: 9m 5s\n",
      "5:\tlearn: 0.5468845\ttotal: 6.74s\tremaining: 9m 14s\n",
      "6:\tlearn: 0.5279374\ttotal: 7.87s\tremaining: 9m 13s\n",
      "7:\tlearn: 0.5144493\ttotal: 9.04s\tremaining: 9m 16s\n",
      "8:\tlearn: 0.4971225\ttotal: 10.2s\tremaining: 9m 15s\n",
      "9:\tlearn: 0.4818705\ttotal: 11.3s\tremaining: 9m 11s\n",
      "10:\tlearn: 0.4662931\ttotal: 12.4s\tremaining: 9m 10s\n",
      "11:\tlearn: 0.4532774\ttotal: 13.5s\tremaining: 9m 7s\n",
      "12:\tlearn: 0.4414301\ttotal: 14.5s\tremaining: 9m 2s\n",
      "13:\tlearn: 0.4286940\ttotal: 15.6s\tremaining: 9m\n",
      "14:\tlearn: 0.4162445\ttotal: 16.7s\tremaining: 8m 58s\n",
      "15:\tlearn: 0.4037990\ttotal: 17.6s\tremaining: 8m 53s\n",
      "16:\tlearn: 0.3923053\ttotal: 18.7s\tremaining: 8m 52s\n",
      "17:\tlearn: 0.3811886\ttotal: 19.9s\tremaining: 8m 52s\n",
      "18:\tlearn: 0.3730914\ttotal: 20.9s\tremaining: 8m 49s\n",
      "19:\tlearn: 0.3654816\ttotal: 21.9s\tremaining: 8m 45s\n",
      "20:\tlearn: 0.3552613\ttotal: 23s\tremaining: 8m 45s\n",
      "21:\tlearn: 0.3460500\ttotal: 24.1s\tremaining: 8m 43s\n",
      "22:\tlearn: 0.3397139\ttotal: 25.3s\tremaining: 8m 43s\n",
      "23:\tlearn: 0.3326826\ttotal: 26.3s\tremaining: 8m 41s\n",
      "24:\tlearn: 0.3233011\ttotal: 27.5s\tremaining: 8m 41s\n",
      "25:\tlearn: 0.3173309\ttotal: 28.4s\tremaining: 8m 38s\n",
      "26:\tlearn: 0.3082706\ttotal: 29.5s\tremaining: 8m 36s\n",
      "27:\tlearn: 0.2980897\ttotal: 30.6s\tremaining: 8m 36s\n",
      "28:\tlearn: 0.2891658\ttotal: 31.7s\tremaining: 8m 35s\n",
      "29:\tlearn: 0.2807840\ttotal: 32.7s\tremaining: 8m 32s\n",
      "30:\tlearn: 0.2729760\ttotal: 33.9s\tremaining: 8m 32s\n",
      "31:\tlearn: 0.2656022\ttotal: 34.9s\tremaining: 8m 30s\n",
      "32:\tlearn: 0.2593424\ttotal: 36s\tremaining: 8m 30s\n",
      "33:\tlearn: 0.2548453\ttotal: 37.2s\tremaining: 8m 29s\n",
      "34:\tlearn: 0.2466600\ttotal: 38.1s\tremaining: 8m 26s\n",
      "35:\tlearn: 0.2399156\ttotal: 39.2s\tremaining: 8m 24s\n",
      "36:\tlearn: 0.2343872\ttotal: 40.3s\tremaining: 8m 23s\n",
      "37:\tlearn: 0.2278553\ttotal: 41.4s\tremaining: 8m 23s\n",
      "38:\tlearn: 0.2220264\ttotal: 42.6s\tremaining: 8m 23s\n",
      "39:\tlearn: 0.2177263\ttotal: 43.6s\tremaining: 8m 21s\n",
      "40:\tlearn: 0.2117572\ttotal: 44.6s\tremaining: 8m 19s\n",
      "41:\tlearn: 0.2067721\ttotal: 45.7s\tremaining: 8m 18s\n",
      "42:\tlearn: 0.2015554\ttotal: 46.8s\tremaining: 8m 17s\n",
      "43:\tlearn: 0.1955555\ttotal: 47.9s\tremaining: 8m 16s\n",
      "44:\tlearn: 0.1909484\ttotal: 48.9s\tremaining: 8m 14s\n",
      "45:\tlearn: 0.1864403\ttotal: 49.9s\tremaining: 8m 12s\n",
      "46:\tlearn: 0.1824443\ttotal: 51.1s\tremaining: 8m 12s\n",
      "47:\tlearn: 0.1773555\ttotal: 52.1s\tremaining: 8m 10s\n",
      "48:\tlearn: 0.1739762\ttotal: 53.4s\tremaining: 8m 11s\n",
      "49:\tlearn: 0.1688173\ttotal: 54.3s\tremaining: 8m 8s\n",
      "50:\tlearn: 0.1648025\ttotal: 55.5s\tremaining: 8m 8s\n",
      "51:\tlearn: 0.1611190\ttotal: 56.6s\tremaining: 8m 7s\n",
      "52:\tlearn: 0.1572177\ttotal: 57.6s\tremaining: 8m 5s\n",
      "53:\tlearn: 0.1543642\ttotal: 58.9s\tremaining: 8m 6s\n",
      "54:\tlearn: 0.1515949\ttotal: 1m\tremaining: 8m 5s\n",
      "55:\tlearn: 0.1479890\ttotal: 1m\tremaining: 8m 3s\n",
      "56:\tlearn: 0.1441944\ttotal: 1m 2s\tremaining: 8m 2s\n",
      "57:\tlearn: 0.1411042\ttotal: 1m 3s\tremaining: 8m\n",
      "58:\tlearn: 0.1381591\ttotal: 1m 4s\tremaining: 8m\n",
      "59:\tlearn: 0.1352537\ttotal: 1m 5s\tremaining: 7m 58s\n",
      "60:\tlearn: 0.1325180\ttotal: 1m 6s\tremaining: 7m 57s\n",
      "61:\tlearn: 0.1290936\ttotal: 1m 7s\tremaining: 7m 56s\n",
      "62:\tlearn: 0.1266187\ttotal: 1m 8s\tremaining: 7m 55s\n",
      "63:\tlearn: 0.1248098\ttotal: 1m 9s\tremaining: 7m 53s\n",
      "64:\tlearn: 0.1217197\ttotal: 1m 10s\tremaining: 7m 53s\n",
      "65:\tlearn: 0.1193990\ttotal: 1m 11s\tremaining: 7m 53s\n",
      "66:\tlearn: 0.1168375\ttotal: 1m 12s\tremaining: 7m 51s\n",
      "67:\tlearn: 0.1144773\ttotal: 1m 14s\tremaining: 7m 50s\n",
      "68:\tlearn: 0.1126085\ttotal: 1m 15s\tremaining: 7m 49s\n",
      "69:\tlearn: 0.1107999\ttotal: 1m 16s\tremaining: 7m 49s\n",
      "70:\tlearn: 0.1088502\ttotal: 1m 17s\tremaining: 7m 47s\n",
      "71:\tlearn: 0.1069326\ttotal: 1m 18s\tremaining: 7m 46s\n",
      "72:\tlearn: 0.1045344\ttotal: 1m 19s\tremaining: 7m 45s\n",
      "73:\tlearn: 0.1025075\ttotal: 1m 20s\tremaining: 7m 44s\n",
      "74:\tlearn: 0.1005760\ttotal: 1m 21s\tremaining: 7m 43s\n",
      "75:\tlearn: 0.0988275\ttotal: 1m 22s\tremaining: 7m 42s\n",
      "76:\tlearn: 0.0973376\ttotal: 1m 23s\tremaining: 7m 41s\n",
      "77:\tlearn: 0.0955263\ttotal: 1m 24s\tremaining: 7m 39s\n",
      "78:\tlearn: 0.0938360\ttotal: 1m 26s\tremaining: 7m 38s\n",
      "79:\tlearn: 0.0916311\ttotal: 1m 27s\tremaining: 7m 37s\n",
      "80:\tlearn: 0.0903460\ttotal: 1m 28s\tremaining: 7m 36s\n",
      "81:\tlearn: 0.0891088\ttotal: 1m 29s\tremaining: 7m 36s\n",
      "82:\tlearn: 0.0878098\ttotal: 1m 30s\tremaining: 7m 35s\n",
      "83:\tlearn: 0.0867280\ttotal: 1m 31s\tremaining: 7m 34s\n",
      "84:\tlearn: 0.0855337\ttotal: 1m 33s\tremaining: 7m 34s\n",
      "85:\tlearn: 0.0834693\ttotal: 1m 34s\tremaining: 7m 33s\n",
      "86:\tlearn: 0.0820199\ttotal: 1m 35s\tremaining: 7m 31s\n",
      "87:\tlearn: 0.0798932\ttotal: 1m 36s\tremaining: 7m 30s\n",
      "88:\tlearn: 0.0785515\ttotal: 1m 37s\tremaining: 7m 29s\n",
      "89:\tlearn: 0.0772701\ttotal: 1m 38s\tremaining: 7m 28s\n",
      "90:\tlearn: 0.0759491\ttotal: 1m 39s\tremaining: 7m 26s\n",
      "91:\tlearn: 0.0740428\ttotal: 1m 40s\tremaining: 7m 25s\n",
      "92:\tlearn: 0.0728663\ttotal: 1m 41s\tremaining: 7m 25s\n",
      "93:\tlearn: 0.0709775\ttotal: 1m 42s\tremaining: 7m 24s\n",
      "94:\tlearn: 0.0700797\ttotal: 1m 43s\tremaining: 7m 23s\n",
      "95:\tlearn: 0.0682480\ttotal: 1m 45s\tremaining: 7m 22s\n",
      "96:\tlearn: 0.0668738\ttotal: 1m 46s\tremaining: 7m 21s\n",
      "97:\tlearn: 0.0655622\ttotal: 1m 47s\tremaining: 7m 20s\n",
      "98:\tlearn: 0.0643541\ttotal: 1m 48s\tremaining: 7m 19s\n",
      "99:\tlearn: 0.0630522\ttotal: 1m 49s\tremaining: 7m 17s\n",
      "100:\tlearn: 0.0616266\ttotal: 1m 50s\tremaining: 7m 16s\n",
      "101:\tlearn: 0.0605479\ttotal: 1m 51s\tremaining: 7m 15s\n",
      "102:\tlearn: 0.0592160\ttotal: 1m 52s\tremaining: 7m 14s\n",
      "103:\tlearn: 0.0582948\ttotal: 1m 53s\tremaining: 7m 13s\n",
      "104:\tlearn: 0.0572014\ttotal: 1m 54s\tremaining: 7m 12s\n",
      "105:\tlearn: 0.0564152\ttotal: 1m 56s\tremaining: 7m 11s\n",
      "106:\tlearn: 0.0558642\ttotal: 1m 57s\tremaining: 7m 11s\n",
      "107:\tlearn: 0.0550554\ttotal: 1m 58s\tremaining: 7m 9s\n",
      "108:\tlearn: 0.0538695\ttotal: 1m 59s\tremaining: 7m 8s\n",
      "109:\tlearn: 0.0526443\ttotal: 2m\tremaining: 7m 6s\n",
      "110:\tlearn: 0.0515851\ttotal: 2m 1s\tremaining: 7m 4s\n",
      "111:\tlearn: 0.0507131\ttotal: 2m 2s\tremaining: 7m 2s\n",
      "112:\tlearn: 0.0500117\ttotal: 2m 3s\tremaining: 7m 1s\n",
      "113:\tlearn: 0.0488564\ttotal: 2m 3s\tremaining: 6m 59s\n",
      "114:\tlearn: 0.0479743\ttotal: 2m 4s\tremaining: 6m 58s\n",
      "115:\tlearn: 0.0472700\ttotal: 2m 5s\tremaining: 6m 56s\n",
      "116:\tlearn: 0.0460120\ttotal: 2m 6s\tremaining: 6m 54s\n",
      "117:\tlearn: 0.0453546\ttotal: 2m 7s\tremaining: 6m 53s\n",
      "118:\tlearn: 0.0444592\ttotal: 2m 8s\tremaining: 6m 51s\n",
      "119:\tlearn: 0.0437870\ttotal: 2m 9s\tremaining: 6m 50s\n",
      "120:\tlearn: 0.0431586\ttotal: 2m 10s\tremaining: 6m 48s\n",
      "121:\tlearn: 0.0424174\ttotal: 2m 11s\tremaining: 6m 46s\n",
      "122:\tlearn: 0.0418263\ttotal: 2m 12s\tremaining: 6m 45s\n",
      "123:\tlearn: 0.0407963\ttotal: 2m 13s\tremaining: 6m 43s\n",
      "124:\tlearn: 0.0399520\ttotal: 2m 14s\tremaining: 6m 42s\n",
      "125:\tlearn: 0.0393147\ttotal: 2m 14s\tremaining: 6m 40s\n",
      "126:\tlearn: 0.0386723\ttotal: 2m 15s\tremaining: 6m 38s\n",
      "127:\tlearn: 0.0382464\ttotal: 2m 16s\tremaining: 6m 37s\n",
      "128:\tlearn: 0.0375657\ttotal: 2m 17s\tremaining: 6m 35s\n",
      "129:\tlearn: 0.0368246\ttotal: 2m 18s\tremaining: 6m 33s\n",
      "130:\tlearn: 0.0361869\ttotal: 2m 19s\tremaining: 6m 32s\n",
      "131:\tlearn: 0.0355331\ttotal: 2m 20s\tremaining: 6m 30s\n",
      "132:\tlearn: 0.0348365\ttotal: 2m 20s\tremaining: 6m 28s\n",
      "133:\tlearn: 0.0342329\ttotal: 2m 21s\tremaining: 6m 27s\n",
      "134:\tlearn: 0.0337707\ttotal: 2m 22s\tremaining: 6m 25s\n",
      "135:\tlearn: 0.0331810\ttotal: 2m 23s\tremaining: 6m 24s\n",
      "136:\tlearn: 0.0325863\ttotal: 2m 24s\tremaining: 6m 22s\n",
      "137:\tlearn: 0.0319566\ttotal: 2m 25s\tremaining: 6m 21s\n",
      "138:\tlearn: 0.0316196\ttotal: 2m 26s\tremaining: 6m 20s\n",
      "139:\tlearn: 0.0311635\ttotal: 2m 27s\tremaining: 6m 18s\n",
      "140:\tlearn: 0.0305953\ttotal: 2m 28s\tremaining: 6m 17s\n",
      "141:\tlearn: 0.0299794\ttotal: 2m 29s\tremaining: 6m 15s\n",
      "142:\tlearn: 0.0295012\ttotal: 2m 29s\tremaining: 6m 14s\n",
      "143:\tlearn: 0.0289310\ttotal: 2m 30s\tremaining: 6m 13s\n",
      "144:\tlearn: 0.0284905\ttotal: 2m 31s\tremaining: 6m 11s\n",
      "145:\tlearn: 0.0279705\ttotal: 2m 32s\tremaining: 6m 9s\n",
      "146:\tlearn: 0.0274286\ttotal: 2m 33s\tremaining: 6m 8s\n",
      "147:\tlearn: 0.0270882\ttotal: 2m 34s\tremaining: 6m 7s\n",
      "148:\tlearn: 0.0266992\ttotal: 2m 35s\tremaining: 6m 5s\n",
      "149:\tlearn: 0.0261264\ttotal: 2m 35s\tremaining: 6m 3s\n",
      "150:\tlearn: 0.0258141\ttotal: 2m 36s\tremaining: 6m 1s\n",
      "151:\tlearn: 0.0253081\ttotal: 2m 37s\tremaining: 5m 59s\n",
      "152:\tlearn: 0.0250606\ttotal: 2m 38s\tremaining: 5m 58s\n",
      "153:\tlearn: 0.0246893\ttotal: 2m 38s\tremaining: 5m 56s\n",
      "154:\tlearn: 0.0242237\ttotal: 2m 39s\tremaining: 5m 54s\n",
      "155:\tlearn: 0.0238214\ttotal: 2m 40s\tremaining: 5m 53s\n",
      "156:\tlearn: 0.0232620\ttotal: 2m 41s\tremaining: 5m 51s\n",
      "157:\tlearn: 0.0229304\ttotal: 2m 41s\tremaining: 5m 50s\n",
      "158:\tlearn: 0.0225112\ttotal: 2m 42s\tremaining: 5m 48s\n",
      "159:\tlearn: 0.0221313\ttotal: 2m 43s\tremaining: 5m 47s\n",
      "160:\tlearn: 0.0218004\ttotal: 2m 44s\tremaining: 5m 45s\n",
      "161:\tlearn: 0.0213334\ttotal: 2m 44s\tremaining: 5m 43s\n",
      "162:\tlearn: 0.0209477\ttotal: 2m 45s\tremaining: 5m 42s\n",
      "163:\tlearn: 0.0206998\ttotal: 2m 46s\tremaining: 5m 40s\n",
      "164:\tlearn: 0.0204021\ttotal: 2m 47s\tremaining: 5m 39s\n",
      "165:\tlearn: 0.0200653\ttotal: 2m 47s\tremaining: 5m 37s\n",
      "166:\tlearn: 0.0198578\ttotal: 2m 48s\tremaining: 5m 36s\n",
      "167:\tlearn: 0.0195767\ttotal: 2m 49s\tremaining: 5m 34s\n",
      "168:\tlearn: 0.0192096\ttotal: 2m 50s\tremaining: 5m 33s\n",
      "169:\tlearn: 0.0188941\ttotal: 2m 50s\tremaining: 5m 31s\n",
      "170:\tlearn: 0.0185471\ttotal: 2m 51s\tremaining: 5m 30s\n",
      "171:\tlearn: 0.0182234\ttotal: 2m 52s\tremaining: 5m 28s\n",
      "172:\tlearn: 0.0179089\ttotal: 2m 53s\tremaining: 5m 27s\n",
      "173:\tlearn: 0.0176545\ttotal: 2m 53s\tremaining: 5m 25s\n",
      "174:\tlearn: 0.0172869\ttotal: 2m 54s\tremaining: 5m 24s\n",
      "175:\tlearn: 0.0170331\ttotal: 2m 55s\tremaining: 5m 22s\n",
      "176:\tlearn: 0.0167384\ttotal: 2m 56s\tremaining: 5m 21s\n",
      "177:\tlearn: 0.0165257\ttotal: 2m 56s\tremaining: 5m 19s\n",
      "178:\tlearn: 0.0163207\ttotal: 2m 57s\tremaining: 5m 18s\n",
      "179:\tlearn: 0.0161962\ttotal: 2m 58s\tremaining: 5m 17s\n",
      "180:\tlearn: 0.0159585\ttotal: 2m 59s\tremaining: 5m 15s\n",
      "181:\tlearn: 0.0156773\ttotal: 2m 59s\tremaining: 5m 14s\n",
      "182:\tlearn: 0.0153739\ttotal: 3m\tremaining: 5m 12s\n",
      "183:\tlearn: 0.0151913\ttotal: 3m\tremaining: 5m 10s\n",
      "184:\tlearn: 0.0149514\ttotal: 3m 1s\tremaining: 5m 9s\n",
      "185:\tlearn: 0.0147094\ttotal: 3m 2s\tremaining: 5m 7s\n",
      "186:\tlearn: 0.0145539\ttotal: 3m 2s\tremaining: 5m 6s\n",
      "187:\tlearn: 0.0142188\ttotal: 3m 3s\tremaining: 5m 4s\n",
      "188:\tlearn: 0.0140314\ttotal: 3m 3s\tremaining: 5m 2s\n",
      "189:\tlearn: 0.0139036\ttotal: 3m 4s\tremaining: 5m 1s\n",
      "190:\tlearn: 0.0137850\ttotal: 3m 5s\tremaining: 4m 59s\n",
      "191:\tlearn: 0.0135696\ttotal: 3m 5s\tremaining: 4m 58s\n",
      "192:\tlearn: 0.0133951\ttotal: 3m 6s\tremaining: 4m 56s\n",
      "193:\tlearn: 0.0132043\ttotal: 3m 7s\tremaining: 4m 55s\n",
      "194:\tlearn: 0.0131098\ttotal: 3m 7s\tremaining: 4m 53s\n",
      "195:\tlearn: 0.0128797\ttotal: 3m 8s\tremaining: 4m 52s\n",
      "196:\tlearn: 0.0126487\ttotal: 3m 8s\tremaining: 4m 50s\n",
      "197:\tlearn: 0.0123848\ttotal: 3m 9s\tremaining: 4m 49s\n",
      "198:\tlearn: 0.0121473\ttotal: 3m 10s\tremaining: 4m 47s\n",
      "199:\tlearn: 0.0119865\ttotal: 3m 10s\tremaining: 4m 46s\n",
      "200:\tlearn: 0.0118738\ttotal: 3m 11s\tremaining: 4m 44s\n",
      "201:\tlearn: 0.0116767\ttotal: 3m 11s\tremaining: 4m 43s\n",
      "202:\tlearn: 0.0115344\ttotal: 3m 12s\tremaining: 4m 41s\n",
      "203:\tlearn: 0.0114122\ttotal: 3m 13s\tremaining: 4m 40s\n",
      "204:\tlearn: 0.0112243\ttotal: 3m 13s\tremaining: 4m 38s\n",
      "205:\tlearn: 0.0110784\ttotal: 3m 14s\tremaining: 4m 37s\n",
      "206:\tlearn: 0.0109292\ttotal: 3m 15s\tremaining: 4m 36s\n",
      "207:\tlearn: 0.0107404\ttotal: 3m 15s\tremaining: 4m 34s\n",
      "208:\tlearn: 0.0106074\ttotal: 3m 16s\tremaining: 4m 33s\n",
      "209:\tlearn: 0.0105076\ttotal: 3m 17s\tremaining: 4m 32s\n",
      "210:\tlearn: 0.0103760\ttotal: 3m 18s\tremaining: 4m 31s\n",
      "211:\tlearn: 0.0102886\ttotal: 3m 18s\tremaining: 4m 30s\n",
      "212:\tlearn: 0.0101391\ttotal: 3m 19s\tremaining: 4m 29s\n",
      "213:\tlearn: 0.0099960\ttotal: 3m 20s\tremaining: 4m 27s\n",
      "214:\tlearn: 0.0098846\ttotal: 3m 21s\tremaining: 4m 26s\n",
      "215:\tlearn: 0.0098142\ttotal: 3m 22s\tremaining: 4m 25s\n",
      "216:\tlearn: 0.0096729\ttotal: 3m 23s\tremaining: 4m 24s\n",
      "217:\tlearn: 0.0095746\ttotal: 3m 24s\tremaining: 4m 24s\n",
      "218:\tlearn: 0.0094800\ttotal: 3m 25s\tremaining: 4m 23s\n",
      "219:\tlearn: 0.0093521\ttotal: 3m 26s\tremaining: 4m 22s\n",
      "220:\tlearn: 0.0092134\ttotal: 3m 27s\tremaining: 4m 21s\n",
      "221:\tlearn: 0.0091329\ttotal: 3m 28s\tremaining: 4m 20s\n",
      "222:\tlearn: 0.0090343\ttotal: 3m 29s\tremaining: 4m 20s\n",
      "223:\tlearn: 0.0088889\ttotal: 3m 30s\tremaining: 4m 18s\n",
      "224:\tlearn: 0.0088001\ttotal: 3m 31s\tremaining: 4m 18s\n",
      "225:\tlearn: 0.0086426\ttotal: 3m 32s\tremaining: 4m 17s\n",
      "226:\tlearn: 0.0085685\ttotal: 3m 33s\tremaining: 4m 16s\n",
      "227:\tlearn: 0.0085008\ttotal: 3m 33s\tremaining: 4m 15s\n",
      "228:\tlearn: 0.0083589\ttotal: 3m 34s\tremaining: 4m 13s\n",
      "229:\tlearn: 0.0082277\ttotal: 3m 35s\tremaining: 4m 12s\n",
      "230:\tlearn: 0.0081510\ttotal: 3m 36s\tremaining: 4m 11s\n",
      "231:\tlearn: 0.0080674\ttotal: 3m 36s\tremaining: 4m 10s\n",
      "232:\tlearn: 0.0079367\ttotal: 3m 37s\tremaining: 4m 9s\n",
      "233:\tlearn: 0.0078015\ttotal: 3m 38s\tremaining: 4m 8s\n",
      "234:\tlearn: 0.0077215\ttotal: 3m 39s\tremaining: 4m 7s\n",
      "235:\tlearn: 0.0076583\ttotal: 3m 40s\tremaining: 4m 6s\n",
      "236:\tlearn: 0.0075804\ttotal: 3m 41s\tremaining: 4m 5s\n",
      "237:\tlearn: 0.0074637\ttotal: 3m 41s\tremaining: 4m 4s\n",
      "238:\tlearn: 0.0073899\ttotal: 3m 42s\tremaining: 4m 3s\n",
      "239:\tlearn: 0.0072929\ttotal: 3m 43s\tremaining: 4m 2s\n",
      "240:\tlearn: 0.0071952\ttotal: 3m 44s\tremaining: 4m 1s\n",
      "241:\tlearn: 0.0071431\ttotal: 3m 45s\tremaining: 3m 59s\n",
      "242:\tlearn: 0.0070235\ttotal: 3m 45s\tremaining: 3m 58s\n",
      "243:\tlearn: 0.0068978\ttotal: 3m 46s\tremaining: 3m 57s\n",
      "244:\tlearn: 0.0068139\ttotal: 3m 47s\tremaining: 3m 56s\n",
      "245:\tlearn: 0.0067584\ttotal: 3m 48s\tremaining: 3m 55s\n",
      "246:\tlearn: 0.0066845\ttotal: 3m 49s\tremaining: 3m 54s\n",
      "247:\tlearn: 0.0065961\ttotal: 3m 49s\tremaining: 3m 53s\n",
      "248:\tlearn: 0.0065022\ttotal: 3m 50s\tremaining: 3m 52s\n",
      "249:\tlearn: 0.0064221\ttotal: 3m 51s\tremaining: 3m 51s\n",
      "250:\tlearn: 0.0062875\ttotal: 3m 52s\tremaining: 3m 50s\n",
      "251:\tlearn: 0.0061870\ttotal: 3m 53s\tremaining: 3m 49s\n",
      "252:\tlearn: 0.0061427\ttotal: 3m 53s\tremaining: 3m 48s\n",
      "253:\tlearn: 0.0060850\ttotal: 3m 54s\tremaining: 3m 47s\n",
      "254:\tlearn: 0.0059647\ttotal: 3m 55s\tremaining: 3m 46s\n",
      "255:\tlearn: 0.0059054\ttotal: 3m 56s\tremaining: 3m 45s\n",
      "256:\tlearn: 0.0058128\ttotal: 3m 57s\tremaining: 3m 44s\n",
      "257:\tlearn: 0.0057231\ttotal: 3m 57s\tremaining: 3m 43s\n",
      "258:\tlearn: 0.0056714\ttotal: 3m 58s\tremaining: 3m 42s\n",
      "259:\tlearn: 0.0055568\ttotal: 3m 59s\tremaining: 3m 41s\n",
      "260:\tlearn: 0.0054845\ttotal: 4m\tremaining: 3m 40s\n",
      "261:\tlearn: 0.0054533\ttotal: 4m 1s\tremaining: 3m 39s\n",
      "262:\tlearn: 0.0054070\ttotal: 4m 2s\tremaining: 3m 38s\n",
      "263:\tlearn: 0.0053515\ttotal: 4m 3s\tremaining: 3m 37s\n",
      "264:\tlearn: 0.0052737\ttotal: 4m 4s\tremaining: 3m 36s\n",
      "265:\tlearn: 0.0052233\ttotal: 4m 4s\tremaining: 3m 35s\n",
      "266:\tlearn: 0.0051872\ttotal: 4m 5s\tremaining: 3m 34s\n",
      "267:\tlearn: 0.0051404\ttotal: 4m 6s\tremaining: 3m 33s\n",
      "268:\tlearn: 0.0050834\ttotal: 4m 7s\tremaining: 3m 32s\n",
      "269:\tlearn: 0.0050237\ttotal: 4m 8s\tremaining: 3m 31s\n",
      "270:\tlearn: 0.0049423\ttotal: 4m 8s\tremaining: 3m 30s\n",
      "271:\tlearn: 0.0048946\ttotal: 4m 9s\tremaining: 3m 29s\n",
      "272:\tlearn: 0.0048306\ttotal: 4m 10s\tremaining: 3m 28s\n",
      "273:\tlearn: 0.0047686\ttotal: 4m 11s\tremaining: 3m 27s\n",
      "274:\tlearn: 0.0047094\ttotal: 4m 12s\tremaining: 3m 26s\n",
      "275:\tlearn: 0.0046620\ttotal: 4m 13s\tremaining: 3m 25s\n",
      "276:\tlearn: 0.0045850\ttotal: 4m 14s\tremaining: 3m 24s\n",
      "277:\tlearn: 0.0045428\ttotal: 4m 15s\tremaining: 3m 23s\n",
      "278:\tlearn: 0.0044739\ttotal: 4m 15s\tremaining: 3m 22s\n",
      "279:\tlearn: 0.0044382\ttotal: 4m 16s\tremaining: 3m 21s\n",
      "280:\tlearn: 0.0043944\ttotal: 4m 17s\tremaining: 3m 20s\n",
      "281:\tlearn: 0.0043134\ttotal: 4m 18s\tremaining: 3m 19s\n",
      "282:\tlearn: 0.0042565\ttotal: 4m 19s\tremaining: 3m 18s\n",
      "283:\tlearn: 0.0042244\ttotal: 4m 20s\tremaining: 3m 17s\n",
      "284:\tlearn: 0.0041677\ttotal: 4m 20s\tremaining: 3m 16s\n",
      "285:\tlearn: 0.0041377\ttotal: 4m 21s\tremaining: 3m 15s\n",
      "286:\tlearn: 0.0041066\ttotal: 4m 22s\tremaining: 3m 14s\n",
      "287:\tlearn: 0.0040437\ttotal: 4m 23s\tremaining: 3m 13s\n",
      "288:\tlearn: 0.0039950\ttotal: 4m 24s\tremaining: 3m 12s\n",
      "289:\tlearn: 0.0039619\ttotal: 4m 25s\tremaining: 3m 12s\n",
      "290:\tlearn: 0.0039155\ttotal: 4m 26s\tremaining: 3m 11s\n",
      "291:\tlearn: 0.0038745\ttotal: 4m 26s\tremaining: 3m 10s\n",
      "292:\tlearn: 0.0038324\ttotal: 4m 27s\tremaining: 3m 9s\n",
      "293:\tlearn: 0.0037793\ttotal: 4m 28s\tremaining: 3m 8s\n",
      "294:\tlearn: 0.0037245\ttotal: 4m 30s\tremaining: 3m 7s\n",
      "295:\tlearn: 0.0036950\ttotal: 4m 31s\tremaining: 3m 6s\n",
      "296:\tlearn: 0.0036534\ttotal: 4m 31s\tremaining: 3m 5s\n",
      "297:\tlearn: 0.0036071\ttotal: 4m 32s\tremaining: 3m 4s\n",
      "298:\tlearn: 0.0035518\ttotal: 4m 33s\tremaining: 3m 4s\n",
      "299:\tlearn: 0.0035282\ttotal: 4m 34s\tremaining: 3m 3s\n",
      "300:\tlearn: 0.0034737\ttotal: 4m 35s\tremaining: 3m 2s\n",
      "301:\tlearn: 0.0034382\ttotal: 4m 36s\tremaining: 3m 1s\n",
      "302:\tlearn: 0.0034146\ttotal: 4m 37s\tremaining: 3m\n",
      "303:\tlearn: 0.0033895\ttotal: 4m 38s\tremaining: 2m 59s\n",
      "304:\tlearn: 0.0033550\ttotal: 4m 39s\tremaining: 2m 58s\n",
      "305:\tlearn: 0.0033261\ttotal: 4m 40s\tremaining: 2m 57s\n",
      "306:\tlearn: 0.0033051\ttotal: 4m 41s\tremaining: 2m 57s\n",
      "307:\tlearn: 0.0032832\ttotal: 4m 43s\tremaining: 2m 56s\n",
      "308:\tlearn: 0.0032614\ttotal: 4m 44s\tremaining: 2m 55s\n",
      "309:\tlearn: 0.0032234\ttotal: 4m 45s\tremaining: 2m 54s\n",
      "310:\tlearn: 0.0031820\ttotal: 4m 46s\tremaining: 2m 54s\n",
      "311:\tlearn: 0.0031386\ttotal: 4m 47s\tremaining: 2m 53s\n",
      "312:\tlearn: 0.0031084\ttotal: 4m 48s\tremaining: 2m 52s\n",
      "313:\tlearn: 0.0030717\ttotal: 4m 50s\tremaining: 2m 51s\n",
      "314:\tlearn: 0.0030560\ttotal: 4m 51s\tremaining: 2m 51s\n",
      "315:\tlearn: 0.0030387\ttotal: 4m 52s\tremaining: 2m 50s\n",
      "316:\tlearn: 0.0030089\ttotal: 4m 53s\tremaining: 2m 49s\n",
      "317:\tlearn: 0.0029662\ttotal: 4m 54s\tremaining: 2m 48s\n",
      "318:\tlearn: 0.0029471\ttotal: 4m 55s\tremaining: 2m 47s\n",
      "319:\tlearn: 0.0029133\ttotal: 4m 56s\tremaining: 2m 47s\n",
      "320:\tlearn: 0.0028972\ttotal: 4m 58s\tremaining: 2m 46s\n",
      "321:\tlearn: 0.0028814\ttotal: 4m 59s\tremaining: 2m 45s\n",
      "322:\tlearn: 0.0028621\ttotal: 5m\tremaining: 2m 44s\n",
      "323:\tlearn: 0.0028446\ttotal: 5m 1s\tremaining: 2m 43s\n",
      "324:\tlearn: 0.0028088\ttotal: 5m 3s\tremaining: 2m 43s\n",
      "325:\tlearn: 0.0027927\ttotal: 5m 4s\tremaining: 2m 42s\n",
      "326:\tlearn: 0.0027727\ttotal: 5m 5s\tremaining: 2m 41s\n",
      "327:\tlearn: 0.0027578\ttotal: 5m 6s\tremaining: 2m 40s\n",
      "328:\tlearn: 0.0027336\ttotal: 5m 7s\tremaining: 2m 40s\n",
      "329:\tlearn: 0.0027012\ttotal: 5m 8s\tremaining: 2m 39s\n",
      "330:\tlearn: 0.0026697\ttotal: 5m 10s\tremaining: 2m 38s\n",
      "331:\tlearn: 0.0026376\ttotal: 5m 11s\tremaining: 2m 37s\n",
      "332:\tlearn: 0.0026190\ttotal: 5m 12s\tremaining: 2m 36s\n",
      "333:\tlearn: 0.0026010\ttotal: 5m 13s\tremaining: 2m 35s\n",
      "334:\tlearn: 0.0025725\ttotal: 5m 14s\tremaining: 2m 34s\n",
      "335:\tlearn: 0.0025314\ttotal: 5m 15s\tremaining: 2m 34s\n",
      "336:\tlearn: 0.0025080\ttotal: 5m 17s\tremaining: 2m 33s\n",
      "337:\tlearn: 0.0024847\ttotal: 5m 18s\tremaining: 2m 32s\n",
      "338:\tlearn: 0.0024625\ttotal: 5m 19s\tremaining: 2m 31s\n",
      "339:\tlearn: 0.0024469\ttotal: 5m 20s\tremaining: 2m 30s\n",
      "340:\tlearn: 0.0024186\ttotal: 5m 21s\tremaining: 2m 30s\n",
      "341:\tlearn: 0.0023845\ttotal: 5m 22s\tremaining: 2m 29s\n",
      "342:\tlearn: 0.0023549\ttotal: 5m 24s\tremaining: 2m 28s\n",
      "343:\tlearn: 0.0023424\ttotal: 5m 25s\tremaining: 2m 27s\n",
      "344:\tlearn: 0.0023229\ttotal: 5m 26s\tremaining: 2m 26s\n",
      "345:\tlearn: 0.0022965\ttotal: 5m 27s\tremaining: 2m 25s\n",
      "346:\tlearn: 0.0022864\ttotal: 5m 28s\tremaining: 2m 25s\n",
      "347:\tlearn: 0.0022756\ttotal: 5m 30s\tremaining: 2m 24s\n",
      "348:\tlearn: 0.0022594\ttotal: 5m 31s\tremaining: 2m 23s\n",
      "349:\tlearn: 0.0022360\ttotal: 5m 32s\tremaining: 2m 22s\n",
      "350:\tlearn: 0.0022135\ttotal: 5m 33s\tremaining: 2m 21s\n",
      "351:\tlearn: 0.0022012\ttotal: 5m 34s\tremaining: 2m 20s\n",
      "352:\tlearn: 0.0021747\ttotal: 5m 36s\tremaining: 2m 19s\n",
      "353:\tlearn: 0.0021549\ttotal: 5m 37s\tremaining: 2m 19s\n",
      "354:\tlearn: 0.0021388\ttotal: 5m 38s\tremaining: 2m 18s\n",
      "355:\tlearn: 0.0021250\ttotal: 5m 39s\tremaining: 2m 17s\n",
      "356:\tlearn: 0.0021012\ttotal: 5m 40s\tremaining: 2m 16s\n",
      "357:\tlearn: 0.0020734\ttotal: 5m 41s\tremaining: 2m 15s\n",
      "358:\tlearn: 0.0020611\ttotal: 5m 42s\tremaining: 2m 14s\n",
      "359:\tlearn: 0.0020436\ttotal: 5m 44s\tremaining: 2m 13s\n",
      "360:\tlearn: 0.0020254\ttotal: 5m 45s\tremaining: 2m 12s\n",
      "361:\tlearn: 0.0020171\ttotal: 5m 46s\tremaining: 2m 12s\n",
      "362:\tlearn: 0.0020099\ttotal: 5m 47s\tremaining: 2m 11s\n",
      "363:\tlearn: 0.0020022\ttotal: 5m 48s\tremaining: 2m 10s\n",
      "364:\tlearn: 0.0019934\ttotal: 5m 50s\tremaining: 2m 9s\n",
      "365:\tlearn: 0.0019717\ttotal: 5m 51s\tremaining: 2m 8s\n",
      "366:\tlearn: 0.0019451\ttotal: 5m 52s\tremaining: 2m 7s\n",
      "367:\tlearn: 0.0019319\ttotal: 5m 53s\tremaining: 2m 6s\n",
      "368:\tlearn: 0.0019194\ttotal: 5m 54s\tremaining: 2m 5s\n",
      "369:\tlearn: 0.0019074\ttotal: 5m 56s\tremaining: 2m 5s\n",
      "370:\tlearn: 0.0018994\ttotal: 5m 57s\tremaining: 2m 4s\n",
      "371:\tlearn: 0.0018784\ttotal: 5m 58s\tremaining: 2m 3s\n",
      "372:\tlearn: 0.0018536\ttotal: 5m 59s\tremaining: 2m 2s\n",
      "373:\tlearn: 0.0018374\ttotal: 6m\tremaining: 2m 1s\n",
      "374:\tlearn: 0.0018181\ttotal: 6m 1s\tremaining: 2m\n",
      "375:\tlearn: 0.0018098\ttotal: 6m 2s\tremaining: 1m 59s\n",
      "376:\tlearn: 0.0017959\ttotal: 6m 3s\tremaining: 1m 58s\n",
      "377:\tlearn: 0.0017840\ttotal: 6m 5s\tremaining: 1m 57s\n",
      "378:\tlearn: 0.0017691\ttotal: 6m 6s\tremaining: 1m 56s\n",
      "379:\tlearn: 0.0017595\ttotal: 6m 7s\tremaining: 1m 56s\n",
      "380:\tlearn: 0.0017411\ttotal: 6m 8s\tremaining: 1m 55s\n",
      "381:\tlearn: 0.0017293\ttotal: 6m 9s\tremaining: 1m 54s\n",
      "382:\tlearn: 0.0017076\ttotal: 6m 10s\tremaining: 1m 53s\n",
      "383:\tlearn: 0.0017019\ttotal: 6m 12s\tremaining: 1m 52s\n",
      "384:\tlearn: 0.0016887\ttotal: 6m 13s\tremaining: 1m 51s\n",
      "385:\tlearn: 0.0016802\ttotal: 6m 14s\tremaining: 1m 50s\n",
      "386:\tlearn: 0.0016674\ttotal: 6m 15s\tremaining: 1m 49s\n",
      "387:\tlearn: 0.0016550\ttotal: 6m 17s\tremaining: 1m 48s\n",
      "388:\tlearn: 0.0016438\ttotal: 6m 18s\tremaining: 1m 47s\n",
      "389:\tlearn: 0.0016231\ttotal: 6m 19s\tremaining: 1m 46s\n",
      "390:\tlearn: 0.0016118\ttotal: 6m 20s\tremaining: 1m 46s\n",
      "391:\tlearn: 0.0015939\ttotal: 6m 21s\tremaining: 1m 45s\n",
      "392:\tlearn: 0.0015778\ttotal: 6m 22s\tremaining: 1m 44s\n",
      "393:\tlearn: 0.0015620\ttotal: 6m 23s\tremaining: 1m 43s\n",
      "394:\tlearn: 0.0015515\ttotal: 6m 25s\tremaining: 1m 42s\n",
      "395:\tlearn: 0.0015414\ttotal: 6m 26s\tremaining: 1m 41s\n",
      "396:\tlearn: 0.0015392\ttotal: 6m 27s\tremaining: 1m 40s\n",
      "397:\tlearn: 0.0015275\ttotal: 6m 28s\tremaining: 1m 39s\n",
      "398:\tlearn: 0.0015224\ttotal: 6m 29s\tremaining: 1m 38s\n",
      "399:\tlearn: 0.0015145\ttotal: 6m 31s\tremaining: 1m 37s\n",
      "400:\tlearn: 0.0015002\ttotal: 6m 32s\tremaining: 1m 36s\n",
      "401:\tlearn: 0.0014868\ttotal: 6m 33s\tremaining: 1m 35s\n",
      "402:\tlearn: 0.0014698\ttotal: 6m 34s\tremaining: 1m 34s\n",
      "403:\tlearn: 0.0014533\ttotal: 6m 35s\tremaining: 1m 34s\n",
      "404:\tlearn: 0.0014447\ttotal: 6m 36s\tremaining: 1m 33s\n",
      "405:\tlearn: 0.0014357\ttotal: 6m 38s\tremaining: 1m 32s\n",
      "406:\tlearn: 0.0014278\ttotal: 6m 39s\tremaining: 1m 31s\n",
      "407:\tlearn: 0.0014189\ttotal: 6m 40s\tremaining: 1m 30s\n",
      "408:\tlearn: 0.0014104\ttotal: 6m 41s\tremaining: 1m 29s\n",
      "409:\tlearn: 0.0013990\ttotal: 6m 42s\tremaining: 1m 28s\n",
      "410:\tlearn: 0.0013857\ttotal: 6m 44s\tremaining: 1m 27s\n",
      "411:\tlearn: 0.0013798\ttotal: 6m 45s\tremaining: 1m 26s\n",
      "412:\tlearn: 0.0013658\ttotal: 6m 46s\tremaining: 1m 25s\n",
      "413:\tlearn: 0.0013569\ttotal: 6m 47s\tremaining: 1m 24s\n",
      "414:\tlearn: 0.0013476\ttotal: 6m 48s\tremaining: 1m 23s\n",
      "415:\tlearn: 0.0013367\ttotal: 6m 49s\tremaining: 1m 22s\n",
      "416:\tlearn: 0.0013328\ttotal: 6m 50s\tremaining: 1m 21s\n",
      "417:\tlearn: 0.0013260\ttotal: 6m 52s\tremaining: 1m 20s\n",
      "418:\tlearn: 0.0013175\ttotal: 6m 53s\tremaining: 1m 19s\n",
      "419:\tlearn: 0.0013031\ttotal: 6m 54s\tremaining: 1m 18s\n",
      "420:\tlearn: 0.0012921\ttotal: 6m 55s\tremaining: 1m 18s\n",
      "421:\tlearn: 0.0012823\ttotal: 6m 56s\tremaining: 1m 17s\n",
      "422:\tlearn: 0.0012679\ttotal: 6m 57s\tremaining: 1m 16s\n",
      "423:\tlearn: 0.0012595\ttotal: 6m 59s\tremaining: 1m 15s\n",
      "424:\tlearn: 0.0012528\ttotal: 7m\tremaining: 1m 14s\n",
      "425:\tlearn: 0.0012454\ttotal: 7m 1s\tremaining: 1m 13s\n",
      "426:\tlearn: 0.0012417\ttotal: 7m 2s\tremaining: 1m 12s\n",
      "427:\tlearn: 0.0012355\ttotal: 7m 3s\tremaining: 1m 11s\n",
      "428:\tlearn: 0.0012255\ttotal: 7m 5s\tremaining: 1m 10s\n",
      "429:\tlearn: 0.0012174\ttotal: 7m 6s\tremaining: 1m 9s\n",
      "430:\tlearn: 0.0012059\ttotal: 7m 7s\tremaining: 1m 8s\n",
      "431:\tlearn: 0.0011998\ttotal: 7m 8s\tremaining: 1m 7s\n",
      "432:\tlearn: 0.0011925\ttotal: 7m 9s\tremaining: 1m 6s\n",
      "433:\tlearn: 0.0011870\ttotal: 7m 10s\tremaining: 1m 5s\n",
      "434:\tlearn: 0.0011736\ttotal: 7m 11s\tremaining: 1m 4s\n",
      "435:\tlearn: 0.0011721\ttotal: 7m 13s\tremaining: 1m 3s\n",
      "436:\tlearn: 0.0011636\ttotal: 7m 14s\tremaining: 1m 2s\n",
      "437:\tlearn: 0.0011535\ttotal: 7m 15s\tremaining: 1m 1s\n",
      "438:\tlearn: 0.0011481\ttotal: 7m 16s\tremaining: 1m\n",
      "439:\tlearn: 0.0011423\ttotal: 7m 17s\tremaining: 59.7s\n",
      "440:\tlearn: 0.0011322\ttotal: 7m 18s\tremaining: 58.7s\n",
      "441:\tlearn: 0.0011231\ttotal: 7m 19s\tremaining: 57.7s\n",
      "442:\tlearn: 0.0011134\ttotal: 7m 21s\tremaining: 56.7s\n",
      "443:\tlearn: 0.0011055\ttotal: 7m 22s\tremaining: 55.8s\n",
      "444:\tlearn: 0.0010992\ttotal: 7m 23s\tremaining: 54.8s\n",
      "445:\tlearn: 0.0010911\ttotal: 7m 24s\tremaining: 53.8s\n",
      "446:\tlearn: 0.0010812\ttotal: 7m 25s\tremaining: 52.8s\n",
      "447:\tlearn: 0.0010715\ttotal: 7m 26s\tremaining: 51.9s\n",
      "448:\tlearn: 0.0010618\ttotal: 7m 27s\tremaining: 50.9s\n",
      "449:\tlearn: 0.0010521\ttotal: 7m 29s\tremaining: 49.9s\n",
      "450:\tlearn: 0.0010455\ttotal: 7m 30s\tremaining: 48.9s\n",
      "451:\tlearn: 0.0010374\ttotal: 7m 31s\tremaining: 47.9s\n",
      "452:\tlearn: 0.0010265\ttotal: 7m 32s\tremaining: 46.9s\n",
      "453:\tlearn: 0.0010203\ttotal: 7m 33s\tremaining: 45.9s\n",
      "454:\tlearn: 0.0010165\ttotal: 7m 34s\tremaining: 45s\n",
      "455:\tlearn: 0.0010102\ttotal: 7m 35s\tremaining: 44s\n",
      "456:\tlearn: 0.0010027\ttotal: 7m 36s\tremaining: 43s\n",
      "457:\tlearn: 0.0009958\ttotal: 7m 38s\tremaining: 42s\n",
      "458:\tlearn: 0.0009905\ttotal: 7m 39s\tremaining: 41s\n",
      "459:\tlearn: 0.0009866\ttotal: 7m 40s\tremaining: 40s\n",
      "460:\tlearn: 0.0009824\ttotal: 7m 41s\tremaining: 39s\n",
      "461:\tlearn: 0.0009758\ttotal: 7m 42s\tremaining: 38s\n",
      "462:\tlearn: 0.0009639\ttotal: 7m 43s\tremaining: 37.1s\n",
      "463:\tlearn: 0.0009593\ttotal: 7m 44s\tremaining: 36.1s\n",
      "464:\tlearn: 0.0009563\ttotal: 7m 45s\tremaining: 35.1s\n",
      "465:\tlearn: 0.0009510\ttotal: 7m 47s\tremaining: 34.1s\n",
      "466:\tlearn: 0.0009481\ttotal: 7m 48s\tremaining: 33.1s\n",
      "467:\tlearn: 0.0009450\ttotal: 7m 49s\tremaining: 32.1s\n",
      "468:\tlearn: 0.0009354\ttotal: 7m 50s\tremaining: 31.1s\n",
      "469:\tlearn: 0.0009216\ttotal: 7m 51s\tremaining: 30.1s\n",
      "470:\tlearn: 0.0009202\ttotal: 7m 53s\tremaining: 29.1s\n",
      "471:\tlearn: 0.0009126\ttotal: 7m 54s\tremaining: 28.1s\n",
      "472:\tlearn: 0.0009046\ttotal: 7m 55s\tremaining: 27.1s\n",
      "473:\tlearn: 0.0008956\ttotal: 7m 56s\tremaining: 26.1s\n",
      "474:\tlearn: 0.0008929\ttotal: 7m 57s\tremaining: 25.1s\n",
      "475:\tlearn: 0.0008855\ttotal: 7m 58s\tremaining: 24.1s\n",
      "476:\tlearn: 0.0008828\ttotal: 7m 59s\tremaining: 23.1s\n",
      "477:\tlearn: 0.0008815\ttotal: 8m 1s\tremaining: 22.1s\n",
      "478:\tlearn: 0.0008770\ttotal: 8m 2s\tremaining: 21.1s\n",
      "479:\tlearn: 0.0008676\ttotal: 8m 3s\tremaining: 20.1s\n",
      "480:\tlearn: 0.0008618\ttotal: 8m 4s\tremaining: 19.1s\n",
      "481:\tlearn: 0.0008558\ttotal: 8m 5s\tremaining: 18.1s\n",
      "482:\tlearn: 0.0008510\ttotal: 8m 6s\tremaining: 17.1s\n",
      "483:\tlearn: 0.0008483\ttotal: 8m 8s\tremaining: 16.1s\n",
      "484:\tlearn: 0.0008470\ttotal: 8m 9s\tremaining: 15.1s\n",
      "485:\tlearn: 0.0008433\ttotal: 8m 10s\tremaining: 14.1s\n",
      "486:\tlearn: 0.0008415\ttotal: 8m 11s\tremaining: 13.1s\n",
      "487:\tlearn: 0.0008339\ttotal: 8m 12s\tremaining: 12.1s\n",
      "488:\tlearn: 0.0008299\ttotal: 8m 14s\tremaining: 11.1s\n",
      "489:\tlearn: 0.0008239\ttotal: 8m 15s\tremaining: 10.1s\n",
      "490:\tlearn: 0.0008155\ttotal: 8m 16s\tremaining: 9.1s\n",
      "491:\tlearn: 0.0008090\ttotal: 8m 17s\tremaining: 8.09s\n",
      "492:\tlearn: 0.0008054\ttotal: 8m 18s\tremaining: 7.08s\n",
      "493:\tlearn: 0.0008003\ttotal: 8m 19s\tremaining: 6.07s\n",
      "494:\tlearn: 0.0007973\ttotal: 8m 20s\tremaining: 5.06s\n",
      "495:\tlearn: 0.0007940\ttotal: 8m 22s\tremaining: 4.05s\n",
      "496:\tlearn: 0.0007875\ttotal: 8m 23s\tremaining: 3.04s\n",
      "497:\tlearn: 0.0007831\ttotal: 8m 24s\tremaining: 2.03s\n",
      "498:\tlearn: 0.0007765\ttotal: 8m 25s\tremaining: 1.01s\n",
      "499:\tlearn: 0.0007723\ttotal: 8m 26s\tremaining: 0us\n",
      "Accuracy: 0.9999869572589375\n",
      "\n",
      "Confusion Matrix:\n",
      " [[76530     2]\n",
      " [    0 76810]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     76532\n",
      "           1       1.00      1.00      1.00     76810\n",
      "\n",
      "    accuracy                           1.00    153342\n",
      "   macro avg       1.00      1.00      1.00    153342\n",
      "weighted avg       1.00      1.00      1.00    153342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Fraud'], axis=1)\n",
    "y = df['Fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a CatBoost Classifier\n",
    "model = CatBoostClassifier(iterations=500, depth=10, learning_rate=0.05, loss_function='MultiClass', random_seed=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, cat_features=None)  # You can specify categorical features if needed\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/DMEPOS/dmepos_smote_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0.1\",\"Unnamed: 0\",\"Rfrg_NPI\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6557283\ttotal: 1.12s\tremaining: 9m 18s\n",
      "1:\tlearn: 0.6225825\ttotal: 2.23s\tremaining: 9m 14s\n",
      "2:\tlearn: 0.5924241\ttotal: 3.48s\tremaining: 9m 36s\n",
      "3:\tlearn: 0.5656682\ttotal: 4.53s\tremaining: 9m 22s\n",
      "4:\tlearn: 0.5372390\ttotal: 5.63s\tremaining: 9m 17s\n",
      "5:\tlearn: 0.5136950\ttotal: 6.9s\tremaining: 9m 28s\n",
      "6:\tlearn: 0.4884111\ttotal: 7.91s\tremaining: 9m 16s\n",
      "7:\tlearn: 0.4656611\ttotal: 9.06s\tremaining: 9m 17s\n",
      "8:\tlearn: 0.4450625\ttotal: 10.2s\tremaining: 9m 17s\n",
      "9:\tlearn: 0.4274337\ttotal: 11.3s\tremaining: 9m 12s\n",
      "10:\tlearn: 0.4102172\ttotal: 12.4s\tremaining: 9m 12s\n",
      "11:\tlearn: 0.3936229\ttotal: 13.5s\tremaining: 9m 10s\n",
      "12:\tlearn: 0.3779130\ttotal: 14.6s\tremaining: 9m 8s\n",
      "13:\tlearn: 0.3615233\ttotal: 15.8s\tremaining: 9m 9s\n",
      "14:\tlearn: 0.3488430\ttotal: 16.9s\tremaining: 9m 5s\n",
      "15:\tlearn: 0.3342742\ttotal: 18s\tremaining: 9m 5s\n",
      "16:\tlearn: 0.3214344\ttotal: 19.2s\tremaining: 9m 6s\n",
      "17:\tlearn: 0.3097549\ttotal: 20.3s\tremaining: 9m 3s\n",
      "18:\tlearn: 0.2984430\ttotal: 21.5s\tremaining: 9m 5s\n",
      "19:\tlearn: 0.2882828\ttotal: 22.7s\tremaining: 9m 5s\n",
      "20:\tlearn: 0.2786338\ttotal: 23.8s\tremaining: 9m 2s\n",
      "21:\tlearn: 0.2685457\ttotal: 25s\tremaining: 9m 3s\n",
      "22:\tlearn: 0.2591461\ttotal: 26.1s\tremaining: 9m 2s\n",
      "23:\tlearn: 0.2505893\ttotal: 27.3s\tremaining: 9m 1s\n",
      "24:\tlearn: 0.2422310\ttotal: 28.4s\tremaining: 9m\n",
      "25:\tlearn: 0.2343831\ttotal: 29.5s\tremaining: 8m 57s\n",
      "26:\tlearn: 0.2272903\ttotal: 30.6s\tremaining: 8m 56s\n",
      "27:\tlearn: 0.2197183\ttotal: 31.8s\tremaining: 8m 55s\n",
      "28:\tlearn: 0.2134373\ttotal: 32.9s\tremaining: 8m 53s\n",
      "29:\tlearn: 0.2065824\ttotal: 34s\tremaining: 8m 52s\n",
      "30:\tlearn: 0.2004599\ttotal: 35.2s\tremaining: 8m 52s\n",
      "31:\tlearn: 0.1940278\ttotal: 36.2s\tremaining: 8m 49s\n",
      "32:\tlearn: 0.1882565\ttotal: 37.4s\tremaining: 8m 49s\n",
      "33:\tlearn: 0.1825666\ttotal: 38.4s\tremaining: 8m 46s\n",
      "34:\tlearn: 0.1778272\ttotal: 39.6s\tremaining: 8m 46s\n",
      "35:\tlearn: 0.1725117\ttotal: 40.9s\tremaining: 8m 46s\n",
      "36:\tlearn: 0.1677702\ttotal: 41.9s\tremaining: 8m 44s\n",
      "37:\tlearn: 0.1630054\ttotal: 43.1s\tremaining: 8m 43s\n",
      "38:\tlearn: 0.1581662\ttotal: 44.2s\tremaining: 8m 42s\n",
      "39:\tlearn: 0.1534154\ttotal: 45.5s\tremaining: 8m 42s\n",
      "40:\tlearn: 0.1498153\ttotal: 46.7s\tremaining: 8m 42s\n",
      "41:\tlearn: 0.1450754\ttotal: 47.8s\tremaining: 8m 41s\n",
      "42:\tlearn: 0.1407478\ttotal: 48.9s\tremaining: 8m 40s\n",
      "43:\tlearn: 0.1370756\ttotal: 50.1s\tremaining: 8m 39s\n",
      "44:\tlearn: 0.1341978\ttotal: 51.2s\tremaining: 8m 38s\n",
      "45:\tlearn: 0.1301683\ttotal: 52.5s\tremaining: 8m 38s\n",
      "46:\tlearn: 0.1266529\ttotal: 53.6s\tremaining: 8m 36s\n",
      "47:\tlearn: 0.1232060\ttotal: 54.9s\tremaining: 8m 36s\n",
      "48:\tlearn: 0.1204278\ttotal: 56s\tremaining: 8m 35s\n",
      "49:\tlearn: 0.1172970\ttotal: 57.3s\tremaining: 8m 35s\n",
      "50:\tlearn: 0.1141455\ttotal: 58.5s\tremaining: 8m 35s\n",
      "51:\tlearn: 0.1116990\ttotal: 59.5s\tremaining: 8m 32s\n",
      "52:\tlearn: 0.1085003\ttotal: 1m\tremaining: 8m 31s\n",
      "53:\tlearn: 0.1058666\ttotal: 1m 1s\tremaining: 8m 31s\n",
      "54:\tlearn: 0.1034303\ttotal: 1m 2s\tremaining: 8m 29s\n",
      "55:\tlearn: 0.1010556\ttotal: 1m 4s\tremaining: 8m 28s\n",
      "56:\tlearn: 0.0985279\ttotal: 1m 5s\tremaining: 8m 27s\n",
      "57:\tlearn: 0.0960373\ttotal: 1m 6s\tremaining: 8m 25s\n",
      "58:\tlearn: 0.0935937\ttotal: 1m 7s\tremaining: 8m 24s\n",
      "59:\tlearn: 0.0910089\ttotal: 1m 8s\tremaining: 8m 23s\n",
      "60:\tlearn: 0.0888683\ttotal: 1m 9s\tremaining: 8m 21s\n",
      "61:\tlearn: 0.0868778\ttotal: 1m 10s\tremaining: 8m 21s\n",
      "62:\tlearn: 0.0852595\ttotal: 1m 11s\tremaining: 8m 19s\n",
      "63:\tlearn: 0.0829726\ttotal: 1m 13s\tremaining: 8m 18s\n",
      "64:\tlearn: 0.0808917\ttotal: 1m 14s\tremaining: 8m 17s\n",
      "65:\tlearn: 0.0784877\ttotal: 1m 15s\tremaining: 8m 15s\n",
      "66:\tlearn: 0.0767086\ttotal: 1m 16s\tremaining: 8m 15s\n",
      "67:\tlearn: 0.0749607\ttotal: 1m 17s\tremaining: 8m 14s\n",
      "68:\tlearn: 0.0737896\ttotal: 1m 18s\tremaining: 8m 13s\n",
      "69:\tlearn: 0.0723155\ttotal: 1m 20s\tremaining: 8m 12s\n",
      "70:\tlearn: 0.0705462\ttotal: 1m 21s\tremaining: 8m 11s\n",
      "71:\tlearn: 0.0693322\ttotal: 1m 22s\tremaining: 8m 10s\n",
      "72:\tlearn: 0.0679929\ttotal: 1m 23s\tremaining: 8m 9s\n",
      "73:\tlearn: 0.0664974\ttotal: 1m 24s\tremaining: 8m 8s\n",
      "74:\tlearn: 0.0647863\ttotal: 1m 26s\tremaining: 8m 8s\n",
      "75:\tlearn: 0.0635175\ttotal: 1m 27s\tremaining: 8m 6s\n",
      "76:\tlearn: 0.0620074\ttotal: 1m 28s\tremaining: 8m 6s\n",
      "77:\tlearn: 0.0604576\ttotal: 1m 29s\tremaining: 8m 5s\n",
      "78:\tlearn: 0.0591770\ttotal: 1m 30s\tremaining: 8m 4s\n",
      "79:\tlearn: 0.0578386\ttotal: 1m 32s\tremaining: 8m 4s\n",
      "80:\tlearn: 0.0569980\ttotal: 1m 33s\tremaining: 8m 2s\n",
      "81:\tlearn: 0.0558140\ttotal: 1m 34s\tremaining: 8m 1s\n",
      "82:\tlearn: 0.0548722\ttotal: 1m 35s\tremaining: 8m\n",
      "83:\tlearn: 0.0539922\ttotal: 1m 36s\tremaining: 7m 59s\n",
      "84:\tlearn: 0.0527960\ttotal: 1m 37s\tremaining: 7m 58s\n",
      "85:\tlearn: 0.0517744\ttotal: 1m 39s\tremaining: 7m 57s\n",
      "86:\tlearn: 0.0510871\ttotal: 1m 40s\tremaining: 7m 55s\n",
      "87:\tlearn: 0.0504485\ttotal: 1m 41s\tremaining: 7m 55s\n",
      "88:\tlearn: 0.0493326\ttotal: 1m 42s\tremaining: 7m 54s\n",
      "89:\tlearn: 0.0485383\ttotal: 1m 43s\tremaining: 7m 53s\n",
      "90:\tlearn: 0.0474614\ttotal: 1m 45s\tremaining: 7m 52s\n",
      "91:\tlearn: 0.0467472\ttotal: 1m 46s\tremaining: 7m 50s\n",
      "92:\tlearn: 0.0458292\ttotal: 1m 47s\tremaining: 7m 51s\n",
      "93:\tlearn: 0.0449693\ttotal: 1m 48s\tremaining: 7m 50s\n",
      "94:\tlearn: 0.0441494\ttotal: 1m 49s\tremaining: 7m 48s\n",
      "95:\tlearn: 0.0431698\ttotal: 1m 51s\tremaining: 7m 47s\n",
      "96:\tlearn: 0.0423689\ttotal: 1m 52s\tremaining: 7m 46s\n",
      "97:\tlearn: 0.0415602\ttotal: 1m 53s\tremaining: 7m 45s\n",
      "98:\tlearn: 0.0407658\ttotal: 1m 54s\tremaining: 7m 44s\n",
      "99:\tlearn: 0.0398732\ttotal: 1m 55s\tremaining: 7m 43s\n",
      "100:\tlearn: 0.0389669\ttotal: 1m 56s\tremaining: 7m 42s\n",
      "101:\tlearn: 0.0385320\ttotal: 1m 58s\tremaining: 7m 41s\n",
      "102:\tlearn: 0.0378569\ttotal: 1m 59s\tremaining: 7m 39s\n",
      "103:\tlearn: 0.0372210\ttotal: 2m\tremaining: 7m 38s\n",
      "104:\tlearn: 0.0367323\ttotal: 2m 1s\tremaining: 7m 37s\n",
      "105:\tlearn: 0.0360548\ttotal: 2m 2s\tremaining: 7m 36s\n",
      "106:\tlearn: 0.0352751\ttotal: 2m 4s\tremaining: 7m 35s\n",
      "107:\tlearn: 0.0346837\ttotal: 2m 5s\tremaining: 7m 34s\n",
      "108:\tlearn: 0.0340918\ttotal: 2m 6s\tremaining: 7m 33s\n",
      "109:\tlearn: 0.0335658\ttotal: 2m 7s\tremaining: 7m 32s\n",
      "110:\tlearn: 0.0332352\ttotal: 2m 8s\tremaining: 7m 32s\n",
      "111:\tlearn: 0.0327430\ttotal: 2m 10s\tremaining: 7m 30s\n",
      "112:\tlearn: 0.0323964\ttotal: 2m 11s\tremaining: 7m 29s\n",
      "113:\tlearn: 0.0318533\ttotal: 2m 12s\tremaining: 7m 28s\n",
      "114:\tlearn: 0.0312557\ttotal: 2m 13s\tremaining: 7m 27s\n",
      "115:\tlearn: 0.0307419\ttotal: 2m 14s\tremaining: 7m 26s\n",
      "116:\tlearn: 0.0302291\ttotal: 2m 16s\tremaining: 7m 25s\n",
      "117:\tlearn: 0.0298044\ttotal: 2m 17s\tremaining: 7m 23s\n",
      "118:\tlearn: 0.0292411\ttotal: 2m 18s\tremaining: 7m 23s\n",
      "119:\tlearn: 0.0287610\ttotal: 2m 19s\tremaining: 7m 22s\n",
      "120:\tlearn: 0.0283293\ttotal: 2m 20s\tremaining: 7m 20s\n",
      "121:\tlearn: 0.0277637\ttotal: 2m 22s\tremaining: 7m 20s\n",
      "122:\tlearn: 0.0273082\ttotal: 2m 23s\tremaining: 7m 18s\n",
      "123:\tlearn: 0.0270168\ttotal: 2m 24s\tremaining: 7m 18s\n",
      "124:\tlearn: 0.0266391\ttotal: 2m 25s\tremaining: 7m 17s\n",
      "125:\tlearn: 0.0262365\ttotal: 2m 26s\tremaining: 7m 16s\n",
      "126:\tlearn: 0.0258830\ttotal: 2m 28s\tremaining: 7m 14s\n",
      "127:\tlearn: 0.0254853\ttotal: 2m 29s\tremaining: 7m 13s\n",
      "128:\tlearn: 0.0250516\ttotal: 2m 30s\tremaining: 7m 12s\n",
      "129:\tlearn: 0.0247108\ttotal: 2m 31s\tremaining: 7m 11s\n",
      "130:\tlearn: 0.0243888\ttotal: 2m 32s\tremaining: 7m 10s\n",
      "131:\tlearn: 0.0240410\ttotal: 2m 34s\tremaining: 7m 9s\n",
      "132:\tlearn: 0.0237822\ttotal: 2m 35s\tremaining: 7m 8s\n",
      "133:\tlearn: 0.0234555\ttotal: 2m 36s\tremaining: 7m 7s\n",
      "134:\tlearn: 0.0231086\ttotal: 2m 37s\tremaining: 7m 6s\n",
      "135:\tlearn: 0.0227237\ttotal: 2m 38s\tremaining: 7m 5s\n",
      "136:\tlearn: 0.0224653\ttotal: 2m 40s\tremaining: 7m 4s\n",
      "137:\tlearn: 0.0221633\ttotal: 2m 41s\tremaining: 7m 3s\n",
      "138:\tlearn: 0.0218199\ttotal: 2m 42s\tremaining: 7m 1s\n",
      "139:\tlearn: 0.0214207\ttotal: 2m 43s\tremaining: 7m\n",
      "140:\tlearn: 0.0210664\ttotal: 2m 44s\tremaining: 6m 59s\n",
      "141:\tlearn: 0.0208900\ttotal: 2m 46s\tremaining: 6m 58s\n",
      "142:\tlearn: 0.0205437\ttotal: 2m 47s\tremaining: 6m 57s\n",
      "143:\tlearn: 0.0202838\ttotal: 2m 48s\tremaining: 6m 56s\n",
      "144:\tlearn: 0.0199857\ttotal: 2m 49s\tremaining: 6m 55s\n",
      "145:\tlearn: 0.0195975\ttotal: 2m 50s\tremaining: 6m 54s\n",
      "146:\tlearn: 0.0193866\ttotal: 2m 52s\tremaining: 6m 53s\n",
      "147:\tlearn: 0.0191198\ttotal: 2m 53s\tremaining: 6m 52s\n",
      "148:\tlearn: 0.0188900\ttotal: 2m 54s\tremaining: 6m 50s\n",
      "149:\tlearn: 0.0185917\ttotal: 2m 55s\tremaining: 6m 49s\n",
      "150:\tlearn: 0.0184190\ttotal: 2m 56s\tremaining: 6m 48s\n",
      "151:\tlearn: 0.0181770\ttotal: 2m 58s\tremaining: 6m 47s\n",
      "152:\tlearn: 0.0179721\ttotal: 2m 59s\tremaining: 6m 46s\n",
      "153:\tlearn: 0.0177038\ttotal: 3m\tremaining: 6m 45s\n",
      "154:\tlearn: 0.0174163\ttotal: 3m 1s\tremaining: 6m 44s\n",
      "155:\tlearn: 0.0170585\ttotal: 3m 2s\tremaining: 6m 43s\n",
      "156:\tlearn: 0.0167944\ttotal: 3m 4s\tremaining: 6m 42s\n",
      "157:\tlearn: 0.0166660\ttotal: 3m 5s\tremaining: 6m 41s\n",
      "158:\tlearn: 0.0165079\ttotal: 3m 6s\tremaining: 6m 40s\n",
      "159:\tlearn: 0.0163674\ttotal: 3m 7s\tremaining: 6m 39s\n",
      "160:\tlearn: 0.0161733\ttotal: 3m 8s\tremaining: 6m 37s\n",
      "161:\tlearn: 0.0159472\ttotal: 3m 10s\tremaining: 6m 36s\n",
      "162:\tlearn: 0.0157040\ttotal: 3m 11s\tremaining: 6m 35s\n",
      "163:\tlearn: 0.0155404\ttotal: 3m 12s\tremaining: 6m 34s\n",
      "164:\tlearn: 0.0153053\ttotal: 3m 13s\tremaining: 6m 33s\n",
      "165:\tlearn: 0.0151524\ttotal: 3m 15s\tremaining: 6m 32s\n",
      "166:\tlearn: 0.0148990\ttotal: 3m 16s\tremaining: 6m 31s\n",
      "167:\tlearn: 0.0147045\ttotal: 3m 17s\tremaining: 6m 30s\n",
      "168:\tlearn: 0.0145098\ttotal: 3m 18s\tremaining: 6m 29s\n",
      "169:\tlearn: 0.0143377\ttotal: 3m 19s\tremaining: 6m 28s\n",
      "170:\tlearn: 0.0141868\ttotal: 3m 21s\tremaining: 6m 26s\n",
      "171:\tlearn: 0.0139955\ttotal: 3m 22s\tremaining: 6m 25s\n",
      "172:\tlearn: 0.0138181\ttotal: 3m 23s\tremaining: 6m 24s\n",
      "173:\tlearn: 0.0136484\ttotal: 3m 24s\tremaining: 6m 23s\n",
      "174:\tlearn: 0.0135091\ttotal: 3m 25s\tremaining: 6m 22s\n",
      "175:\tlearn: 0.0133590\ttotal: 3m 27s\tremaining: 6m 21s\n",
      "176:\tlearn: 0.0131704\ttotal: 3m 28s\tremaining: 6m 20s\n",
      "177:\tlearn: 0.0130051\ttotal: 3m 29s\tremaining: 6m 18s\n",
      "178:\tlearn: 0.0128152\ttotal: 3m 30s\tremaining: 6m 17s\n",
      "179:\tlearn: 0.0126725\ttotal: 3m 31s\tremaining: 6m 16s\n",
      "180:\tlearn: 0.0125615\ttotal: 3m 33s\tremaining: 6m 15s\n",
      "181:\tlearn: 0.0124169\ttotal: 3m 34s\tremaining: 6m 14s\n",
      "182:\tlearn: 0.0122745\ttotal: 3m 35s\tremaining: 6m 14s\n",
      "183:\tlearn: 0.0121122\ttotal: 3m 37s\tremaining: 6m 12s\n",
      "184:\tlearn: 0.0119676\ttotal: 3m 38s\tremaining: 6m 11s\n",
      "185:\tlearn: 0.0118639\ttotal: 3m 39s\tremaining: 6m 10s\n",
      "186:\tlearn: 0.0117603\ttotal: 3m 40s\tremaining: 6m 9s\n",
      "187:\tlearn: 0.0115672\ttotal: 3m 42s\tremaining: 6m 8s\n",
      "188:\tlearn: 0.0113741\ttotal: 3m 43s\tremaining: 6m 7s\n",
      "189:\tlearn: 0.0112550\ttotal: 3m 44s\tremaining: 6m 6s\n",
      "190:\tlearn: 0.0111300\ttotal: 3m 45s\tremaining: 6m 4s\n",
      "191:\tlearn: 0.0109520\ttotal: 3m 46s\tremaining: 6m 3s\n",
      "192:\tlearn: 0.0107962\ttotal: 3m 47s\tremaining: 6m 2s\n",
      "193:\tlearn: 0.0106922\ttotal: 3m 48s\tremaining: 6m 1s\n",
      "194:\tlearn: 0.0105921\ttotal: 3m 50s\tremaining: 5m 59s\n",
      "195:\tlearn: 0.0104490\ttotal: 3m 51s\tremaining: 5m 58s\n",
      "196:\tlearn: 0.0103810\ttotal: 3m 52s\tremaining: 5m 57s\n",
      "197:\tlearn: 0.0102609\ttotal: 3m 53s\tremaining: 5m 56s\n",
      "198:\tlearn: 0.0101068\ttotal: 3m 54s\tremaining: 5m 55s\n",
      "199:\tlearn: 0.0099869\ttotal: 3m 56s\tremaining: 5m 54s\n",
      "200:\tlearn: 0.0098883\ttotal: 3m 57s\tremaining: 5m 53s\n",
      "201:\tlearn: 0.0097721\ttotal: 3m 58s\tremaining: 5m 52s\n",
      "202:\tlearn: 0.0097040\ttotal: 3m 59s\tremaining: 5m 51s\n",
      "203:\tlearn: 0.0095695\ttotal: 4m 1s\tremaining: 5m 49s\n",
      "204:\tlearn: 0.0094820\ttotal: 4m 2s\tremaining: 5m 48s\n",
      "205:\tlearn: 0.0093251\ttotal: 4m 3s\tremaining: 5m 47s\n",
      "206:\tlearn: 0.0092078\ttotal: 4m 4s\tremaining: 5m 46s\n",
      "207:\tlearn: 0.0091534\ttotal: 4m 6s\tremaining: 5m 45s\n",
      "208:\tlearn: 0.0090307\ttotal: 4m 7s\tremaining: 5m 44s\n",
      "209:\tlearn: 0.0089493\ttotal: 4m 8s\tremaining: 5m 43s\n",
      "210:\tlearn: 0.0088515\ttotal: 4m 9s\tremaining: 5m 42s\n",
      "211:\tlearn: 0.0087421\ttotal: 4m 10s\tremaining: 5m 40s\n",
      "212:\tlearn: 0.0086216\ttotal: 4m 12s\tremaining: 5m 39s\n",
      "213:\tlearn: 0.0085192\ttotal: 4m 13s\tremaining: 5m 38s\n",
      "214:\tlearn: 0.0084581\ttotal: 4m 14s\tremaining: 5m 37s\n",
      "215:\tlearn: 0.0083729\ttotal: 4m 15s\tremaining: 5m 36s\n",
      "216:\tlearn: 0.0082797\ttotal: 4m 16s\tremaining: 5m 35s\n",
      "217:\tlearn: 0.0081859\ttotal: 4m 18s\tremaining: 5m 33s\n",
      "218:\tlearn: 0.0080778\ttotal: 4m 19s\tremaining: 5m 32s\n",
      "219:\tlearn: 0.0080092\ttotal: 4m 20s\tremaining: 5m 31s\n",
      "220:\tlearn: 0.0079245\ttotal: 4m 21s\tremaining: 5m 30s\n",
      "221:\tlearn: 0.0078069\ttotal: 4m 22s\tremaining: 5m 29s\n",
      "222:\tlearn: 0.0076661\ttotal: 4m 24s\tremaining: 5m 28s\n",
      "223:\tlearn: 0.0076023\ttotal: 4m 25s\tremaining: 5m 26s\n",
      "224:\tlearn: 0.0075063\ttotal: 4m 26s\tremaining: 5m 25s\n",
      "225:\tlearn: 0.0074228\ttotal: 4m 27s\tremaining: 5m 24s\n",
      "226:\tlearn: 0.0073366\ttotal: 4m 28s\tremaining: 5m 23s\n",
      "227:\tlearn: 0.0072747\ttotal: 4m 30s\tremaining: 5m 22s\n",
      "228:\tlearn: 0.0071897\ttotal: 4m 31s\tremaining: 5m 21s\n",
      "229:\tlearn: 0.0071499\ttotal: 4m 32s\tremaining: 5m 19s\n",
      "230:\tlearn: 0.0070674\ttotal: 4m 33s\tremaining: 5m 18s\n",
      "231:\tlearn: 0.0070071\ttotal: 4m 35s\tremaining: 5m 17s\n",
      "232:\tlearn: 0.0069294\ttotal: 4m 36s\tremaining: 5m 16s\n",
      "233:\tlearn: 0.0068815\ttotal: 4m 37s\tremaining: 5m 15s\n",
      "234:\tlearn: 0.0068266\ttotal: 4m 38s\tremaining: 5m 14s\n",
      "235:\tlearn: 0.0067764\ttotal: 4m 40s\tremaining: 5m 13s\n",
      "236:\tlearn: 0.0067205\ttotal: 4m 41s\tremaining: 5m 12s\n",
      "237:\tlearn: 0.0066844\ttotal: 4m 42s\tremaining: 5m 11s\n",
      "238:\tlearn: 0.0065985\ttotal: 4m 43s\tremaining: 5m 9s\n",
      "239:\tlearn: 0.0065379\ttotal: 4m 44s\tremaining: 5m 8s\n",
      "240:\tlearn: 0.0064590\ttotal: 4m 46s\tremaining: 5m 7s\n",
      "241:\tlearn: 0.0064043\ttotal: 4m 47s\tremaining: 5m 6s\n",
      "242:\tlearn: 0.0063823\ttotal: 4m 48s\tremaining: 5m 5s\n",
      "243:\tlearn: 0.0062857\ttotal: 4m 50s\tremaining: 5m 4s\n",
      "244:\tlearn: 0.0062440\ttotal: 4m 51s\tremaining: 5m 3s\n",
      "245:\tlearn: 0.0061910\ttotal: 4m 52s\tremaining: 5m 1s\n",
      "246:\tlearn: 0.0061183\ttotal: 4m 53s\tremaining: 5m\n",
      "247:\tlearn: 0.0060808\ttotal: 4m 54s\tremaining: 4m 59s\n",
      "248:\tlearn: 0.0060088\ttotal: 4m 56s\tremaining: 4m 58s\n",
      "249:\tlearn: 0.0059626\ttotal: 4m 57s\tremaining: 4m 57s\n",
      "250:\tlearn: 0.0059026\ttotal: 4m 58s\tremaining: 4m 56s\n",
      "251:\tlearn: 0.0058601\ttotal: 4m 59s\tremaining: 4m 54s\n",
      "252:\tlearn: 0.0058179\ttotal: 5m\tremaining: 4m 53s\n",
      "253:\tlearn: 0.0057515\ttotal: 5m 2s\tremaining: 4m 52s\n",
      "254:\tlearn: 0.0057129\ttotal: 5m 3s\tremaining: 4m 51s\n",
      "255:\tlearn: 0.0056640\ttotal: 5m 4s\tremaining: 4m 50s\n",
      "256:\tlearn: 0.0055924\ttotal: 5m 6s\tremaining: 4m 49s\n",
      "257:\tlearn: 0.0055169\ttotal: 5m 7s\tremaining: 4m 48s\n",
      "258:\tlearn: 0.0054573\ttotal: 5m 8s\tremaining: 4m 46s\n",
      "259:\tlearn: 0.0053841\ttotal: 5m 9s\tremaining: 4m 45s\n",
      "260:\tlearn: 0.0053235\ttotal: 5m 10s\tremaining: 4m 44s\n",
      "261:\tlearn: 0.0052933\ttotal: 5m 12s\tremaining: 4m 43s\n",
      "262:\tlearn: 0.0052623\ttotal: 5m 13s\tremaining: 4m 42s\n",
      "263:\tlearn: 0.0052281\ttotal: 5m 14s\tremaining: 4m 41s\n",
      "264:\tlearn: 0.0051994\ttotal: 5m 15s\tremaining: 4m 39s\n",
      "265:\tlearn: 0.0051565\ttotal: 5m 16s\tremaining: 4m 38s\n",
      "266:\tlearn: 0.0051100\ttotal: 5m 18s\tremaining: 4m 37s\n",
      "267:\tlearn: 0.0050674\ttotal: 5m 19s\tremaining: 4m 36s\n",
      "268:\tlearn: 0.0050318\ttotal: 5m 20s\tremaining: 4m 35s\n",
      "269:\tlearn: 0.0049547\ttotal: 5m 21s\tremaining: 4m 34s\n",
      "270:\tlearn: 0.0048963\ttotal: 5m 22s\tremaining: 4m 32s\n",
      "271:\tlearn: 0.0048413\ttotal: 5m 24s\tremaining: 4m 31s\n",
      "272:\tlearn: 0.0048147\ttotal: 5m 25s\tremaining: 4m 30s\n",
      "273:\tlearn: 0.0047625\ttotal: 5m 26s\tremaining: 4m 29s\n",
      "274:\tlearn: 0.0047191\ttotal: 5m 27s\tremaining: 4m 28s\n",
      "275:\tlearn: 0.0046960\ttotal: 5m 28s\tremaining: 4m 26s\n",
      "276:\tlearn: 0.0046480\ttotal: 5m 30s\tremaining: 4m 25s\n",
      "277:\tlearn: 0.0046058\ttotal: 5m 31s\tremaining: 4m 24s\n",
      "278:\tlearn: 0.0045616\ttotal: 5m 32s\tremaining: 4m 23s\n",
      "279:\tlearn: 0.0044921\ttotal: 5m 33s\tremaining: 4m 22s\n",
      "280:\tlearn: 0.0044557\ttotal: 5m 34s\tremaining: 4m 20s\n",
      "281:\tlearn: 0.0044311\ttotal: 5m 36s\tremaining: 4m 19s\n",
      "282:\tlearn: 0.0044045\ttotal: 5m 37s\tremaining: 4m 18s\n",
      "283:\tlearn: 0.0043726\ttotal: 5m 38s\tremaining: 4m 17s\n",
      "284:\tlearn: 0.0043423\ttotal: 5m 39s\tremaining: 4m 16s\n",
      "285:\tlearn: 0.0043044\ttotal: 5m 41s\tremaining: 4m 15s\n",
      "286:\tlearn: 0.0042492\ttotal: 5m 42s\tremaining: 4m 14s\n",
      "287:\tlearn: 0.0041912\ttotal: 5m 43s\tremaining: 4m 12s\n",
      "288:\tlearn: 0.0041621\ttotal: 5m 44s\tremaining: 4m 11s\n",
      "289:\tlearn: 0.0041156\ttotal: 5m 45s\tremaining: 4m 10s\n",
      "290:\tlearn: 0.0040726\ttotal: 5m 47s\tremaining: 4m 9s\n",
      "291:\tlearn: 0.0040298\ttotal: 5m 48s\tremaining: 4m 8s\n",
      "292:\tlearn: 0.0039746\ttotal: 5m 49s\tremaining: 4m 6s\n",
      "293:\tlearn: 0.0039503\ttotal: 5m 50s\tremaining: 4m 5s\n",
      "294:\tlearn: 0.0039094\ttotal: 5m 51s\tremaining: 4m 4s\n",
      "295:\tlearn: 0.0038796\ttotal: 5m 53s\tremaining: 4m 3s\n",
      "296:\tlearn: 0.0038588\ttotal: 5m 54s\tremaining: 4m 2s\n",
      "297:\tlearn: 0.0038409\ttotal: 5m 55s\tremaining: 4m 1s\n",
      "298:\tlearn: 0.0038198\ttotal: 5m 56s\tremaining: 3m 59s\n",
      "299:\tlearn: 0.0037744\ttotal: 5m 58s\tremaining: 3m 58s\n",
      "300:\tlearn: 0.0037607\ttotal: 5m 59s\tremaining: 3m 57s\n",
      "301:\tlearn: 0.0037338\ttotal: 6m\tremaining: 3m 56s\n",
      "302:\tlearn: 0.0036975\ttotal: 6m 1s\tremaining: 3m 55s\n",
      "303:\tlearn: 0.0036843\ttotal: 6m 2s\tremaining: 3m 53s\n",
      "304:\tlearn: 0.0036574\ttotal: 6m 4s\tremaining: 3m 52s\n",
      "305:\tlearn: 0.0036398\ttotal: 6m 5s\tremaining: 3m 51s\n",
      "306:\tlearn: 0.0035976\ttotal: 6m 6s\tremaining: 3m 50s\n",
      "307:\tlearn: 0.0035804\ttotal: 6m 7s\tremaining: 3m 49s\n",
      "308:\tlearn: 0.0035669\ttotal: 6m 8s\tremaining: 3m 48s\n",
      "309:\tlearn: 0.0035442\ttotal: 6m 10s\tremaining: 3m 46s\n",
      "310:\tlearn: 0.0035048\ttotal: 6m 11s\tremaining: 3m 45s\n",
      "311:\tlearn: 0.0034470\ttotal: 6m 12s\tremaining: 3m 44s\n",
      "312:\tlearn: 0.0034266\ttotal: 6m 13s\tremaining: 3m 43s\n",
      "313:\tlearn: 0.0034043\ttotal: 6m 15s\tremaining: 3m 42s\n",
      "314:\tlearn: 0.0033729\ttotal: 6m 16s\tremaining: 3m 40s\n",
      "315:\tlearn: 0.0033433\ttotal: 6m 17s\tremaining: 3m 39s\n",
      "316:\tlearn: 0.0033233\ttotal: 6m 18s\tremaining: 3m 38s\n",
      "317:\tlearn: 0.0033137\ttotal: 6m 20s\tremaining: 3m 37s\n",
      "318:\tlearn: 0.0032866\ttotal: 6m 21s\tremaining: 3m 36s\n",
      "319:\tlearn: 0.0032667\ttotal: 6m 22s\tremaining: 3m 35s\n",
      "320:\tlearn: 0.0032442\ttotal: 6m 23s\tremaining: 3m 33s\n",
      "321:\tlearn: 0.0032078\ttotal: 6m 24s\tremaining: 3m 32s\n",
      "322:\tlearn: 0.0031883\ttotal: 6m 26s\tremaining: 3m 31s\n",
      "323:\tlearn: 0.0031722\ttotal: 6m 27s\tremaining: 3m 30s\n",
      "324:\tlearn: 0.0031583\ttotal: 6m 28s\tremaining: 3m 29s\n",
      "325:\tlearn: 0.0031451\ttotal: 6m 29s\tremaining: 3m 28s\n",
      "326:\tlearn: 0.0031183\ttotal: 6m 30s\tremaining: 3m 26s\n",
      "327:\tlearn: 0.0031063\ttotal: 6m 32s\tremaining: 3m 25s\n",
      "328:\tlearn: 0.0030803\ttotal: 6m 33s\tremaining: 3m 24s\n",
      "329:\tlearn: 0.0030496\ttotal: 6m 34s\tremaining: 3m 23s\n",
      "330:\tlearn: 0.0030391\ttotal: 6m 35s\tremaining: 3m 22s\n",
      "331:\tlearn: 0.0030034\ttotal: 6m 36s\tremaining: 3m 20s\n",
      "332:\tlearn: 0.0029880\ttotal: 6m 38s\tremaining: 3m 19s\n",
      "333:\tlearn: 0.0029601\ttotal: 6m 39s\tremaining: 3m 18s\n",
      "334:\tlearn: 0.0029407\ttotal: 6m 40s\tremaining: 3m 17s\n",
      "335:\tlearn: 0.0029264\ttotal: 6m 41s\tremaining: 3m 16s\n",
      "336:\tlearn: 0.0029107\ttotal: 6m 43s\tremaining: 3m 14s\n",
      "337:\tlearn: 0.0028947\ttotal: 6m 44s\tremaining: 3m 13s\n",
      "338:\tlearn: 0.0028836\ttotal: 6m 45s\tremaining: 3m 12s\n",
      "339:\tlearn: 0.0028562\ttotal: 6m 46s\tremaining: 3m 11s\n",
      "340:\tlearn: 0.0028350\ttotal: 6m 47s\tremaining: 3m 10s\n",
      "341:\tlearn: 0.0028021\ttotal: 6m 49s\tremaining: 3m 8s\n",
      "342:\tlearn: 0.0027827\ttotal: 6m 50s\tremaining: 3m 7s\n",
      "343:\tlearn: 0.0027584\ttotal: 6m 51s\tremaining: 3m 6s\n",
      "344:\tlearn: 0.0027319\ttotal: 6m 52s\tremaining: 3m 5s\n",
      "345:\tlearn: 0.0027155\ttotal: 6m 53s\tremaining: 3m 4s\n",
      "346:\tlearn: 0.0026983\ttotal: 6m 54s\tremaining: 3m 2s\n",
      "347:\tlearn: 0.0026758\ttotal: 6m 55s\tremaining: 3m 1s\n",
      "348:\tlearn: 0.0026653\ttotal: 6m 57s\tremaining: 3m\n",
      "349:\tlearn: 0.0026387\ttotal: 6m 58s\tremaining: 2m 59s\n",
      "350:\tlearn: 0.0026241\ttotal: 6m 59s\tremaining: 2m 58s\n",
      "351:\tlearn: 0.0026043\ttotal: 7m\tremaining: 2m 56s\n",
      "352:\tlearn: 0.0025778\ttotal: 7m 1s\tremaining: 2m 55s\n",
      "353:\tlearn: 0.0025610\ttotal: 7m 3s\tremaining: 2m 54s\n",
      "354:\tlearn: 0.0025543\ttotal: 7m 4s\tremaining: 2m 53s\n",
      "355:\tlearn: 0.0025301\ttotal: 7m 5s\tremaining: 2m 52s\n",
      "356:\tlearn: 0.0025229\ttotal: 7m 6s\tremaining: 2m 51s\n",
      "357:\tlearn: 0.0025127\ttotal: 7m 8s\tremaining: 2m 49s\n",
      "358:\tlearn: 0.0025071\ttotal: 7m 9s\tremaining: 2m 48s\n",
      "359:\tlearn: 0.0024904\ttotal: 7m 10s\tremaining: 2m 47s\n",
      "360:\tlearn: 0.0024754\ttotal: 7m 11s\tremaining: 2m 46s\n",
      "361:\tlearn: 0.0024566\ttotal: 7m 12s\tremaining: 2m 44s\n",
      "362:\tlearn: 0.0024480\ttotal: 7m 14s\tremaining: 2m 43s\n",
      "363:\tlearn: 0.0024351\ttotal: 7m 15s\tremaining: 2m 42s\n",
      "364:\tlearn: 0.0024303\ttotal: 7m 16s\tremaining: 2m 41s\n",
      "365:\tlearn: 0.0024228\ttotal: 7m 17s\tremaining: 2m 40s\n",
      "366:\tlearn: 0.0024149\ttotal: 7m 18s\tremaining: 2m 39s\n",
      "367:\tlearn: 0.0024047\ttotal: 7m 20s\tremaining: 2m 37s\n",
      "368:\tlearn: 0.0024005\ttotal: 7m 21s\tremaining: 2m 36s\n",
      "369:\tlearn: 0.0023926\ttotal: 7m 22s\tremaining: 2m 35s\n",
      "370:\tlearn: 0.0023724\ttotal: 7m 22s\tremaining: 2m 34s\n",
      "371:\tlearn: 0.0023666\ttotal: 7m 23s\tremaining: 2m 32s\n",
      "372:\tlearn: 0.0023484\ttotal: 7m 24s\tremaining: 2m 31s\n",
      "373:\tlearn: 0.0023434\ttotal: 7m 25s\tremaining: 2m 30s\n",
      "374:\tlearn: 0.0023258\ttotal: 7m 26s\tremaining: 2m 28s\n",
      "375:\tlearn: 0.0023177\ttotal: 7m 27s\tremaining: 2m 27s\n",
      "376:\tlearn: 0.0023106\ttotal: 7m 28s\tremaining: 2m 26s\n",
      "377:\tlearn: 0.0023022\ttotal: 7m 29s\tremaining: 2m 24s\n",
      "378:\tlearn: 0.0022901\ttotal: 7m 29s\tremaining: 2m 23s\n",
      "379:\tlearn: 0.0022705\ttotal: 7m 30s\tremaining: 2m 22s\n",
      "380:\tlearn: 0.0022629\ttotal: 7m 31s\tremaining: 2m 21s\n",
      "381:\tlearn: 0.0022585\ttotal: 7m 32s\tremaining: 2m 19s\n",
      "382:\tlearn: 0.0022525\ttotal: 7m 33s\tremaining: 2m 18s\n",
      "383:\tlearn: 0.0022447\ttotal: 7m 34s\tremaining: 2m 17s\n",
      "384:\tlearn: 0.0022315\ttotal: 7m 35s\tremaining: 2m 15s\n",
      "385:\tlearn: 0.0022257\ttotal: 7m 35s\tremaining: 2m 14s\n",
      "386:\tlearn: 0.0022091\ttotal: 7m 36s\tremaining: 2m 13s\n",
      "387:\tlearn: 0.0021953\ttotal: 7m 37s\tremaining: 2m 12s\n",
      "388:\tlearn: 0.0021798\ttotal: 7m 38s\tremaining: 2m 10s\n",
      "389:\tlearn: 0.0021728\ttotal: 7m 39s\tremaining: 2m 9s\n",
      "390:\tlearn: 0.0021536\ttotal: 7m 40s\tremaining: 2m 8s\n",
      "391:\tlearn: 0.0021330\ttotal: 7m 40s\tremaining: 2m 6s\n",
      "392:\tlearn: 0.0021264\ttotal: 7m 41s\tremaining: 2m 5s\n",
      "393:\tlearn: 0.0021050\ttotal: 7m 42s\tremaining: 2m 4s\n",
      "394:\tlearn: 0.0020975\ttotal: 7m 43s\tremaining: 2m 3s\n",
      "395:\tlearn: 0.0020845\ttotal: 7m 44s\tremaining: 2m 1s\n",
      "396:\tlearn: 0.0020770\ttotal: 7m 44s\tremaining: 2m\n",
      "397:\tlearn: 0.0020582\ttotal: 7m 45s\tremaining: 1m 59s\n",
      "398:\tlearn: 0.0020494\ttotal: 7m 46s\tremaining: 1m 58s\n",
      "399:\tlearn: 0.0020383\ttotal: 7m 47s\tremaining: 1m 56s\n",
      "400:\tlearn: 0.0020305\ttotal: 7m 48s\tremaining: 1m 55s\n",
      "401:\tlearn: 0.0020245\ttotal: 7m 49s\tremaining: 1m 54s\n",
      "402:\tlearn: 0.0020124\ttotal: 7m 50s\tremaining: 1m 53s\n",
      "403:\tlearn: 0.0020042\ttotal: 7m 50s\tremaining: 1m 51s\n",
      "404:\tlearn: 0.0020009\ttotal: 7m 51s\tremaining: 1m 50s\n",
      "405:\tlearn: 0.0019844\ttotal: 7m 52s\tremaining: 1m 49s\n",
      "406:\tlearn: 0.0019764\ttotal: 7m 53s\tremaining: 1m 48s\n",
      "407:\tlearn: 0.0019666\ttotal: 7m 54s\tremaining: 1m 46s\n",
      "408:\tlearn: 0.0019621\ttotal: 7m 55s\tremaining: 1m 45s\n",
      "409:\tlearn: 0.0019486\ttotal: 7m 55s\tremaining: 1m 44s\n",
      "410:\tlearn: 0.0019396\ttotal: 7m 56s\tremaining: 1m 43s\n",
      "411:\tlearn: 0.0019285\ttotal: 7m 57s\tremaining: 1m 42s\n",
      "412:\tlearn: 0.0019191\ttotal: 7m 58s\tremaining: 1m 40s\n",
      "413:\tlearn: 0.0019134\ttotal: 7m 59s\tremaining: 1m 39s\n",
      "414:\tlearn: 0.0019067\ttotal: 8m\tremaining: 1m 38s\n",
      "415:\tlearn: 0.0019024\ttotal: 8m 1s\tremaining: 1m 37s\n",
      "416:\tlearn: 0.0018912\ttotal: 8m 2s\tremaining: 1m 36s\n",
      "417:\tlearn: 0.0018813\ttotal: 8m 3s\tremaining: 1m 34s\n",
      "418:\tlearn: 0.0018750\ttotal: 8m 4s\tremaining: 1m 33s\n",
      "419:\tlearn: 0.0018673\ttotal: 8m 5s\tremaining: 1m 32s\n",
      "420:\tlearn: 0.0018630\ttotal: 8m 6s\tremaining: 1m 31s\n",
      "421:\tlearn: 0.0018547\ttotal: 8m 8s\tremaining: 1m 30s\n",
      "422:\tlearn: 0.0018401\ttotal: 8m 9s\tremaining: 1m 29s\n",
      "423:\tlearn: 0.0018254\ttotal: 8m 10s\tremaining: 1m 27s\n",
      "424:\tlearn: 0.0018171\ttotal: 8m 11s\tremaining: 1m 26s\n",
      "425:\tlearn: 0.0018063\ttotal: 8m 13s\tremaining: 1m 25s\n",
      "426:\tlearn: 0.0017976\ttotal: 8m 14s\tremaining: 1m 24s\n",
      "427:\tlearn: 0.0017932\ttotal: 8m 15s\tremaining: 1m 23s\n",
      "428:\tlearn: 0.0017848\ttotal: 8m 16s\tremaining: 1m 22s\n",
      "429:\tlearn: 0.0017759\ttotal: 8m 17s\tremaining: 1m 21s\n",
      "430:\tlearn: 0.0017672\ttotal: 8m 18s\tremaining: 1m 19s\n",
      "431:\tlearn: 0.0017595\ttotal: 8m 20s\tremaining: 1m 18s\n",
      "432:\tlearn: 0.0017560\ttotal: 8m 21s\tremaining: 1m 17s\n",
      "433:\tlearn: 0.0017436\ttotal: 8m 22s\tremaining: 1m 16s\n",
      "434:\tlearn: 0.0017370\ttotal: 8m 23s\tremaining: 1m 15s\n",
      "435:\tlearn: 0.0017284\ttotal: 8m 24s\tremaining: 1m 14s\n",
      "436:\tlearn: 0.0017261\ttotal: 8m 26s\tremaining: 1m 12s\n",
      "437:\tlearn: 0.0017223\ttotal: 8m 27s\tremaining: 1m 11s\n",
      "438:\tlearn: 0.0017187\ttotal: 8m 28s\tremaining: 1m 10s\n",
      "439:\tlearn: 0.0017134\ttotal: 8m 29s\tremaining: 1m 9s\n",
      "440:\tlearn: 0.0017106\ttotal: 8m 31s\tremaining: 1m 8s\n",
      "441:\tlearn: 0.0017023\ttotal: 8m 32s\tremaining: 1m 7s\n",
      "442:\tlearn: 0.0016965\ttotal: 8m 33s\tremaining: 1m 6s\n",
      "443:\tlearn: 0.0016924\ttotal: 8m 34s\tremaining: 1m 4s\n",
      "444:\tlearn: 0.0016865\ttotal: 8m 35s\tremaining: 1m 3s\n",
      "445:\tlearn: 0.0016781\ttotal: 8m 37s\tremaining: 1m 2s\n",
      "446:\tlearn: 0.0016675\ttotal: 8m 38s\tremaining: 1m 1s\n",
      "447:\tlearn: 0.0016576\ttotal: 8m 39s\tremaining: 1m\n",
      "448:\tlearn: 0.0016555\ttotal: 8m 40s\tremaining: 59.1s\n",
      "449:\tlearn: 0.0016520\ttotal: 8m 41s\tremaining: 58s\n",
      "450:\tlearn: 0.0016453\ttotal: 8m 43s\tremaining: 56.8s\n",
      "451:\tlearn: 0.0016377\ttotal: 8m 44s\tremaining: 55.7s\n",
      "452:\tlearn: 0.0016288\ttotal: 8m 45s\tremaining: 54.5s\n",
      "453:\tlearn: 0.0016245\ttotal: 8m 46s\tremaining: 53.4s\n",
      "454:\tlearn: 0.0016228\ttotal: 8m 47s\tremaining: 52.2s\n",
      "455:\tlearn: 0.0016139\ttotal: 8m 49s\tremaining: 51.1s\n",
      "456:\tlearn: 0.0016109\ttotal: 8m 50s\tremaining: 49.9s\n",
      "457:\tlearn: 0.0016043\ttotal: 8m 51s\tremaining: 48.7s\n",
      "458:\tlearn: 0.0015945\ttotal: 8m 52s\tremaining: 47.6s\n",
      "459:\tlearn: 0.0015876\ttotal: 8m 53s\tremaining: 46.4s\n",
      "460:\tlearn: 0.0015862\ttotal: 8m 55s\tremaining: 45.3s\n",
      "461:\tlearn: 0.0015839\ttotal: 8m 56s\tremaining: 44.1s\n",
      "462:\tlearn: 0.0015793\ttotal: 8m 57s\tremaining: 42.9s\n",
      "463:\tlearn: 0.0015765\ttotal: 8m 58s\tremaining: 41.8s\n",
      "464:\tlearn: 0.0015678\ttotal: 8m 59s\tremaining: 40.6s\n",
      "465:\tlearn: 0.0015651\ttotal: 9m\tremaining: 39.5s\n",
      "466:\tlearn: 0.0015529\ttotal: 9m 2s\tremaining: 38.3s\n",
      "467:\tlearn: 0.0015513\ttotal: 9m 3s\tremaining: 37.1s\n",
      "468:\tlearn: 0.0015489\ttotal: 9m 4s\tremaining: 36s\n",
      "469:\tlearn: 0.0015425\ttotal: 9m 5s\tremaining: 34.8s\n",
      "470:\tlearn: 0.0015399\ttotal: 9m 6s\tremaining: 33.7s\n",
      "471:\tlearn: 0.0015365\ttotal: 9m 8s\tremaining: 32.5s\n",
      "472:\tlearn: 0.0015293\ttotal: 9m 9s\tremaining: 31.4s\n",
      "473:\tlearn: 0.0015255\ttotal: 9m 10s\tremaining: 30.2s\n",
      "474:\tlearn: 0.0015207\ttotal: 9m 11s\tremaining: 29s\n",
      "475:\tlearn: 0.0015183\ttotal: 9m 12s\tremaining: 27.9s\n",
      "476:\tlearn: 0.0015117\ttotal: 9m 14s\tremaining: 26.7s\n",
      "477:\tlearn: 0.0015083\ttotal: 9m 15s\tremaining: 25.6s\n",
      "478:\tlearn: 0.0015043\ttotal: 9m 16s\tremaining: 24.4s\n",
      "479:\tlearn: 0.0014974\ttotal: 9m 17s\tremaining: 23.2s\n",
      "480:\tlearn: 0.0014923\ttotal: 9m 18s\tremaining: 22.1s\n",
      "481:\tlearn: 0.0014902\ttotal: 9m 20s\tremaining: 20.9s\n",
      "482:\tlearn: 0.0014823\ttotal: 9m 21s\tremaining: 19.8s\n",
      "483:\tlearn: 0.0014787\ttotal: 9m 22s\tremaining: 18.6s\n",
      "484:\tlearn: 0.0014760\ttotal: 9m 23s\tremaining: 17.4s\n",
      "485:\tlearn: 0.0014730\ttotal: 9m 24s\tremaining: 16.3s\n",
      "486:\tlearn: 0.0014682\ttotal: 9m 26s\tremaining: 15.1s\n",
      "487:\tlearn: 0.0014660\ttotal: 9m 27s\tremaining: 13.9s\n",
      "488:\tlearn: 0.0014622\ttotal: 9m 28s\tremaining: 12.8s\n",
      "489:\tlearn: 0.0014576\ttotal: 9m 29s\tremaining: 11.6s\n",
      "490:\tlearn: 0.0014534\ttotal: 9m 31s\tremaining: 10.5s\n",
      "491:\tlearn: 0.0014512\ttotal: 9m 32s\tremaining: 9.31s\n",
      "492:\tlearn: 0.0014481\ttotal: 9m 33s\tremaining: 8.14s\n",
      "493:\tlearn: 0.0014426\ttotal: 9m 34s\tremaining: 6.98s\n",
      "494:\tlearn: 0.0014410\ttotal: 9m 36s\tremaining: 5.82s\n",
      "495:\tlearn: 0.0014361\ttotal: 9m 37s\tremaining: 4.65s\n",
      "496:\tlearn: 0.0014349\ttotal: 9m 38s\tremaining: 3.49s\n",
      "497:\tlearn: 0.0014254\ttotal: 9m 39s\tremaining: 2.33s\n",
      "498:\tlearn: 0.0014204\ttotal: 9m 40s\tremaining: 1.16s\n",
      "499:\tlearn: 0.0014171\ttotal: 9m 42s\tremaining: 0us\n",
      "Accuracy: 0.9998923095561808\n",
      "\n",
      "Confusion Matrix:\n",
      " [[72982     0]\n",
      " [   16 75576]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     72982\n",
      "           1       1.00      1.00      1.00     75592\n",
      "\n",
      "    accuracy                           1.00    148574\n",
      "   macro avg       1.00      1.00      1.00    148574\n",
      "weighted avg       1.00      1.00      1.00    148574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Fraud'], axis=1)\n",
    "y = df['Fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a CatBoost Classifier\n",
    "model = CatBoostClassifier(iterations=500, depth=10, learning_rate=0.05, loss_function='MultiClass', random_seed=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, cat_features=None)  # You can specify categorical features if needed\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/DMEPOS/imputed_dmepos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\",\"Rfrg_NPI\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.8727472\ttotal: 1.26s\tremaining: 5.06s\n",
      "1:\tlearn: 1.6072748\ttotal: 2.43s\tremaining: 3.64s\n",
      "2:\tlearn: 1.4135769\ttotal: 3.73s\tremaining: 2.49s\n",
      "3:\tlearn: 1.2637592\ttotal: 5s\tremaining: 1.25s\n",
      "4:\tlearn: 1.1411076\ttotal: 6.29s\tremaining: 0us\n",
      "Accuracy: 0.9997131382673551\n",
      "\n",
      "Confusion Matrix:\n",
      " [[76670     0     0     0     0     0     0     0     0]\n",
      " [    2     0     0     0     0     0     0     0     0]\n",
      " [    3     0     0     0     0     0     0     0     0]\n",
      " [    1     0     0     0     0     0     0     0     0]\n",
      " [    1     0     0     0     0     0     0     0     0]\n",
      " [    6     0     0     0     0     0     0     0     0]\n",
      " [    1     0     0     0     0     0     0     0     0]\n",
      " [    7     0     0     0     0     0     0     0     0]\n",
      " [    1     0     0     0     0     0     0     0     0]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     76670\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         3\n",
      "           3       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         6\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         7\n",
      "          10       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           1.00     76692\n",
      "   macro avg       0.11      0.11      0.11     76692\n",
      "weighted avg       1.00      1.00      1.00     76692\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sujaykumar/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Fraud','FraudType'], axis=1)\n",
    "y = df['FraudType']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a CatBoost Classifier\n",
    "model = CatBoostClassifier(iterations=5, depth=10, learning_rate=0.05, loss_function='MultiClass', random_seed=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, cat_features=None)  # You can specify categorical features if needed\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/DMEPOS/dmepos_ros_type_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\",\"Unnamed: 0.1\",\"Rfrg_NPI\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.0325532\ttotal: 13.4s\tremaining: 53.6s\n",
      "1:\tlearn: 1.7634606\ttotal: 27.6s\tremaining: 41.4s\n",
      "2:\tlearn: 1.5655964\ttotal: 40s\tremaining: 26.6s\n",
      "3:\tlearn: 1.4137308\ttotal: 53.2s\tremaining: 13.3s\n",
      "4:\tlearn: 1.2939533\ttotal: 1m 5s\tremaining: 0us\n",
      "Accuracy: 0.9590944069169213\n",
      "\n",
      "Confusion Matrix:\n",
      " [[50837  6129  3476   893    12  2257    15  5953    23  6025  1112]\n",
      " [    0 71626  2428  2277     0     0     0     0     0     0     0]\n",
      " [    0     0 76525     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0 76611     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0 76495     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0 76716     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0 76760     0     0     0     0]\n",
      " [    0  3899     0     0     0     0     0 73237     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0 76692     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0 76738     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0 76645]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.66      0.80     76732\n",
      "           1       0.88      0.94      0.91     76331\n",
      "           2       0.93      1.00      0.96     76525\n",
      "           3       0.96      1.00      0.98     76611\n",
      "           4       1.00      1.00      1.00     76495\n",
      "           5       0.97      1.00      0.99     76716\n",
      "           6       1.00      1.00      1.00     76760\n",
      "           7       0.92      0.95      0.94     77136\n",
      "           8       1.00      1.00      1.00     76692\n",
      "           9       0.93      1.00      0.96     76738\n",
      "          10       0.99      1.00      0.99     76645\n",
      "\n",
      "    accuracy                           0.96    843381\n",
      "   macro avg       0.96      0.96      0.96    843381\n",
      "weighted avg       0.96      0.96      0.96    843381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['FraudType'], axis=1)\n",
    "y = df['FraudType']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a CatBoost Classifier\n",
    "model = CatBoostClassifier(iterations=5, depth=10, learning_rate=0.05, loss_function='MultiClass', random_seed=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, cat_features=None)  # You can specify categorical features if needed\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../labelled_data/DMEPOS/dmepos_ros_type_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\",\"Unnamed: 0.1\",\"Rfrg_NPI\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.0325532\ttotal: 13.1s\tremaining: 52.3s\n",
      "1:\tlearn: 1.7634606\ttotal: 24.9s\tremaining: 37.4s\n",
      "2:\tlearn: 1.5655964\ttotal: 38s\tremaining: 25.3s\n",
      "3:\tlearn: 1.4137308\ttotal: 51.1s\tremaining: 12.8s\n",
      "4:\tlearn: 1.2939533\ttotal: 1m 4s\tremaining: 0us\n",
      "Accuracy: 0.9590944069169213\n",
      "\n",
      "Confusion Matrix:\n",
      " [[50837  6129  3476   893    12  2257    15  5953    23  6025  1112]\n",
      " [    0 71626  2428  2277     0     0     0     0     0     0     0]\n",
      " [    0     0 76525     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0 76611     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0 76495     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0 76716     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0 76760     0     0     0     0]\n",
      " [    0  3899     0     0     0     0     0 73237     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0 76692     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0 76738     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0 76645]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.66      0.80     76732\n",
      "           1       0.88      0.94      0.91     76331\n",
      "           2       0.93      1.00      0.96     76525\n",
      "           3       0.96      1.00      0.98     76611\n",
      "           4       1.00      1.00      1.00     76495\n",
      "           5       0.97      1.00      0.99     76716\n",
      "           6       1.00      1.00      1.00     76760\n",
      "           7       0.92      0.95      0.94     77136\n",
      "           8       1.00      1.00      1.00     76692\n",
      "           9       0.93      1.00      0.96     76738\n",
      "          10       0.99      1.00      0.99     76645\n",
      "\n",
      "    accuracy                           0.96    843381\n",
      "   macro avg       0.96      0.96      0.96    843381\n",
      "weighted avg       0.96      0.96      0.96    843381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['FraudType'], axis=1)\n",
    "y = df['FraudType']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a CatBoost Classifier\n",
    "model = CatBoostClassifier(iterations=5, depth=10, learning_rate=0.05, loss_function='MultiClass', random_seed=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, cat_features=None)  # You can specify categorical features if needed\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
